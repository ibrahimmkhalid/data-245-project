{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "69fb128c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "52ec8e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option(\"display.width\", 10000)\n",
    "pd.set_option(\"display.max_rows\", 500)\n",
    "pd.set_option(\"display.max_columns\", 500)\n",
    "pd.set_option(\"display.max_colwidth\", None)\n",
    "\n",
    "TESTING = False\n",
    "TESTING_SIZE = 0.01\n",
    "BENCMARK_ITER_N = 10\n",
    "random_state = 245\n",
    "\n",
    "benchmark_results = pd.DataFrame(\n",
    "    columns=[\n",
    "        \"Model\",\n",
    "        \"Dataset\",\n",
    "        \"Info\",\n",
    "        \"Data size\",\n",
    "        \"Accuracy\",\n",
    "        \"Precision\",\n",
    "        \"Recall\",\n",
    "        \"F1\",\n",
    "        \"Time per data per iter\",\n",
    "    ]\n",
    ")\n",
    "\n",
    "\n",
    "def benchmarkAndUpdateResult(df, model, model_name, dataset_name, info, pipeline_fn, **pipeline_kwargs):\n",
    "    global benchmark_results\n",
    "    df_ = pipeline_fn(df=df, **pipeline_kwargs)\n",
    "    X = df_[df_.columns[:-1]]\n",
    "    y = df_[df_.columns[-1]]\n",
    "    data_size = np.shape(X)[0]\n",
    "    y_pred = model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    precision = precision_score(y, y_pred)\n",
    "    recall = recall_score(y, y_pred)\n",
    "    f1 = f1_score(y, y_pred)\n",
    "    iter_n = BENCMARK_ITER_N\n",
    "    start = time.perf_counter_ns()\n",
    "    for _ in range(iter_n):  # benchmark\n",
    "        df_ = pipeline_fn(df=df, **pipeline_kwargs)\n",
    "        X = df_[df_.columns[:-1]]\n",
    "        model.predict(X)\n",
    "    end = time.perf_counter_ns()\n",
    "    time_per_data_per_iter = (end - start) / data_size / iter_n\n",
    "    benchmark_results.loc[len(benchmark_results)] = [\n",
    "        model_name,\n",
    "        dataset_name,\n",
    "        info,\n",
    "        data_size,\n",
    "        accuracy,\n",
    "        precision,\n",
    "        recall,\n",
    "        f1,\n",
    "        time_per_data_per_iter,\n",
    "    ]\n",
    "    print(classification_report(y, y_pred))\n",
    "    print()\n",
    "    print(f\"Model: {model_name}\")\n",
    "    print(f\"Data size: {data_size}\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1: {f1}\")\n",
    "    print(f\"Time per data per iter: {time_per_data_per_iter}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "dafed65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_train_val_split(df, random_state=random_state):\n",
    "    X_train, X_tmp, y_train, y_tmp = train_test_split(\n",
    "        df.iloc[:, :-1], df.iloc[:, -1], test_size=0.3, random_state=random_state\n",
    "    )\n",
    "    X_val, X_test, y_val, y_test = train_test_split(\n",
    "        X_tmp, y_tmp, test_size=0.5, random_state=random_state\n",
    "    )\n",
    "    return X_train, X_val, X_test, y_train, y_val, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5db8635f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Known Attacks Path: C:\\Users\\harsh\\OneDrive\\Desktop\\study work\\DATA 245 -ml\\Project\\data\\data\\probe_known_attacks_small.csv\n",
      "Similar Attacks Path: C:\\Users\\harsh\\OneDrive\\Desktop\\study work\\DATA 245 -ml\\Project\\data\\data\\probe_similar_attacks_small.csv\n",
      "New Attacks Path: C:\\Users\\harsh\\OneDrive\\Desktop\\study work\\DATA 245 -ml\\Project\\data\\data\\probe_new_attacks_small.csv\n"
     ]
    }
   ],
   "source": [
    "# Base path for the data files on your local system\n",
    "prepend_path = BASE_PATH\n",
    "\n",
    "# Define the paths to the files\n",
    "known_attacks_path = f\"{prepend_path}\\probe_known_attacks_small.csv\"\n",
    "similar_attacks_path = f\"{prepend_path}\\probe_similar_attacks_small.csv\"\n",
    "new_attacks_path = f\"{prepend_path}\\probe_new_attacks_small.csv\"\n",
    "\n",
    "# Example to print the paths (optional, for debugging purposes)\n",
    "print(\"Known Attacks Path:\", known_attacks_path)\n",
    "print(\"Similar Attacks Path:\", similar_attacks_path)\n",
    "print(\"New Attacks Path:\", new_attacks_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "332640bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(known_attacks_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "18297501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85060, 51)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "if TESTING:\n",
    "    df = df.sample(frac=TESTING_SIZE, random_state=random_state)\n",
    "    df.reset_index(drop=True, inplace=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4cdd9813",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip_type', 'ip_len', 'ip_id', 'ip_offset', 'ip_RF', 'ip_DF', 'ip_MF', 'ip_proto', 'ip_checksum', 'udp_sport', 'udp_dport', 'udp_len', 'udp_chk', 'icmp_type', 'icmp_code', 'icmp_chk', 'tcp_sport', 'tcp_dport', 'tcp_seq', 'tcp_ack', 'tcp_ffyn', 'tcp_fsyn', 'tcp_frst', 'tcp_fpush', 'tcp_fack', 'tcp_furg', 'fr_length', 'conn_status', 'count_fr_src_dst', 'count_fr_dst_src', 'count_serv_src_dst', 'count_serv_dst_src', 'num_bytes_src_dst', 'num_bytes_dst_src', 'num_bytes_serv_src_dst', 'num_bytes_serv_dst_src', 'num_pushed_src_dst', 'num_pushed_dst_src', 'num_syn_fin_src_dst', 'num_syn_fin_dst_src', 'num_fin_src_dst', 'num_fin_dst_src', 'num_ack_src_dst', 'num_ack_dst_src', 'num_syn_src_dst', 'num_syn_dst_src', 'num_rst_src_dst', 'num_rst_dst_src', 'first_packet', 'first_serv_packet', 'class'], dtype='object')"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31c9ed06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_type</th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_offset</th>\n",
       "      <th>ip_RF</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>ip_MF</th>\n",
       "      <th>ip_proto</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_dport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>udp_chk</th>\n",
       "      <th>icmp_type</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_seq</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_frst</th>\n",
       "      <th>tcp_fpush</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>tcp_furg</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>count_fr_src_dst</th>\n",
       "      <th>count_fr_dst_src</th>\n",
       "      <th>count_serv_src_dst</th>\n",
       "      <th>count_serv_dst_src</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_pushed_src_dst</th>\n",
       "      <th>num_pushed_dst_src</th>\n",
       "      <th>num_syn_fin_src_dst</th>\n",
       "      <th>num_syn_fin_dst_src</th>\n",
       "      <th>num_fin_src_dst</th>\n",
       "      <th>num_fin_dst_src</th>\n",
       "      <th>num_ack_src_dst</th>\n",
       "      <th>num_ack_dst_src</th>\n",
       "      <th>num_syn_src_dst</th>\n",
       "      <th>num_syn_dst_src</th>\n",
       "      <th>num_rst_src_dst</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_packet</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>552</td>\n",
       "      <td>13968</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>49165</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>54640</td>\n",
       "      <td>2925601313</td>\n",
       "      <td>2784850843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>6</td>\n",
       "      <td>416</td>\n",
       "      <td>579</td>\n",
       "      <td>416</td>\n",
       "      <td>579</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>579</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>552</td>\n",
       "      <td>13969</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>49164</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>54640</td>\n",
       "      <td>2925601825</td>\n",
       "      <td>2784850843</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>512</td>\n",
       "      <td>6</td>\n",
       "      <td>416</td>\n",
       "      <td>580</td>\n",
       "      <td>416</td>\n",
       "      <td>580</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>5121</td>\n",
       "      <td>65535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>415</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>40</td>\n",
       "      <td>25941</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>44274</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>58502</td>\n",
       "      <td>80</td>\n",
       "      <td>0</td>\n",
       "      <td>394780220</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>attack</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>56525</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>56195</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>56069</td>\n",
       "      <td>80</td>\n",
       "      <td>7130052</td>\n",
       "      <td>2926006578</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>31</td>\n",
       "      <td>37</td>\n",
       "      <td>500</td>\n",
       "      <td>16916</td>\n",
       "      <td>500</td>\n",
       "      <td>16916</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>52</td>\n",
       "      <td>27415</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>19834</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>54640</td>\n",
       "      <td>80</td>\n",
       "      <td>2784850843</td>\n",
       "      <td>2925599265</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>417</td>\n",
       "      <td>580</td>\n",
       "      <td>417</td>\n",
       "      <td>580</td>\n",
       "      <td>5133</td>\n",
       "      <td>65535</td>\n",
       "      <td>5133</td>\n",
       "      <td>65535</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>416</td>\n",
       "      <td>580</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ip_type  ip_len  ip_id  ip_offset  ip_RF  ip_DF  ip_MF  ip_proto  ip_checksum  udp_sport  udp_dport  udp_len  udp_chk  icmp_type  icmp_code  icmp_chk  tcp_sport  tcp_dport     tcp_seq     tcp_ack  tcp_ffyn  tcp_fsyn  tcp_frst  tcp_fpush  tcp_fack  tcp_furg  fr_length  conn_status  count_fr_src_dst  count_fr_dst_src  count_serv_src_dst  count_serv_dst_src  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_pushed_src_dst  num_pushed_dst_src  num_syn_fin_src_dst  num_syn_fin_dst_src  num_fin_src_dst  num_fin_dst_src  num_ack_src_dst  num_ack_dst_src  num_syn_src_dst  num_syn_dst_src  num_rst_src_dst  num_rst_dst_src  first_packet  first_serv_packet   class\n",
       "0        0     552  13968          0      0      0      0         6        49165          0          0        0        0          0          0         0         80      54640  2925601313  2784850843         0         0         0          0         1         0        512            6               416               579                 416                 579               5121              65535                    5121                   65535                   1                   0                    0                    0                0                0              415              579                1                1                0                0             0                  0  normal\n",
       "1        0     552  13969          0      0      0      0         6        49164          0          0        0        0          0          0         0         80      54640  2925601825  2784850843         0         0         0          0         1         0        512            6               416               580                 416                 580               5121              65535                    5121                   65535                   1                   0                    0                    0                0                0              415              580                1                1                0                0             0                  0  normal\n",
       "2        0      40  25941          0      0      0      0         6        44274          0          0        0        0          0          0         0      58502         80           0   394780220         0         0         0          0         1         0          6            1                 1                 0                   1                   0                  6                  0                       6                       0                   0                   0                    0                    0                0                0                1                0                0                0                0                0             1                  1  attack\n",
       "3        0      52  56525          0      0      1      0         6        56195          0          0        0        0          0          0         0      56069         80     7130052  2926006578         0         0         0          0         1         0         12            6                31                37                  31                  37                500              16916                     500                   16916                   1                   0                    0                    0                0                0               30               37                1                1                0                0             0                  0  normal\n",
       "4        0      52  27415          0      0      1      0         6        19834          0          0        0        0          0          0         0      54640         80  2784850843  2925599265         0         0         0          0         1         0         12            6               417               580                 417                 580               5133              65535                    5133                   65535                   1                   0                    0                    0                0                0              416              580                1                1                0                0             0                  0  normal"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36bc9fd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_type</th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_offset</th>\n",
       "      <th>ip_RF</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>ip_MF</th>\n",
       "      <th>ip_proto</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_dport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>udp_chk</th>\n",
       "      <th>icmp_type</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_seq</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_frst</th>\n",
       "      <th>tcp_fpush</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>tcp_furg</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>count_fr_src_dst</th>\n",
       "      <th>count_fr_dst_src</th>\n",
       "      <th>count_serv_src_dst</th>\n",
       "      <th>count_serv_dst_src</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_pushed_src_dst</th>\n",
       "      <th>num_pushed_dst_src</th>\n",
       "      <th>num_syn_fin_src_dst</th>\n",
       "      <th>num_syn_fin_dst_src</th>\n",
       "      <th>num_fin_src_dst</th>\n",
       "      <th>num_fin_dst_src</th>\n",
       "      <th>num_ack_src_dst</th>\n",
       "      <th>num_ack_dst_src</th>\n",
       "      <th>num_syn_src_dst</th>\n",
       "      <th>num_syn_dst_src</th>\n",
       "      <th>num_rst_src_dst</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_packet</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.0</td>\n",
       "      <td>85060.0</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.0</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>8.506000e+04</td>\n",
       "      <td>8.506000e+04</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060.000000</td>\n",
       "      <td>85060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>normal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>48432</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.754667</td>\n",
       "      <td>100.386174</td>\n",
       "      <td>31165.699577</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.363931</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.039925</td>\n",
       "      <td>33087.734246</td>\n",
       "      <td>7335.142699</td>\n",
       "      <td>4493.626499</td>\n",
       "      <td>7.966353</td>\n",
       "      <td>6440.783964</td>\n",
       "      <td>0.062168</td>\n",
       "      <td>0.054456</td>\n",
       "      <td>620.470245</td>\n",
       "      <td>27821.129226</td>\n",
       "      <td>13938.420973</td>\n",
       "      <td>1.471971e+09</td>\n",
       "      <td>1.008449e+09</td>\n",
       "      <td>0.553903</td>\n",
       "      <td>0.568152</td>\n",
       "      <td>0.527980</td>\n",
       "      <td>0.486151</td>\n",
       "      <td>0.913884</td>\n",
       "      <td>0.473360</td>\n",
       "      <td>65.945121</td>\n",
       "      <td>5.869821</td>\n",
       "      <td>405.885857</td>\n",
       "      <td>520.797084</td>\n",
       "      <td>328.958617</td>\n",
       "      <td>291.029732</td>\n",
       "      <td>10105.989772</td>\n",
       "      <td>28114.899694</td>\n",
       "      <td>8279.352187</td>\n",
       "      <td>17662.463144</td>\n",
       "      <td>40.784376</td>\n",
       "      <td>44.620327</td>\n",
       "      <td>36.238349</td>\n",
       "      <td>74.642147</td>\n",
       "      <td>83.044075</td>\n",
       "      <td>19.918340</td>\n",
       "      <td>162.481060</td>\n",
       "      <td>265.684047</td>\n",
       "      <td>113.913144</td>\n",
       "      <td>30.737621</td>\n",
       "      <td>37.778486</td>\n",
       "      <td>140.026957</td>\n",
       "      <td>0.003492</td>\n",
       "      <td>0.089560</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>5.925130</td>\n",
       "      <td>191.572060</td>\n",
       "      <td>19906.379891</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.481132</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.450021</td>\n",
       "      <td>18710.567547</td>\n",
       "      <td>17846.337785</td>\n",
       "      <td>13369.749481</td>\n",
       "      <td>21.495346</td>\n",
       "      <td>15363.667022</td>\n",
       "      <td>0.491994</td>\n",
       "      <td>0.400504</td>\n",
       "      <td>4495.728132</td>\n",
       "      <td>24382.931287</td>\n",
       "      <td>20878.971872</td>\n",
       "      <td>1.419588e+09</td>\n",
       "      <td>1.377824e+09</td>\n",
       "      <td>0.820632</td>\n",
       "      <td>0.819572</td>\n",
       "      <td>0.821924</td>\n",
       "      <td>0.822284</td>\n",
       "      <td>0.710662</td>\n",
       "      <td>0.821969</td>\n",
       "      <td>190.189264</td>\n",
       "      <td>4.249343</td>\n",
       "      <td>1235.773115</td>\n",
       "      <td>1367.500610</td>\n",
       "      <td>1956.456315</td>\n",
       "      <td>1413.383988</td>\n",
       "      <td>17353.336438</td>\n",
       "      <td>41288.108509</td>\n",
       "      <td>17651.159114</td>\n",
       "      <td>29433.799558</td>\n",
       "      <td>1117.698208</td>\n",
       "      <td>1485.625396</td>\n",
       "      <td>786.401261</td>\n",
       "      <td>1124.563326</td>\n",
       "      <td>1294.569237</td>\n",
       "      <td>968.524034</td>\n",
       "      <td>1637.743817</td>\n",
       "      <td>1173.387641</td>\n",
       "      <td>1556.568989</td>\n",
       "      <td>1363.660077</td>\n",
       "      <td>1310.832438</td>\n",
       "      <td>666.280141</td>\n",
       "      <td>0.058987</td>\n",
       "      <td>0.285552</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>40.000000</td>\n",
       "      <td>14018.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>16980.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>80.000000</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>39.000000</td>\n",
       "      <td>38.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>813.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>52.000000</td>\n",
       "      <td>31076.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>34049.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36378.000000</td>\n",
       "      <td>1057.000000</td>\n",
       "      <td>1.237088e+09</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>250.000000</td>\n",
       "      <td>301.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>56.000000</td>\n",
       "      <td>3989.000000</td>\n",
       "      <td>343.500000</td>\n",
       "      <td>1377.500000</td>\n",
       "      <td>125.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>48434.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>47231.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>50326.000000</td>\n",
       "      <td>33354.000000</td>\n",
       "      <td>2.578381e+09</td>\n",
       "      <td>2.032205e+09</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>651.000000</td>\n",
       "      <td>763.000000</td>\n",
       "      <td>461.000000</td>\n",
       "      <td>386.000000</td>\n",
       "      <td>9528.000000</td>\n",
       "      <td>59434.750000</td>\n",
       "      <td>5046.000000</td>\n",
       "      <td>33812.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>384.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>78.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>192.000000</td>\n",
       "      <td>4108.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>65534.000000</td>\n",
       "      <td>63399.000000</td>\n",
       "      <td>65024.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>65533.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>65030.000000</td>\n",
       "      <td>65389.000000</td>\n",
       "      <td>65389.000000</td>\n",
       "      <td>4.294916e+09</td>\n",
       "      <td>4.294913e+09</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4068.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>66329.000000</td>\n",
       "      <td>65799.000000</td>\n",
       "      <td>155647.000000</td>\n",
       "      <td>86070.000000</td>\n",
       "      <td>140123.000000</td>\n",
       "      <td>262140.000000</td>\n",
       "      <td>135204.000000</td>\n",
       "      <td>262140.000000</td>\n",
       "      <td>79380.000000</td>\n",
       "      <td>131070.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>125971.000000</td>\n",
       "      <td>65556.000000</td>\n",
       "      <td>65536.000000</td>\n",
       "      <td>130773.000000</td>\n",
       "      <td>65976.000000</td>\n",
       "      <td>131072.000000</td>\n",
       "      <td>95251.000000</td>\n",
       "      <td>65535.000000</td>\n",
       "      <td>65538.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             ip_type        ip_len         ip_id  ip_offset    ip_RF         ip_DF    ip_MF      ip_proto   ip_checksum     udp_sport     udp_dport       udp_len       udp_chk     icmp_type     icmp_code      icmp_chk     tcp_sport     tcp_dport       tcp_seq       tcp_ack      tcp_ffyn      tcp_fsyn      tcp_frst     tcp_fpush      tcp_fack      tcp_furg     fr_length   conn_status  count_fr_src_dst  count_fr_dst_src  count_serv_src_dst  count_serv_dst_src  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_pushed_src_dst  num_pushed_dst_src  num_syn_fin_src_dst  num_syn_fin_dst_src  num_fin_src_dst  num_fin_dst_src  num_ack_src_dst  num_ack_dst_src  num_syn_src_dst  num_syn_dst_src  num_rst_src_dst  num_rst_dst_src  first_packet  first_serv_packet   class\n",
       "count   85060.000000  85060.000000  85060.000000    85060.0  85060.0  85060.000000  85060.0  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  8.506000e+04  8.506000e+04  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000  85060.000000      85060.000000      85060.000000        85060.000000        85060.000000       85060.000000       85060.000000            85060.000000            85060.000000        85060.000000        85060.000000         85060.000000         85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000     85060.000000  85060.000000       85060.000000   85060\n",
       "unique           NaN           NaN           NaN        NaN      NaN           NaN      NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN               NaN               NaN                 NaN                 NaN                NaN                NaN                     NaN                     NaN                 NaN                 NaN                  NaN                  NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN           NaN                NaN       2\n",
       "top              NaN           NaN           NaN        NaN      NaN           NaN      NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN               NaN               NaN                 NaN                 NaN                NaN                NaN                     NaN                     NaN                 NaN                 NaN                  NaN                  NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN           NaN                NaN  normal\n",
       "freq             NaN           NaN           NaN        NaN      NaN           NaN      NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN           NaN               NaN               NaN                 NaN                 NaN                NaN                NaN                     NaN                     NaN                 NaN                 NaN                  NaN                  NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN              NaN           NaN                NaN   48432\n",
       "mean        0.754667    100.386174  31165.699577        0.0      0.0      0.363931      0.0      8.039925  33087.734246   7335.142699   4493.626499      7.966353   6440.783964      0.062168      0.054456    620.470245  27821.129226  13938.420973  1.471971e+09  1.008449e+09      0.553903      0.568152      0.527980      0.486151      0.913884      0.473360     65.945121      5.869821        405.885857        520.797084          328.958617          291.029732       10105.989772       28114.899694             8279.352187            17662.463144           40.784376           44.620327            36.238349            74.642147        83.044075        19.918340       162.481060       265.684047       113.913144        30.737621        37.778486       140.026957      0.003492           0.089560     NaN\n",
       "std         5.925130    191.572060  19906.379891        0.0      0.0      0.481132      0.0      4.450021  18710.567547  17846.337785  13369.749481     21.495346  15363.667022      0.491994      0.400504   4495.728132  24382.931287  20878.971872  1.419588e+09  1.377824e+09      0.820632      0.819572      0.821924      0.822284      0.710662      0.821969    190.189264      4.249343       1235.773115       1367.500610         1956.456315         1413.383988       17353.336438       41288.108509            17651.159114            29433.799558         1117.698208         1485.625396           786.401261          1124.563326      1294.569237       968.524034      1637.743817      1173.387641      1556.568989      1363.660077      1310.832438       666.280141      0.058987           0.285552     NaN\n",
       "min         0.000000     28.000000      0.000000        0.0      0.0      0.000000      0.0      1.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000  0.000000e+00  0.000000e+00      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      1.000000          0.000000          0.000000            0.000000            0.000000           0.000000           0.000000                0.000000                0.000000            0.000000            0.000000             0.000000             0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000         0.000000      0.000000           0.000000     NaN\n",
       "25%         0.000000     40.000000  14018.000000        0.0      0.0      0.000000      0.0      6.000000  16980.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000     80.000000     80.000000  0.000000e+00  0.000000e+00      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      6.000000      2.000000         39.000000         38.000000            5.000000            2.000000         813.000000          18.000000               30.000000                0.000000            0.000000            0.000000             0.000000             0.000000         0.000000         0.000000         1.000000         1.000000         1.000000         0.000000         0.000000         0.000000      0.000000           0.000000     NaN\n",
       "50%         0.000000     52.000000  31076.500000        0.0      0.0      0.000000      0.0      6.000000  34049.500000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000  36378.000000   1057.000000  1.237088e+09  0.000000e+00      0.000000      0.000000      0.000000      0.000000      1.000000      0.000000     12.000000      6.000000        250.000000        301.000000           94.000000           56.000000        3989.000000         343.500000             1377.500000              125.000000            0.000000            0.000000             0.000000             0.000000         0.000000         0.000000        11.000000        77.000000         1.000000         1.000000         0.000000         2.000000      0.000000           0.000000     NaN\n",
       "75%         0.000000     60.000000  48434.500000        0.0      0.0      1.000000      0.0      6.000000  47231.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000      0.000000  50326.000000  33354.000000  2.578381e+09  2.032205e+09      1.000000      1.000000      1.000000      1.000000      1.000000      1.000000     20.000000      8.000000        651.000000        763.000000          461.000000          386.000000        9528.000000       59434.750000             5046.000000            33812.000000            3.000000            0.000000             0.000000             0.000000         2.000000         1.000000       135.000000       384.000000         3.000000         2.000000         0.000000        78.000000      0.000000           0.000000     NaN\n",
       "max       192.000000   4108.000000  65535.000000        0.0      0.0      1.000000      0.0     17.000000  65534.000000  63399.000000  65024.000000    200.000000  65533.000000     14.000000      3.000000  65030.000000  65389.000000  65389.000000  4.294916e+09  4.294913e+09      2.000000      2.000000      2.000000      2.000000      2.000000      2.000000   4068.000000     15.000000      66329.000000      65799.000000       155647.000000        86070.000000      140123.000000      262140.000000           135204.000000           262140.000000        79380.000000       131070.000000         65535.000000        125971.000000     65556.000000     65536.000000    130773.000000     65976.000000    131072.000000     95251.000000     65535.000000     65538.000000      1.000000           1.000000     NaN"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6098a7",
   "metadata": {},
   "source": [
    "It seems as though ip_RF, ip_MF, and ip_offset do not contain any valuable information. They can be removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "61b3a361",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=[\"ip_RF\", \"ip_MF\", \"ip_offset\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "368b6fc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['ip_type', 'ip_len', 'ip_id', 'ip_DF', 'ip_proto', 'ip_checksum', 'udp_sport', 'udp_dport', 'udp_len', 'udp_chk', 'icmp_type', 'icmp_code', 'icmp_chk', 'tcp_sport', 'tcp_dport', 'tcp_seq', 'tcp_ack', 'tcp_ffyn', 'tcp_fsyn', 'tcp_frst', 'tcp_fpush', 'tcp_fack', 'tcp_furg', 'fr_length', 'conn_status', 'count_fr_src_dst', 'count_fr_dst_src', 'count_serv_src_dst', 'count_serv_dst_src', 'num_bytes_src_dst', 'num_bytes_dst_src', 'num_bytes_serv_src_dst', 'num_bytes_serv_dst_src', 'num_pushed_src_dst', 'num_pushed_dst_src', 'num_syn_fin_src_dst', 'num_syn_fin_dst_src', 'num_fin_src_dst', 'num_fin_dst_src', 'num_ack_src_dst', 'num_ack_dst_src', 'num_syn_src_dst', 'num_syn_dst_src', 'num_rst_src_dst', 'num_rst_dst_src', 'first_packet', 'first_serv_packet', 'class'], dtype='object')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "45c257fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "normal    48432\n",
      "attack    36628\n",
      "Name: class, dtype: int64\n",
      "normal    56.938632\n",
      "attack    43.061368\n",
      "Name: class, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(df[\"class\"].value_counts())\n",
    "print(df[\"class\"].value_counts(normalize=True) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b57a7bfb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ip_type                    int64\n",
       "ip_len                     int64\n",
       "ip_id                      int64\n",
       "ip_DF                      int64\n",
       "ip_proto                   int64\n",
       "ip_checksum                int64\n",
       "udp_sport                  int64\n",
       "udp_dport                  int64\n",
       "udp_len                    int64\n",
       "udp_chk                    int64\n",
       "icmp_type                  int64\n",
       "icmp_code                  int64\n",
       "icmp_chk                   int64\n",
       "tcp_sport                  int64\n",
       "tcp_dport                  int64\n",
       "tcp_seq                    int64\n",
       "tcp_ack                    int64\n",
       "tcp_ffyn                   int64\n",
       "tcp_fsyn                   int64\n",
       "tcp_frst                   int64\n",
       "tcp_fpush                  int64\n",
       "tcp_fack                   int64\n",
       "tcp_furg                   int64\n",
       "fr_length                  int64\n",
       "conn_status                int64\n",
       "count_fr_src_dst           int64\n",
       "count_fr_dst_src           int64\n",
       "count_serv_src_dst         int64\n",
       "count_serv_dst_src         int64\n",
       "num_bytes_src_dst          int64\n",
       "num_bytes_dst_src          int64\n",
       "num_bytes_serv_src_dst     int64\n",
       "num_bytes_serv_dst_src     int64\n",
       "num_pushed_src_dst         int64\n",
       "num_pushed_dst_src         int64\n",
       "num_syn_fin_src_dst        int64\n",
       "num_syn_fin_dst_src        int64\n",
       "num_fin_src_dst            int64\n",
       "num_fin_dst_src            int64\n",
       "num_ack_src_dst            int64\n",
       "num_ack_dst_src            int64\n",
       "num_syn_src_dst            int64\n",
       "num_syn_dst_src            int64\n",
       "num_rst_src_dst            int64\n",
       "num_rst_dst_src            int64\n",
       "first_packet               int64\n",
       "first_serv_packet          int64\n",
       "class                     object\n",
       "dtype: object"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "15fcff91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      83516\n",
       "40      1528\n",
       "192       16\n",
       "Name: ip_type, dtype: int64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"ip_type\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "9b8ce454",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"class\"] = df[\"class\"].replace({\"normal\": 0, \"attack\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "bab49396",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.astype(float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "56842aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = df.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "c239308b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x1200 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(15, 12))\n",
    "sns.heatmap(corr, cmap=\"Blues\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8b03645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "class                     1.000000\n",
       "tcp_sport                 0.376711\n",
       "first_serv_packet         0.288401\n",
       "tcp_fsyn                  0.183862\n",
       "tcp_ffyn                  0.179369\n",
       "udp_sport                 0.159150\n",
       "num_rst_dst_src           0.148479\n",
       "tcp_furg                  0.081623\n",
       "ip_id                     0.070370\n",
       "ip_proto                  0.068846\n",
       "tcp_fpush                 0.068064\n",
       "udp_chk                   0.050838\n",
       "udp_dport                 0.043169\n",
       "num_syn_fin_dst_src       0.032562\n",
       "num_syn_src_dst           0.023503\n",
       "num_fin_src_dst           0.018179\n",
       "count_fr_dst_src          0.016557\n",
       "num_syn_fin_src_dst       0.010139\n",
       "num_pushed_src_dst       -0.005405\n",
       "num_pushed_dst_src       -0.006834\n",
       "num_fin_dst_src          -0.008403\n",
       "num_rst_src_dst          -0.008925\n",
       "count_serv_src_dst       -0.010181\n",
       "ip_checksum              -0.015762\n",
       "num_syn_dst_src          -0.017306\n",
       "count_fr_src_dst         -0.018505\n",
       "first_packet             -0.032560\n",
       "num_ack_dst_src          -0.042007\n",
       "num_ack_src_dst          -0.055285\n",
       "count_serv_dst_src       -0.058866\n",
       "icmp_type                -0.076590\n",
       "tcp_seq                  -0.082221\n",
       "tcp_frst                 -0.089140\n",
       "ip_type                  -0.098455\n",
       "icmp_chk                 -0.106911\n",
       "icmp_code                -0.115398\n",
       "num_bytes_serv_src_dst   -0.205258\n",
       "conn_status              -0.217683\n",
       "udp_len                  -0.244732\n",
       "fr_length                -0.249022\n",
       "ip_len                   -0.265645\n",
       "num_bytes_src_dst        -0.275082\n",
       "tcp_dport                -0.302774\n",
       "ip_DF                    -0.305169\n",
       "tcp_fack                 -0.406649\n",
       "tcp_ack                  -0.456281\n",
       "num_bytes_serv_dst_src   -0.520069\n",
       "num_bytes_dst_src        -0.535816\n",
       "Name: class, dtype: float64"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corr[\"class\"].sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba0f28df",
   "metadata": {},
   "source": [
    "The target feature does not seem to have very strong correlations with any particular feature."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "80670942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove all features with an absolute correlation of less than 0.1\n",
    "cols_corr_gt1 = corr[\"class\"][abs(corr[\"class\"]) > 0.1].index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "b91cff26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['ip_len', 'ip_DF', 'udp_sport', 'udp_len', 'icmp_code', 'icmp_chk', 'tcp_sport', 'tcp_dport', 'tcp_ack', 'tcp_ffyn', 'tcp_fsyn', 'tcp_fack', 'fr_length', 'conn_status', 'num_bytes_src_dst', 'num_bytes_dst_src', 'num_bytes_serv_src_dst', 'num_bytes_serv_dst_src', 'num_rst_dst_src', 'first_serv_packet', 'class'], dtype='object')\n",
      "21\n"
     ]
    }
   ],
   "source": [
    "print(cols_corr_gt1)\n",
    "print(len(cols_corr_gt1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0378af67",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X = df.drop(columns=[\"class\"])\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "pca = PCA(n_components=len(df.columns) - 1)\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "pca_cumsum = pca.explained_variance_ratio_.cumsum()\n",
    "plt.plot(pca_cumsum)\n",
    "plt.xlabel(\"Number of components\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\"Cumulative explained variance vs Number of components\")\n",
    "plt.grid()\n",
    "plt.xticks(range(0, len(df.columns) - 1, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8efeeab5",
   "metadata": {},
   "source": [
    "- at n=27, we have 95% of the variance explained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3689f280",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAr4AAAHFCAYAAAAUivrqAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/bCgiHAAAACXBIWXMAAA9hAAAPYQGoP6dpAACQmElEQVR4nOzdd1hT1x8G8DdASNgge4Mbt+LeC3BUf9parbZuW6211lGt1jrrrrXaodbWbW1t66haHLhn3VvEalUcIIrKFAjk/P6gpMYwFbjc8H6eh0dzcu/Nm5v1zcm55yqEEAJEREREREbOROoARERERETFgYUvEREREZUKLHyJiIiIqFRg4UtEREREpQILXyIiIiIqFVj4EhEREVGpwMKXiIiIiEoFFr5EREREVCqw8CUiIiKiUuGlCt8LFy6gf//+8Pf3h1qthrW1NerUqYO5c+fi8ePHhZ2xUE2ZMgUKheKl1g0NDcWUKVOyvc7Pzw/9+vV7+WAys3//figUCuzfv79Y1y0MJfGxUigUOT636D8KhQIKhQKzZ882uG7lypVQKBQ4deqUBMkyn1evvfaaJLf9Mj777DP4+PjAzMwM9vb2UscplZKTkzFlyhTJ3guf17JlS7Rs2VJ3ObdsWZ+jjx49eqnbunXrlqSfAa8q673m1q1bBV736NGjmDJlCp4+fWpw3YuPQVHx8/OT5PNGo9Fg6tSp8PPzg0qlQuXKlfHNN9/ka92EhASMHTsWwcHBcHZ2fqXPTLOCrvDDDz9g6NChqFSpEsaMGYMqVapAo9Hg1KlTWLJkCY4dO4ZNmza9VJiSLjQ0FN999122O3vTpk2wtbUt/lAyVKdOHRw7dgxVqlSROkqJcezYMXh5eUkdQzZmz56N9957D2XKlJE6iiz98ccfmDFjBiZMmID27dtDpVJJHalUSk5OxtSpUwGgWAqe3CxatEjvcknKZkyOHj2KqVOnol+/fgZfOF98DIzN0KFDsWbNGnz++eeoV68edu7ciY8++ggJCQn49NNPc103NjYWS5cuRc2aNdGlSxf8+OOPL52jQIXvsWPH8P777yMoKAibN2/We7MMCgrC6NGjsWPHjpcOI2e1a9eWOoJs2NraomHDhlLHkJwQAikpKbCwsOD+KIC2bdti//79mDFjBr788kup4xSr558zr+LSpUsAgOHDh8PFxaUwopHMlYaOiGfPnmX72tFoNFAoFDAzK3BfYKEqaY9BVFQUrKysCqVT7/Lly1i2bBlmzJiBMWPGAMj8QhUbG4vp06djyJAhuXZk+Pr64smTJ7pfGl6l8C3QUIeZM2dCoVBg6dKl2fYQmJubo3PnzrrLOXVFv/hTc9bPBnv37sW7774LR0dH2Nraok+fPkhKSkJ0dDS6d+8Oe3t7uLu74+OPP4ZGo9Gtn9NP51k/p6xcuTLX+7V+/XoEBwfD3d0dFhYWCAgIwLhx45CUlKRbpl+/fvjuu+909yvrL+unjufv08OHD2Fubo6JEyca3NbVq1ehUCjw9ddf69qio6MxePBgeHl5wdzcHP7+/pg6dSrS09Nzzf18/kaNGsHKygrW1tYICQnB2bNnddcfPnwYSqUSH3/8sd56Wft92bJlujaFQoFhw4bh+++/R8WKFaFSqVClShX88ssveeY4deoU3nrrLfj5+cHCwgJ+fn7o2bMnbt++rbdcdo9Xv379YG1tjevXr6NDhw6wtraGt7c3Ro8ejdTUVL3109LSMH36dFSuXBkqlQrOzs7o378/Hj58qLecRqPB2LFj4ebmBktLSzRt2hQnTpzI835oNBq4uLigd+/eBtc9ffoUFhYWGDVqFAAgJSUFo0ePRq1atWBnZ4cyZcqgUaNG+OOPPwzWzdq3S5YsQUBAAFQqFVatWqW77vnXysOHDzF06FBUqVIF1tbWcHFxQevWrXHo0CG9bWY9x+fNm4f58+fD398f1tbWaNSoEf766y+DDMePH0enTp3g6OgItVqNcuXKYcSIEXrL/P333+jVqxdcXFygUqkQEBCge+7npnbt2mjWrJlBe0ZGBjw9PfH666/r2hYvXoyaNWvC2toaNjY2qFy5cp7f+LNUqlQJAwcOxHfffWfw3HpRTj8d9uvXD35+frrLWfvxiy++wJw5c3TP4ZYtW+LatWvQaDQYN24cPDw8YGdnh65duyImJibb29y0aRNq1KgBtVqNsmXL6r3Ws8THx+Pjjz+Gv78/zM3N4enpiREjRui95wC5P2eyo9VqMXfuXN1rw8XFBX369MHdu3d1y/j5+eGzzz4DALi6uubrJ8P8PG8OHz6MNm3awMbGBpaWlmjcuDH+/PNPvWVe9b0+63GaO3cuZsyYAR8fH6jVatStWxd79uwxyF2QTPv27cP7778PJycnODo64vXXX8f9+/cNtpnX+y2Qv/ezW7duwdnZGQAwdepU3WfK858j7733Hry9vXXvc02aNMHu3btzfJwuX74MhUKB3377Tdd2+vRpKBQKVK1aVW/Zzp07IzAwUHf5+ddKXtmyPHjwAD179oSdnR1cXV0xYMAAxMXF5ZgvL6mpqZg2bRoCAgKgVqvh6OiIVq1a4ejRo7plUlJSMH78eL3XzgcffGAwdCBr6NHGjRtRu3ZtqNVqTJ06Vff5s2bNGowePRqenp5QqVS4fv06AGD37t1o06YNbG1tYWlpiSZNmmT73HpRWFgY/ve//8HLywtqtRrly5fH4MGD9YaDTJkyRVf0+fv76/Zr1mdhdu9Xjx8/xtChQ+Hp6Qlzc3OULVsWEyZMMPhczHqvWLNmDQICAmBpaYmaNWti27Zt+d39Bnbu3AlXV1d069YNGzduREpKyktva/PmzRBCoH///nrt/fv3x7Nnz/LsNM3aV4VC5FN6erqwtLQUDRo0yO8qAoCYPHmyQbuvr6/o27ev7vKKFSsEAOHv7y9Gjx4tdu3aJebMmSNMTU1Fz549RZ06dcT06dNFWFiY+OSTTwQA8eWXX+rW37dvnwAg9u3bp3c7N2/eFADEihUrdG2TJ08WL97tzz//XHz11Vfizz//FPv37xdLliwR/v7+olWrVrplrl+/Lrp16yYAiGPHjun+UlJSsr1PXbt2Fd7e3iIjI0PvtsaOHSvMzc3Fo0ePhBBCREVFCW9vb+Hr6yu+//57sXv3bvH5558LlUol+vXrl+c+njFjhlAoFGLAgAFi27ZtYuPGjaJRo0bCyspKXL58Wbfc7NmzBQDxxx9/CCGEuHTpkrC0tBTvvPOO3vYACG9vb1GlShXx888/iy1btoh27doJAOK3337LdZ//9ttvYtKkSWLTpk3iwIED4pdffhEtWrQQzs7O4uHDh7mu27dvX2Fubi4CAgLEvHnzxO7du8WkSZOEQqEQU6dO1S2XkZEh2rVrJ6ysrMTUqVNFWFiY+PHHH4Wnp6eoUqWKSE5O1tumQqEQY8aMEbt27RLz588Xnp6ewtbWVu+xys7IkSOFhYWFiIuL02tftGiRACAuXLgghBDi6dOnol+/fmLNmjVi7969YseOHeLjjz8WJiYmYtWqVQb71tPTU9SoUUOsW7dO7N27V1y6dEl33fOvlatXr4r3339f/PLLL2L//v1i27ZtYuDAgcLExERvv2U9x/38/ES7du3E5s2bxebNm0X16tWFg4ODePr0qW7ZHTt2CKVSKWrUqCFWrlwp9u7dK5YvXy7eeust3TKXL18WdnZ2onr16mL16tVi165dYvTo0cLExERMmTIl1322cOFCAUBcu3ZNrz00NFQAEFu2bBFCCPHzzz8LAOLDDz8Uu3btErt37xZLliwRw4cPz3X7Wfvpgw8+EFFRUcLS0lL07t1bd13W+8jJkyd1bS1atBAtWrQw2E7fvn2Fr6+vwX709fUVnTp1Etu2bRNr164Vrq6uomLFiqJ3795iwIABYvv27WLJkiXC2tpadOrUSW+bvr6+wtPTU/j4+Ijly5eL0NBQ8fbbbwsA4osvvtAtl5SUJGrVqiWcnJzE/Pnzxe7du8XChQuFnZ2daN26tdBqtXr3N6fnTHbee+89AUAMGzZM7NixQyxZskQ4OzsLb29v3WvwzJkzYuDAgQKA2LFjhzh27Ji4c+dOjtvMz/Nm//79QqlUisDAQLF+/XqxefNmERwcLBQKhfjll18MHqOXfa/Pepy8vb1F06ZNxYYNG8Rvv/0m6tWrJ5RKpTh69OhLZypbtqz48MMPxc6dO8WPP/4oHBwc9D4DhMj/+21+3s9SUlLEjh07BAAxcOBA3WfK9evXhRBChISECGdnZ7F06VKxf/9+sXnzZjFp0iS97Nlxd3cX7733nu7y7NmzhYWFhQAg7t27J4QQQqPRCFtbWzF27Fjdcs+/VvLKlvU5WqlSJTFp0iQRFhYm5s+fL1Qqlejfv3+u+Z5/HJ9/L9NoNKJVq1bCzMxMfPzxxyI0NFRs2bJFfPrpp+Lnn38WQgih1WpFSEiIMDMzExMnThS7du0S8+bNE1ZWVqJ27dq6z2MhMl+P7u7uomzZsmL58uVi37594sSJE7rPH09PT9GtWzexZcsWsW3bNhEbGyvWrFkjFAqF6NKli9i4caPYunWreO2114SpqanYvXu3bttZz5mbN2/q2hYvXixmzZoltmzZIg4cOCBWrVolatasKSpVqiTS0tKEEELcuXNHfPjhhwKA2Lhxo26/Zn3OvPh+9ezZM1GjRg1hZWUl5s2bJ3bt2iUmTpwozMzMRIcOHfT2adbnQP369cWvv/4qQkNDRcuWLYWZmZm4ceOG3rK+vr7Z1mYvevr0qVi6dKlo3bq1MDU11X127tixQ6Snp+e5/vPeeust4ezsbNCemJgoAIjx48fne1sPHz7Msb7Mj3wXvtHR0QKA3ptdnhsvYOH74Ycf6i3XpUsXAUDMnz9fr71WrVqiTp06usuvWvg+T6vVCo1GIw4cOCAAiPPnz+uu++CDD3Jc98X7tGXLFgFA7Nq1S9eWnp4uPDw8xBtvvKFrGzx4sLC2tha3b9/W2968efMEAL030xdFRkYKMzMzg/2WkJAg3NzcRPfu3fXuV4cOHYS9vb24dOmSqFKliqhcubJITEzUWxeAsLCwENHR0Xq5K1euLMqXL69ry2mfPy89PV0kJiYKKysrsXDhwlzX7du3rwAgfv31V71tdOjQQVSqVEl3Oato2rBhg95yJ0+eFADEokWLhBBChIeHCwBi5MiResv99NNPAkCehe+FCxcEALF06VK99vr164vAwMBc77NGoxEDBw4UtWvX1rsOgLCzsxOPHz82WC+vF3HWdtu0aSO6du2qa896jlevXl3vjejEiRMCgO4DQwghypUrJ8qVKyeePXuW4+2EhIQILy8vg4J/2LBhQq1WZ5s9y6NHj4S5ubn49NNP9dq7d+8uXF1dhUaj0W3L3t4+x+3kJqvwFUKICRMmCBMTE91rtDAK35o1a+p9WV2wYIEAIDp37qy3/ogRIwQAvf3k6+srFAqFOHfunN6yQUFBwtbWViQlJQkhhJg1a5YwMTHRyymEEL///rsAIEJDQ/Xub07PmRdlPeeHDh2q1378+HEBQO9xyXoffP4LaU7y87xp2LChcHFxEQkJCbq29PR0Ua1aNeHl5aUr5l/1vT7rcfLw8NDLEx8fL8qUKSPatm370ple3G9z584VAERUVJQQomDvt/l9P8vtA9za2lqMGDHCoD0v77zzjihbtqzuctu2bcW7774rHBwcdF/Gjxw5YvD59OJrJbdsWc+fuXPn6rUPHTpUqNVqvS9v2cmu8F29erUAIH744Ycc18sqxl+83fXr1xu8X/v6+gpTU1MRERGht2zW50/z5s312pOSkkSZMmUMvtBmZGSImjVrivr16+vasit8n5dVR9y+fVuvw0kIIb744osc133xMViyZEm2z6M5c+YYPH4AhKurq4iPj9e1RUdHCxMTEzFr1iy99fNb+D4vOjpafPPNN6JJkyZCoVAIFxcX8cEHH4jDhw/n+XgLkfk++Pxz/3nm5uZ6X9by8qqFb4mazuzFI6IDAgIAAB07djRoz+snzoL4559/0KtXL7i5ucHU1BRKpRItWrQAAISHh7/UNtu3bw83NzesWLFC17Zz507cv38fAwYM0LVt27YNrVq1goeHB9LT03V/7du3BwAcOHAgx9vYuXMn0tPT0adPH7111Wo1WrRooTeUQKFQYPXq1bCxsUHdunVx8+ZN/Prrr7CysjLYbps2beDq6qq7bGpqih49euD69et6P5m+KDExEZ988gnKly8PMzMzmJmZwdraGklJSfnajwqFAp06ddJrq1Gjht5jvW3bNtjb26NTp05697lWrVpwc3PT3ed9+/YBAN5++2297XXv3j1f47iqV6+OwMBAvccvPDwcJ06c0Hv8AOC3335DkyZNYG1tDTMzMyiVSixbtizb+9y6dWs4ODjkefsAsGTJEtSpUwdqtVq33T179mS73Y4dO8LU1FR3uUaNGgCg23fXrl3DjRs3MHDgQKjV6mxvLyUlBXv27EHXrl1haWmpt387dOiAlJSUbIdPZHF0dESnTp2watUqaLVaAMCTJ0/wxx9/oE+fPrr9Xr9+fTx9+hQ9e/bEH3/88dJHho8dOxZlypTBJ5988lLrZ6dDhw4wMfnvbTG39yAAiIyM1GuvWrUqatasqdfWq1cvxMfH48yZMwAyn8PVqlVDrVq19PZxSEhItkO28vucyXrOv/hzdP369REQEJCvn2tflJ/nTVJSEo4fP45u3brB2tpa125qaorevXvj7t27iIiI0FvnVd/rX3/9db08NjY26NSpEw4ePIiMjIyXyvT8MD3A8DVUkPdbIH/vZ7mpX78+Vq5cienTp+Ovv/7SG/KRmzZt2uCff/7BzZs3kZKSgsOHD6Ndu3Zo1aoVwsLCAGT+nK9SqdC0adN8bTMn2e2zlJSUHIcB5Wb79u1Qq9UG76/P27t3LwDD5/ibb74JKysrg+d4jRo1ULFixWy39cYbb+hdPnr0KB4/foy+ffvqPb5arRbt2rXDyZMnDYYiPS8mJgZDhgyBt7e37v3a19cXwMvXEXv37oWVlRW6deum1551/1+8v61atYKNjY3usqurK1xcXAqlXnJ1dcWwYcNw+PBh3L59G2PHjsXx48fRtGlT+Pv757pvsuQ2VKHQhjHkQ74LXycnJ1haWuLmzZtFFubFgc3m5uY5tr/KWJPnJSYmolmzZjh+/DimT5+O/fv34+TJk9i4cSOAzMHwL8PMzAy9e/fGpk2bdGOPVq5cCXd3d4SEhOiWe/DgAbZu3QqlUqn3lzUeK7ei4MGDBwCAevXqGay/fv16g3UdHR3RuXNnpKSkoF27dqhevXq223Vzc8uxLTY2Nsc8vXr1wrfffotBgwZh586dOHHiBE6ePAlnZ+d87UdLS0uDD1eVSqX3WD948ABPnz6Fubm5wX2Ojo7W3eesnC/eFzMzMzg6OuaZBQAGDBiAY8eO4erVqwCAFStWQKVSoWfPnrplNm7ciO7du8PT0xNr167FsWPHcPLkSQwYMCDb56i7u3u+bnv+/Pl4//330aBBA2zYsAF//fUXTp48iXbt2mW7L1+8T1lj8LOWzRr/nNvMEbGxsUhPT8c333xjsG87dOgAIPfnI5C5z+7du6f7gP3555+Rmpqq90HVu3dvLF++HLdv38Ybb7wBFxcXNGjQQLdOftna2uKzzz7Djh07dEXfqyrIexAAg8c4P6+dBw8e4MKFCwb72MbGBkIIg32c3+dM1vazW97DwyPX125O8vO8efLkCYQQOd7u89myvOp7fU77OS0tDYmJiS+VKa/XUEHfb/Pzfpab9evXo2/fvvjxxx/RqFEjlClTBn369EF0dHSu67Vt2xZAZnF7+PBhaDQatG7dGm3bttUVSrt370aTJk1e+SDJvPZZQTx8+BAeHh56XzxfFBsbCzMzM9344ywKhQJubm4Gj2lur50Xr8t6fLt162bw+M6ZMwdCiByna9VqtQgODsbGjRsxduxY7NmzBydOnNB1FLxsHREbGws3NzeDotDFxQVmZmZ5PoeBzMfkZW8/J3FxcXj69KluPLeDg0Ouj1tWtuzeg5KSkpCWllasM/Tk+xBGU1NTtGnTBtu3b8fdu3fzNfWSSqUyGIAN5F48vYysN5cXbys/PUl79+7F/fv3sX//fl0vL4Bs59grqP79++OLL77AL7/8gh49emDLli0YMWKEXs+ck5MTatSogRkzZmS7jaw36ew4OTkBAH7//XfdN8vchIWFYfHixahfvz42bdqEDRs2GHzrBZDtG2tWW05FY1xcHLZt24bJkydj3LhxuvbU1NRCnds568CTnAbCZ33bzcoZHR0NT09P3fXp6en5fv717NkTo0aNwsqVKzFjxgysWbMGXbp00et9W7t2Lfz9/bF+/Xq9N6fsnvdA/r/Vrl27Fi1btsTixYv12hMSEvK1/ouyPihy67F3cHDQ9Yh98MEH2S7j7++f6+2EhITAw8MDK1asQEhICFasWIEGDRoYHK3cv39/9O/fH0lJSTh48CAmT56M1157DdeuXcvXcznL+++/j4ULF+KTTz7B+++/b3C9Wq3O9mCbl+1lzkt+XjtOTk6wsLDA8uXLs91G1us6S36fM1nbj4qKMnh/vn//vsF28yO/zxsTExNERUUZXJd1cNjL3HZuctrP5ubmul9eCjtTQd9vX5WTkxMWLFiABQsWIDIyElu2bMG4ceMQExOT64FAXl5eqFixInbv3g0/Pz/UrVsX9vb2aNOmDYYOHYrjx4/jr7/+0k1VVlI4Ozvj8OHD0Gq1ORZRjo6OSE9Px8OHD/WKXyEEoqOjUa9ePb3lC9LDmPX4fvPNNznOsvP8L6HPu3TpEs6fP4+VK1eib9++uvasA+ZelqOjI44fPw4hhF7emJgYpKenF/rrKjfXrl3D+vXr8csvv+DKlSsoX748evbsiV69eqFy5cp5rl+9enX88ssviI6O1vvievHiRQBAtWrViiz7iwo01GH8+PEQQuDdd99FWlqawfUajQZbt27VXfbz88OFCxf0ltm7dy8SExNfMm72so7OfvG2tmzZkue6WU+mF2ep+P777w2WLei32YCAADRo0AArVqzAunXrkJqaanBE42uvvYZLly6hXLlyqFu3rsFfboVvSEgIzMzMcOPGjWzXrVu3rm7ZqKgovPPOO2jRogWOHj2Kzp07Y+DAgdn24O/Zs0f37RfIPCp//fr1KFeuXI5feBQKBYQQBvvxxx9/REZGRr72V3689tpriI2NRUZGRrb3t1KlSgD+m3fyp59+0lv/119/zfdsGQ4ODujSpQtWr16Nbdu2ITo62uBnOIVCAXNzc703pejo6GxndSgIhUJhsC8vXLiAY8eOvdT2KlasiHLlymH58uU5FuWWlpZo1aoVzp49ixo1amS7f/PqLc8qnDdv3oxDhw7h1KlTuf50aWVlhfbt22PChAlIS0vD5cuXC3S/zM3NMX36dJw8eVLvSPYsfn5+uHbtmt59jo2N1TtKvDBdvnwZ58+f12tbt24dbGxsUKdOHQCZz+EbN27A0dEx2338/GwTBdG6dWsAmV+annfy5EmEh4ejTZs2Bd5mfp43VlZWaNCgATZu3Kj33qjVarF27VpdIVaYXjzCPCEhAVu3bkWzZs1gampaJJkK8n6bX/n9TPHx8cGwYcMQFBSkGzKTm7Zt22Lv3r0ICwtDUFAQgMzH0sfHB5MmTYJGo9H1DL9qtsLSvn17pKSk5DoLU9Zz+MXn+IYNG5CUlPRSz/EsTZo0gb29Pa5cuZLj45v1y8SLiqqOaNOmDRITE7F582a99tWrV+uuL0oxMTGYM2cOateujUqVKmHJkiUIDg7GiRMn8Pfff2PatGn5KnoB4H//+x8UCoXBrDQrV66EhYUF2rVrVxR3IVsFmrSuUaNGWLx4MYYOHYrAwEC8//77qFq1KjQaDc6ePYulS5eiWrVqunFNvXv3xsSJEzFp0iS0aNECV65cwbfffgs7O7tCvRNubm5o27YtZs2aBQcHB/j6+mLPnj264Qq5ady4MRwcHDBkyBBMnjwZSqUSP/30k8GHFwDd0IA5c+agffv2MDU1RY0aNXJ8MQCZP/0OHjwY9+/fR+PGjXWFWZZp06YhLCwMjRs3xvDhw1GpUiWkpKTg1q1bCA0NxZIlS3IsNv38/DBt2jRMmDAB//zzD9q1awcHBwc8ePAAJ06cgJWVFaZOnYqMjAz07NkTCoUC69atg6mpKVauXIlatWqhR48eOHz4sN59cHJyQuvWrTFx4kRYWVlh0aJFuHr1aq5Tmtna2qJ58+b44osv4OTkBD8/Pxw4cADLli0r1LNCvfXWW/jpp5/QoUMHfPTRR6hfvz6USiXu3r2Lffv24X//+x+6du2KgIAAvPPOO1iwYAGUSiXatm2LS5cuYd68eQWak3DAgAFYv349hg0bBi8vL4MPi6zpcoYOHYpu3brhzp07+Pzzz+Hu7o6///77pe/na6+9hs8//xyTJ09GixYtEBERgWnTpsHf3z/fhfuLvvvuO3Tq1AkNGzbEyJEj4ePjg8jISOzcuVP3BWHhwoVo2rQpmjVrhvfffx9+fn5ISEjA9evXsXXrVt0Yu9wMGDAAc+bMQa9evWBhYYEePXroXf/uu+/CwsICTZo0gbu7O6KjozFr1izY2dkZ9NjkR8+ePTFv3jxs377d4LrevXvj+++/xzvvvIN3330XsbGxmDt3bpGdbMbDwwOdO3fGlClT4O7ujrVr1yIsLAxz5syBpaUlAGDEiBHYsGEDmjdvjpEjR6JGjRrQarWIjIzErl27MHr0aDRo0KDAt12pUiW89957+Oabb2BiYoL27dvj1q1bmDhxIry9vTFy5MiXuk/5ed7MmjULQUFBaNWqFT7++GOYm5tj0aJFuHTpEn7++edCH79namqKoKAgjBo1ClqtFnPmzEF8fLxeL2ZhZ8rv+21B2NjYwNfXF3/88QfatGmDMmXKwMnJCQ4ODmjVqpWuN83GxgYnT57Ejh079KYFzEmbNm2waNEiPHr0CAsWLNBrX7FiBRwcHPSmMitItpf9YpaXnj17YsWKFRgyZAgiIiLQqlUraLVaHD9+HAEBAXjrrbcQFBSEkJAQfPLJJ4iPj0eTJk1w4cIFTJ48GbVr1852Csr8sra2xjfffIO+ffvi8ePH6NatG1xcXPDw4UOcP38eDx8+NPgFLkvlypVRrlw5jBs3DkIIlClTBlu3bs12+FZWHbFw4UL07dsXSqUSlSpV0hubm6VPnz747rvv0LdvX9y6dQvVq1fH4cOHMXPmTHTo0CHPLy+vKjQ0FLNnz8Ybb7yBefPmoVWrVnkOachJ1apVMXDgQEyePBmmpqaoV68edu3ahaVLl2L69Ol6Qx2mTZuGadOmYc+ePXq/xG/fvh1JSUm6Xz6vXLmC33//HUDm8RlZ77F5epkj4s6dOyf69u0rfHx8hLm5uW4qkUmTJomYmBjdcqmpqWLs2LHC29tbWFhYiBYtWohz587lOKvDi0c553Tkcd++fYWVlZVeW1RUlOjWrZsoU6aMsLOzE++88444depUvmZ1OHr0qGjUqJGwtLQUzs7OYtCgQeLMmTMG66ampopBgwYJZ2dnoVAo9I7MfPE+ZYmLi9NNJZPT0aoPHz4Uw4cPF/7+/kKpVIoyZcqIwMBAMWHCBINZF7KzefNm0apVK2FraytUKpXw9fUV3bp1002/knX0+549ewzut5mZmfjoo490bfj3qPlFixaJcuXKCaVSKSpXrix++uknvXWzm5nh7t274o033hAODg7CxsZGtGvXTly6dMlg3+Q0q8OLj6kQ2T9eGo1GzJs3T9SsWVOo1WphbW0tKleuLAYPHiz+/vtv3XKpqali9OjRwsXFRajVatGwYUNx7NixHB+r7GRkZAhvb28BQEyYMCHbZWbPni38/PyESqUSAQEB4ocffsg2d9a+zQ5eOEI1NTVVfPzxx8LT01Oo1WpRp04dsXnz5hxnI3h+uqyctimEEMeOHRPt27cXdnZ2QqVSiXLlyhnMfHHz5k0xYMAA4enpKZRKpXB2dhaNGzcW06dPz2VP6WvcuLEAIN5++22D61atWiVatWolXF1dhbm5ufDw8BDdu3fXTRGXm5z24a5duwSAbN9HVq1aJQICAoRarRZVqlQR69evz/d+zHquPj+VnxDZv2f5+vqKjh07it9//11UrVpVmJubCz8/P4OZCoTInMLns88+E5UqVRLm5ua6KeRGjhypN6NKbs+Z7GRkZIg5c+aIihUrCqVSKZycnMQ777xjMF1ZQWZ1ECJ/z5tDhw6J1q1bCysrK2FhYSEaNmwotm7dqrfMq77XZz1Oc+bMEVOnThVeXl7C3Nxc1K5dW+zcudMg96tkymnmmrzeb7PL/eL9fN7u3btF7dq1hUql0s04k5KSIoYMGSJq1KghbG1thYWFhahUqZKYPHmybnaQ3Dx58kSYmJgIKysr3VRaQvw3q83rr79usE52M6Bkl+35+/Hi45XXbAdZspvVQYjM6bsmTZokKlSoIMzNzYWjo6No3bq13jR1z549E5988onw9fUVSqVSuLu7i/fff188efJEb1tZr8cX5fSaznLgwAHRsWNHUaZMGaFUKoWnp6fo2LGj3vLZ3c8rV66IoKAgYWNjIxwcHMSbb74pIiMjs30fHj9+vPDw8BAmJiZ6+yG7xyA2NlYMGTJEuLu7CzMzM+Hr6yvGjx+vN3WbEDm/V2T3eZffWR0ePXokUlNT81wuv9LS0sTkyZN1tWPFihXF119/bbBc1vPrxeeHr6+v7n3+xb+8nnPPUwghRP5KZCoNFAoFPvjgA3z77bdSRyEi0nPr1i34+/vjiy++MDghD8lH1uO4b98+ng5ZAlkn3MrrxDXGqkRNZ0ZEREREVFRY+BIRERFRqVCgg9vI+HHkCxGVVH5+fnyPIqJXwjG+RERERFQqcKgDEREREZUKLHyJiIiIqFTgGN8SSqvV4v79+7CxsSn0yd+JiIioaAghkJCQAA8Pj5c+4QMVHRa+JdT9+/fh7e0tdQwiIiJ6CXfu3MnxzKskHRa+JVTW6Qvv3LlT6KdX1Wg02LVrF4KDg6FUKgt120VNztkBeeeXc3ZA3vnlnB2Qd345ZwfknV+u2ePj4+Ht7Z3taYhJeix8S6is4Q22trZFUvhaWlrC1tZWVm8mgLyzA/LOL+fsgLzzyzk7IO/8cs4OyDu/nLMD4DDFEoqDT4iIiIioVGDhS0RERESlAgtfIiIiIioVWPgSERERUanAwpeIiIiISgUWvkRERERUKrDwJSIiIqJSgYUvEREREZUKLHyJiIiIqFRg4UtEREREpQIL33w4ePAgOnXqBA8PDygUCmzevDnPdQ4cOIDAwECo1WqULVsWS5YsKfqgRERERJQjFr75kJSUhJo1a+Lbb7/N1/I3b95Ehw4d0KxZM5w9exaffvophg8fjg0bNhRxUiIiIiLKiZnUAeSgffv2aN++fb6XX7JkCXx8fLBgwQIAQEBAAE6dOoV58+bhjTfeyHad1NRUpKam6i7Hx8cDADQaDTQazcuHz0bW9gp7u8VBztkBeeeXc3ZA3vnlnB2Qd345ZweKP3+GViAtXYvUdC1S0zP+/Vdr2KbRPnfdf8s9/5eSpsHtOybY9/sFmJgUTT+dh50aH7UpX6jblOtzpbRQCCGE1CHkRKFQYNOmTejSpUuOyzRv3hy1a9fGwoULdW2bNm1C9+7dkZycDKVSabDOlClTMHXqVIP2devWwdLSslCyExERvUgrgNQM4FkGkJKe+e+zDMV//08HUjIUz/0feJauQEpG5v/TtYBGZP6bIRRS350C8bQUGFszo1C3mZycjF69eiEuLg62traFum16dezxLQLR0dFwdXXVa3N1dUV6ejoePXoEd3d3g3XGjx+PUaNG6S7Hx8fD29sbwcHBhf7C0Wg0CAsLQ1BQULZFeEkm5+yAvPPLOTsg7/xyzg7IO79csgshkJyWgdikNDxOSsPjZA0eJ6XhUUIKLoT/DWcPbySmapGQqkFCSvp/f6npSExNR1F0gZmZKKAyM4G5mQlUZiZQmZlm/qs0yb7d7Pl2U5iZCNy8cR0VKlSAiYlp4QcE4Ghtjg51PAt1m1m/2FLJxMK3iCgU+t96szrWX2zPolKpoFKpDNqVSmWRvdkW5baLmpyzA/LOL+fsgLzzyzk7IO/8xZ1dCIGE1HQ8Tkz7r5hNSkVsUhpiEzMvx/7blrVMaro2h62ZAPfu5Xmb5qYmsFGbwUZtBlsLZeb/VUrYWpjBRv3vZbUSts/9a602g1ppalDYmpuawMz01YYnaDQahKb8jQ4ty8vqeSOnrKURC98i4ObmhujoaL22mJgYmJmZwdHRUaJUREQkJa1W4HFyGmLiUxGTkIKYhFQ8TEjFo8TUfwvb/4rax0lpSMvIqZDNmcrMBE7WKpSxMkcZK3PYW5jhyYN7qFapPBysVP8Vr3rFrBls1UqolUXTq0pUkrDwLQKNGjXC1q1b9dp27dqFunXr8psgEZGRSUvX4mFiKmLiM4vZrIL2YULKv0VuZqH7KDENGdqCjSmwUJqijJU5nKzN/y1mVXD89/+OVub//l8Fx38LXUtzU71fFjUaDUJD76BDW3n1mhIVFRa++ZCYmIjr16/rLt+8eRPnzp1DmTJl4OPjg/Hjx+PevXtYvXo1AGDIkCH49ttvMWrUKLz77rs4duwYli1bhp9//lmqu0BERAWUosnA3cfJuB4P/HkxGrHJ6YhJSMHD+P+K25iEFDxJLthR/I5W5nC2UcHFVg1naxWcbMz/LVwzi9qsItbRSgULc/bCEhUmFr75cOrUKbRq1Up3OesgtL59+2LlypWIiopCZGSk7np/f3+EhoZi5MiR+O677+Dh4YGvv/46x6nMiIioeKVoMvAgPgX3n6YgOv5Z5r9xKYiKe4aouBRExaXgcVLav0ubAZcv5Lo9pakCztYqONuq4WKjyixsbVRwscm87GKb2eZkrYLyFce+EtHLY+GbDy1btkRus76tXLnSoK1FixY4c+ZMEaYiIqLs5FXURselIFZX1OZOrTSBjWkG/NzKwNVWDRcb9X9Fre1/ha2dhRImJvKayouoNGLhS0REspKclo7bscm4HZuMyMdJuPM4q5f2WYGLWg87C7jZqeFuZwF3OzXc7dWZ//572dIM2L59Ozp0qMcxskRGgIUvERGVKEIIPE5Kw+3HyYj8t8C9/Tgp8/+Pk/EwITXPbajMTOBhn1m8utmpdQWuh70abrYW8LBXw85CmeMUk1l4Fi4i48LCl4iIil2GViAq7pmumM3qvb0dm1nsJqSm57q+nYUSvo6W8CmT+ZdV5Gb11Npb5l3UElHpw8KXiIiKhBACUXEpuHzvCfZHKXDqz6u4++QZbj9Oxt3Hz/Kcp9bNVg0fR0v4lrHMLHIdrXT/t7c0L6Z7QUTGhIUvERG9stT0DFyPScSV+/EIj0pAeFQ8wqPj8VQ31ZcpcCtSbx2lqQJeDpk9tlm9t36OVvB1tIR3GUueUIGICh0LXyIiKpDYxFRdcXslKh7hUfG4HpOI9GxOzmBqokBZJ0tYpCegfpWyKOtsoytyPewtYMqZEIioGLHwJSKibGVoBW4+SsSVrB7cqHhcuR+PmBwOLrNVmyHA3RZVPGwz/3W3RXkXa5hCi9DQUHQIqciZEYhIUix8iYgICSkaXI1O+HeoQuZfxIMEpGiyH4fr52iJAPf/CtwAD1t42KmzPaBMk8M2iIiKGwtfIqJSJj5Fg0v34nDxbhwu/Ptv5OPkbJe1UJqikpvNc724NqjkZgtrFT8+iEh++M5FRGTEklLTcfl+PC7cfYqL/xa5/zxKynZZdzv1v724NqjibocAdxv4OlpxHC4RGQ0WvkRERuJZWgauRMXj4t2nup7c6w8Tkd0Z1z3tLVDDyw7VvexQw9MeVT1s4WDFKcKIyLix8CUikqEUTQauRidkFrl343DxXhz+jklERjYzK7jbqVHd0w41vOxQzdMO1T3t4GitkiA1EZG0WPgSEZVwmgwt7iQCv5y8iyvRCbhwNw4R0QnZTh/mZK1Czaye3H8LXRcbtQSpiYhKHha+REQlUHyKBgciHmJ3+APsuxqD+BQz4OIVvWXKWJnrenIz/7WHq62Kp+olIsoBC18iohLi7pNk7AmPwe7wB/jrn1hoMv7r0bUwFajj54Sa3vb/js21z3H6MCIiyh4LXyIiiQghcOlePMLCH2D3lQe4EhWvd305Zyu0reKKVhUcEXXpGF7rGMgTQBARvQIWvkRExSg1PQPHbsRid/gD7L4Sg+j4FN11Jgqgrm8ZtK3igrYBrijrbA0A0Gg0CL0sVWIiIuPBwpeIqIg9TU7D3quZQxgORDxEUlqG7jpLc1M0r+CMtlVc0bqyC8pwSjEioiLDwpeIqAjcepSE3eEPEHblAU7dfqI3zZiLjQptq7giKMAVjco5Qq00lTApEVHpwcKXiKgQaLUCZ+88/XcIwwP8HZOod31lNxsEVXFF2wBXVPe0gwnPhkZEVOxY+BIRvaQUTeZ43Z2Xo7E7PAaPElN115mZKNCgbBm0Dcgsdr3LWEqYlIiIABa+REQFEvdMg/0RMdh1+QH2R8Tojde1UZmhZWUXBFVxRYuKzrCz4AwMREQlCQtfIqI8RMelIOxKNHZdeYBjN2L1zpjmZqtGcFVXBFVxRQN/R5ibmUiYlIiIcsPCl4joBUII3HiYiJ2XH2DXlQc4f+ep3vUVXKwRUtUNwVUzx+vyJBJERPLAwpeICP8dnLbrSjTCLj/AP4+SdNcpFEAdHwcEV8ns2c2aX5eIiOSFhS8RlVpZJ5PYefkBdoc/wMOE/w5OMzc1QePyjgip6oY2AS5wsVFLmJSIiAoDC18iKlUSUjQ4fOUhdl2Oxv6Ih0hMTdddZ6MyQ6vKLgiumnlwmo2aB6cRERkTFr5EZPTS0rX47dRdrLligo9P7IcmQ/9kEkFVXBFS1Q0Ny/LgNCIiY8bCl4iM2ombjzFh08V/TyhhAkCgnLMVgqu6IbiKK2p62fNkEkREpQQLXyIySo+T0jArNBy/nb4LAChjpURjxxQM69IclT3spQ1HRESSYOFLREZFqxX4/cxdzAoNx5NkDQCgZ30fjGpTDkf3h6Gcs5XECYmISCosfInIaFx7kIDPNl3CiVuPAQCV3Wwwo2t1BPo6QKPRSJyOiIikxsKXiGTvWVoGvt77N344+A/StQIWSlOMCqqIfk38oDTlwWpERJSJhS8Rydq+qzGY+Mcl3H3yDAAQVMUVUzpXhae9hcTJiIiopGHhS0SyFBX3DNO2XsH2S9EAAA87NaZ0rorgqm4SJyMiopKKhS8RyUp6hharjt3G/F0RSErLgKmJAoOa+mN4mwqwUvEtjYiIcsZPCSKSjXN3nmLCpou4fD8eAFDHxx4zulZHgLutxMmIiEgOeNRHPi1atAj+/v5Qq9UIDAzEoUOHcl3+u+++Q0BAACwsLFCpUiWsXr26mJISGZ+4ZxpM3HwJXRcdweX78bCzUGLW69Xx+5DGLHqJiCjf2OObD+vXr8eIESOwaNEiNGnSBN9//z3at2+PK1euwMfHx2D5xYsXY/z48fjhhx9Qr149nDhxAu+++y4cHBzQqVMnCe4BkTwJIbDl/H18vi0cjxJTAQCv1/bEpx0D4GStkjgdERHJDQvffJg/fz4GDhyIQYMGAQAWLFiAnTt3YvHixZg1a5bB8mvWrMHgwYPRo0cPAEDZsmXx119/Yc6cOSx8ifLp5qMkTPrjEg79/QgAUNbZCtO7VEPjck4SJyMiIrli4ZuHtLQ0nD59GuPGjdNrDw4OxtGjR7NdJzU1FWq1Wq/NwsICJ06cgEajgVKpzHad1NRU3eX4+MwxjBqNptAn3s/anhwn9JdzdkDe+Ysre2q6FksP3cSSgzeRlq6FuZkJhrYoi0FN/aAyM3np2+e+l46c88s5OyDv/HLNLre8pY1CCCGkDlGS3b9/H56enjhy5AgaN26sa585cyZWrVqFiIgIg3U+/fRTrFixAtu2bUOdOnVw+vRpdOzYETExMbh//z7c3d0N1pkyZQqmTp1q0L5u3TpYWloW7p0iKqGuxSnw2z8miElRAAAq22nRzV8LZ07JS0QykZycjF69eiEuLg62tjwGoaRhj28+KRQKvctCCIO2LBMnTkR0dDQaNmwIIQRcXV3Rr18/zJ07F6amptmuM378eIwaNUp3OT4+Ht7e3ggODi70F45Go0FYWBiCgoKy7X0uyeScHZB3/qLMnpquxeStV7Dhyn0AgLO1OSZ0qIwO1VxzfJ0VFPe9dOScX87ZAXnnl2v2rF9sqWRi4ZsHJycnmJqaIjo6Wq89JiYGrq6u2a5jYWGB5cuX4/vvv8eDBw/g7u6OpUuXwsbGBk5O2Y9PVKlUUKkMD9ZRKpVF9oIvym0XNTlnB+Sdv7CzJ6am4721Z3H0RiwUCqBPQ1+MDqkEWzWf9y+Sc3ZA3vnlnB2Qd365ZZdT1tKI05nlwdzcHIGBgQgLC9NrDwsL0xv6kB2lUgkvLy+Ympril19+wWuvvQYTE+5yoiyxiano9cNfOHojFlbmplg7sAGm/q9akRW9RERUurHHNx9GjRqF3r17o27dumjUqBGWLl2KyMhIDBkyBEDmMIV79+7p5uq9du0aTpw4gQYNGuDJkyeYP38+Ll26hFWrVkl5N4hKlHtPn6H3suP452ESyliZY2X/eqjhZS91LCIiMmIsfPOhR48eiI2NxbRp0xAVFYVq1aohNDQUvr6+AICoqChERkbqls/IyMCXX36JiIgIKJVKtGrVCkePHoWfn59E94CoZPn7QQJ6LzuB6PgUeNipsWZQA5RztpY6FhERGTkWvvk0dOhQDB06NNvrVq5cqXc5ICAAZ8+eLYZURPJzNvIJ+q88iafJGpR3scbqAfXhYc9pG4iIqOix8CWiYnPo74cYvOY0ktMyUNPbHiv71YODlbnUsYiIqJRg4UtExWLbhfsYuf4cNBkCzSo4Yck7gbBS8S2IiIiKDz91iKjIrfnrNib9cQlCAB1ruGN+95pQmWU/pzUREVFRYeFLREVGCIFv917Hl2HXAABvN/DBtP9Vg6lJ4ZyUgoiIqCBY+BJRkdBqBT7/8wpWHLkFABjeujxGBlUstDOxERERFRQLXyIqdJoMLcb+fgGbzt4DAEx6rQoGNPWXOBUREZV2Rn8asevXr2Pnzp149uwZgMyfXomo6DxLy8DgNaex6ew9mJoo8FWPmix6iYioRDDawjc2NhZt27ZFxYoV0aFDB0RFRQEABg0ahNGjR0ucjsg4xSVr0HvZcey9GgOVmQl+6BOIrrW9pI5FREQEwIgL35EjR8LMzAyRkZGwtLTUtffo0QM7duyQMBmRcYqJT0GPpcdw6vYT2KrNsHZQA7Su7Cp1LCIiIh2jHeO7a9cu7Ny5E15e+r1NFSpUwO3btyVKRWScbscm4Z1lx3Hn8TM426iwekB9BLjbSh2LiIhIj9EWvklJSXo9vVkePXoElUolQSIi43Tlfjz6LD+BR4mp8CljibUDG8DH0fC1R0REJDWjHerQvHlzrF69WndZoVBAq9Xiiy++QKtWrSRMRmQ8Ttx8jB5Lj+FRYioC3G3x+/uNWPQSEVGJZbQ9vl988QVatmyJU6dOIS0tDWPHjsXly5fx+PFjHDlyROp4RLK3+8oDfLDuDFLTtajn54Af+9aDnYVS6lhEREQ5Mtoe3ypVquDChQuoX78+goKCkJSUhNdffx1nz55FuXLlpI5HJGsbTt/F4LWnkZquRZvKLlg9oAGLXiIiKvGMtscXANzc3DB16lSpYxAZlRVHb2Pm9ggAwOu1PTGnWw0oTY32OzQRERkRoy18V6xYAWtra7z55pt67b/99huSk5PRt29fiZIRyZMQAtsiTRB2LLPoHdjUHxM6BMDEhKcgJiIieTDabprZs2fDycnJoN3FxQUzZ86UIBGRfGVoBSZtDUfYvcy3jDEhlfBZRxa9REQkL0bb43v79m34+xueJtXX1xeRkZESJCKSJ02GFqN/PY8t5+9DAYFpnauid2OegpiIiOTHaHt8XVxccOHCBYP28+fPw9HRUYJERPKTosnA+2tPY8v5+zAzUaBPBS3eqsdTEBMRkTwZbeH71ltvYfjw4di3bx8yMjKQkZGBvXv34qOPPsJbb70ldTyiEi8pNR0DVp7E7vAYqMxMsKhXLdRxElLHIiIiemlGO9Rh+vTpuH37Ntq0aQMzs8y7qdVq0adPH47xJcpDXLIG/VaewNnIp7AyN8WPfeuhro8tQm9InYyIiOjlGW3ha25ujvXr1+Pzzz/H+fPnYWFhgerVq8PX11fqaEQl2sOEVPRedhxXoxNgZ6HEqgH1UcvbHhqNRupoREREr8RoC98sFStWRMWKFaWOQSQL954+Q+8fj+OfR0lwslZh7aD6qOxmK3UsIiKiQmG0hW9GRgZWrlyJPXv2ICYmBlqtVu/6vXv3SpSMqGS6+SgJ7/x4HPeePoOnvQXWDmoAfycrqWMREREVGqMtfD/66COsXLkSHTt2RLVq1aBQcL5RopxcjY7HOz+ewKPEVJR1ssKaQQ3gaW8hdSwiIqJCZbSF7y+//IJff/0VHTp0kDoKUYl27s5T9F1+AnHPNAhwt8XqAfXhbKOSOhYREVGhM9rC19zcHOXLl5c6BlGJduxGLAatOomktAzU9rHHyn71YWeplDoWERFRkTDaeXxHjx6NhQsXQgjOO0qUnb1XH6DfihNISstA43KOWDuwAYteIiIyakbb43v48GHs27cP27dvR9WqVaFU6n+gb9y4UaJkRNLbev4+Rq4/h3StQNsAF3zbqw7USlOpYxERERUpoy187e3t0bVrV6ljEJU4609GYtzGixAC6FzTA192rwmlqdH++ENERKRjtIXvihUrpI5AVOL8eOgfTP8zHADQs74PpnepBlMTznhCRESlg9EWvkT0HyEEFu75Gwt2/w0AeK95WYxvX5nT/BERUali1IXv77//jl9//RWRkZFIS0vTu+7MmTMSpSIqXkIIzPgzHD8evgkAGB1UEcNal2fRS0REpY7RDuz7+uuv0b9/f7i4uODs2bOoX78+HB0d8c8//6B9+/ZSxyMqFhlagfEbL+qK3kmvVcGHbSqw6CUiolLJaAvfRYsWYenSpfj2229hbm6OsWPHIiwsDMOHD0dcXJzU8YiKnCZDi49+OYtfTt6BiQKY+0YNDGjqL3UsIiIiyRht4RsZGYnGjRsDACwsLJCQkAAA6N27N37++WcpoxEVuRRNBoasOY1tF6KgNFXgm5510L2et9SxiIiIJGW0ha+bmxtiY2MBAL6+vvjrr78AADdv3uRJLcioJaamo/+Kk9hzNQYqMxMs7VMXHWu4Sx2LiIhIckZb+LZu3Rpbt24FAAwcOBAjR45EUFAQevTowfl9yWg9TU7D2z8ex7F/YmGtMsOqAfXRqpKL1LGIiIhKBKMtfJcuXYoJEyYAAIYMGYKVK1ciICAAU6dOxeLFiwu8vUWLFsHf3x9qtRqBgYE4dOhQrsv/9NNPqFmzJiwtLeHu7o7+/fvreqCJisLDhFS8tfQvnL/zFPaWSvw0qAEalnWUOhYREVGJYbSFr4mJCczM/putrXv37vj6668xfPhwmJubF2hb69evx4gRIzBhwgScPXsWzZo1Q/v27REZGZnt8ocPH0afPn0wcOBAXL58Gb/99htOnjyJQYMGvdJ9IspJiiYDg1afwtXoBDjbqLD+vUao6W0vdSwiIqISxajm8b1w4QKqVasGExMTXLhwIddla9Soke/tzp8/HwMHDtQVrgsWLMDOnTuxePFizJo1y2D5v/76C35+fhg+fDgAwN/fH4MHD8bcuXNzvI3U1FSkpqbqLsfHxwMANBoNNBpNvrPmR9b2Cnu7xUHO2YGiyS+EwOjfLuL8naewszDDTwPqwt9RzefNC+ScX87ZAXnnl3N2QN755ZpdbnlLG4UwoiO9TExMEB0dDRcXF5iYmEChUGR7IJtCoUBGRka+tpmWlgZLS0v89ttvemODP/roI5w7dw4HDhwwWOfo0aNo1aoVNm3ahPbt2yMmJgbdu3dHQEAAlixZku3tTJkyBVOnTjVoX7duHSwtLfOVlUqnHXcU2H7XFCYKgaEBWlSwM5qXNBGR7CQnJ6NXr16Ii4uDra2t1HHoBUbV43vz5k04Ozvr/l8YHj16hIyMDLi6uuq1u7q6Ijo6Ott1GjdujJ9++gk9evRASkoK0tPT0blzZ3zzzTc53s748eMxatQo3eX4+Hh4e3sjODi40F84Go0GYWFhCAoKglKpLNRtFzU5ZwcKP3/oxWhsP5b568bnnauie12vV95mTrjvpSPn7IC888s5OyDv/HLNnvWLLZVMRlX4+vr6Ash8sUyZMgUTJ05E2bJlC2XbL57pSgiR49mvrly5guHDh2PSpEkICQlBVFQUxowZgyFDhmDZsmXZrqNSqaBSqQzalUplkb3gi3LbRU3O2YHCyX/+zlOM3XgJADCwqT/eblQ8J6fgvpeOnLMD8s4v5+yAvPPLLbucspZGRnlwm1KpxKZNmwplW05OTjA1NTXo3Y2JiTHoBc4ya9YsNGnSBGPGjEGNGjUQEhKCRYsWYfny5YiKiiqUXFS6RcU9w7urTyE1XYtWlZzxaYcAqSMRERGVeEZZ+AJA165dsXnz5lfejrm5OQIDAxEWFqbXHhYWpjsz3IuSk5NhYqK/a01NTQGAJ8+gV5aclo53V59CTEIqKrpa4+uetWFqkv2vD0RERPQfoxrq8Lzy5cvj888/x9GjRxEYGAgrKyu967NmXMiPUaNGoXfv3qhbty4aNWqEpUuXIjIyEkOGDAGQOT733r17WL16NQCgU6dOePfdd7F48WLdUIcRI0agfv368PDwKLw7SaWOViswav15XLoXjzJW5ljWtx5s1PxZjYiIKD+MtvD98ccfYW9vj9OnT+P06dN61ykUigIVvj169EBsbCymTZuGqKgoVKtWDaGhoboxxVFRUXpz+vbr1w8JCQn49ttvMXr0aNjb26N169aYM2dO4dw5KrXmh13DjsvRMDc1wfe9A+FdhjN+EBER5ZfRFr6FNatDlqFDh2Lo0KHZXrdy5UqDtg8//BAffvhhoWag0m3z2Xv4dt91AMCs16ujnl8ZiRMRERHJi9GO8SUyJqdvP8HYDZnTlr3fshzeCCy6acuIiIiMldH2+ALA3bt3sWXLFkRGRiItLU3vuvnz50uUiqhg7j5JxuA1p5CWrkVwFVeMCa4kdSQiIiJZMtrCd8+ePejcuTP8/f0RERGBatWq4datWxBCoE6dOlLHI8qXxNR0DFp1Co8S0xDgbouvetSCCWdwICIieilGO9Rh/PjxGD16NC5dugS1Wo0NGzbgzp07aNGiBd58802p4xHlKUMr8NHPZ3E1OgFO1ios61sXViqj/a5KRERU5Iy28A0PD0ffvn0BAGZmZnj27Bmsra0xbdo0zq5AsjB3x1XsuRoDczMT/NAnEB72FlJHIiIikjWjLXytrKyQmpoKAPDw8MCNGzd01z169EiqWET58uupO/j+4D8AgHlv1kRtHweJExEREcmf0f5u2rBhQxw5cgRVqlRBx44dMXr0aFy8eBEbN25Ew4YNpY5HlKPj/8RiwqaLAIDhbSqgc02e9ISIiKgwGG3hO3/+fCQmJgIApkyZgsTERKxfvx7ly5fHV199JXE6ouxFxiZjyNrT0GQIdKzujhFtKkgdiYiIyGgYbeFbtmxZ3f8tLS2xaNEiCdMQ5S0+RYMBq07iSbIGNbzsMO/NmpzBgYiIqBAZ7Rjf/v37Y8+ePRBCSB2FKE/pGVoMW3cW12MS4Warxg996sLC3FTqWEREREbFaAvf2NhYdOzYEV5eXhg9ejTOnTsndSSiHM0IDcfBaw+hVprgx7514WqrljoSERGR0THawnfLli2Ijo7G5MmTcfr0aQQGBqJKlSqYOXMmbt26JXU8Ip2fjt/GiiO3AABfda+Fap520gYiIiIyUkZb+AKAvb093nvvPezfvx+3b99G//79sWbNGpQvX17qaEQAgKPXH2HSH5cBAB8HV0T76u4SJyIiIjJeRl34ZtFoNDh16hSOHz+OW7duwdXVVepIRPjnYSKGrD2NDK1Al1oe+KAVv5AREREVJaMufPft24d3330Xrq6u6Nu3L2xsbLB161bcuXNH6mhUysU902DgqlOIT0lHHR97zH6jBhQKzuBARERUlIx2OjMvLy/ExsYiJCQE33//PTp16gS1mgcMkfQytMDwX87j5qMkeNpb4PvedaFWcgYHIiKioma0he+kSZPw5ptvwsGBp3qlkkMIgQ23THD0wWNYmpvix7514WyjkjoWERFRqWC0he97770ndQQiA2uO38GRByZQKICv36qNAHdbqSMRERGVGkY9xpeoJDl16zFmhF4FAIwNroi2VXiQJRERUXFi4UtUDJ6lZeDj385DK4BAJy0GNvGVOhIREVGpw8KXqBh8sTMCt2KT4WqrQjd/LWdwICIikgALX6IiduLmY6w4ehMAMLNLVVga7ch6IiKiks2oPoK3bNmS72U7d+5chEmIMiWnpWPM7+chBNCjrjeaV3BC6N9SpyIiIiqdjKrw7dKli95lhUIBIYTe5SwZGRnFFYtKsbk7InA7NhkedmpMeC1A6jhERESlmlENddBqtbq/Xbt2oVatWti+fTuePn2KuLg4hIaGok6dOtixY4fUUakU+OufWKw8egsAMPuNGrBVK6UNREREVMoZVY/v80aMGIElS5agadOmuraQkBBYWlrivffeQ3h4uITpyNglpaZj7O8XAAA96/ugeUVniRMRERGRUfX4Pu/GjRuws7MzaLezs8OtW7eKPxCVKnN2XEXk42R42lvg0w6VpY5DREREMOLCt169ehgxYgSioqJ0bdHR0Rg9ejTq168vYTIydkdvPMLqY7cBAHPeqAEbDnEgIiIqEYy28F2+fDliYmLg6+uL8uXLo3z58vDx8UFUVBSWLVsmdTwyUs8PcXi7gQ+aVnCSOBERERFlMdoxvuXLl8eFCxcQFhaGq1evQgiBKlWqoG3btjx5ABWZWdvDcffJM3jaW2B8B87iQEREVJIYbeELZE5fFhwcjObNm0OlUrHgpSJ15PojrP0rEgDwRbcasFYZ9cuLiIhIdox2qINWq8Xnn38OT09PWFtb4+bNzDNnTZw4kUMdqNAlpGh0Qxx6N/RF4/Ic4kBERFTSGG3hO336dKxcuRJz586Fubm5rr169er48ccfJUxGxmhm6FXce/oM3mUsMK49Z3EgIiIqiYy28F29ejWWLl2Kt99+G6amprr2GjVq4OrVqxImI2Nz8NpD/Hwic4jD3DdqwopDHIiIiEokoy187927h/Llyxu0a7VaaDQaCRKRMYpP0WDchswhDn0b+aJROUeJExEREVFOjLbwrVq1Kg4dOmTQ/ttvv6F27doSJCJjNPPPcNyPS4FPGUt8wiEOREREJZrR/iY7efJk9O7dG/fu3YNWq8XGjRsRERGB1atXY9u2bVLHIyNw4NpD/HLyDoDMWRwszY325URERGQUjLbHt1OnTli/fj1CQ0OhUCgwadIkhIeHY+vWrQgKCirw9hYtWgR/f3+o1WoEBgZm25ucpV+/flAoFAZ/VatWfZW7RCXI80Mc+jfxQ4OyHOJARERU0hl1F1VISAhCQkJeeTvr16/HiBEjsGjRIjRp0gTff/892rdvjytXrsDHx8dg+YULF2L27Nm6y+np6ahZsybefPPNV85CJcP0bVcQFZcCP0dLjA3hEAciIiI5MOrCFwDS0tIQExMDrVar155dwZqT+fPnY+DAgRg0aBAAYMGCBdi5cycWL16MWbNmGSxvZ2cHOzs73eXNmzfjyZMn6N+//0veCypJ9l2Nwa+n7kKhAL54syYszE3zXomIiIgkZ7SF799//40BAwbg6NGjeu1CCCgUCmRkZORrO2lpaTh9+jTGjRun1x4cHGyw7ZwsW7YMbdu2ha+vb47LpKamIjU1VXc5Pj4eAKDRaAp9Foqs7clxdgups8c9+2+IQ79GvqjlaVOgLFLnfxVyzg7IO7+cswPyzi/n7IC888s1u9zyljYKIYSQOkRRaNKkCczMzDBu3Di4u7sbnK64Zs2a+drO/fv34enpiSNHjqBx48a69pkzZ2LVqlWIiIjIdf2oqCh4e3tj3bp16N69e47LTZkyBVOnTjVoX7duHSwtLfOVlYreT9dNcOKhCVzUAmNqZICdvURE9Lzk5GT06tULcXFxsLW1lToOvcBoe3zPnTuH06dPo3Llwhl/+WLhnNVznJeVK1fC3t4eXbp0yXW58ePHY9SoUbrL8fHx8Pb2RnBwcKG/cDQaDcLCwhAUFASlUlmo2y5qUmbfG/EQJ46dhUIBfNO7Aer42Bd4G9z30pFzfjlnB+SdX87ZAXnnl2v2rF9sqWQy2sK3SpUqePTo0Stvx8nJCaampoiOjtZrj4mJgaura67rCiGwfPly9O7dW++0ydlRqVRQqVQG7Uqlsshe8EW57aJW3NnjkjWY+McVAMCgpv5oUM75lbbHfS8dOeeXc3ZA3vnlnB2Qd365ZZdT1tLIaKczmzNnDsaOHYv9+/cjNjYW8fHxen/5ZW5ujsDAQISFhem1h4WF6Q19yM6BAwdw/fp1DBw48KXuA5UcU7deRkxCKso6W2F0cCWp4xAREdFLMNoe37Zt2wIA2rRpo9de0IPbAGDUqFHo3bs36tati0aNGmHp0qWIjIzEkCFDAGQOU7h37x5Wr16tt96yZcvQoEEDVKtW7RXvDUkp7MoDbDx7DyYKYN6bNaFWcmAvERGRHBlt4btv375C21aPHj0QGxuLadOmISoqCtWqVUNoaKhuloaoqChERkbqrRMXF4cNGzZg4cKFhZaDit+TpDR8uukiAODd5mVRx8dB4kRERET0soy28G3RokWhbm/o0KEYOnRottetXLnSoM3Ozg7JycmFmoGK35Stl/EwIRXlXawxsm1FqeMQERHRKzCqwvfChQuoVq0aTExMcOHChVyXrVGjRjGlIrnaeTkaf5y7zyEORERERsKoCt9atWohOjoaLi4uqFWrFhQKBbKbprigY3yp9HmclIYJ/w5xGNyiHGp520sbiIiIiF6ZURW+N2/ehLOzs+7/RC9r8pbLeJSYhoqu1hjRtoLUcYiIiKgQGFXh+/wpgXM7PTBRbrZfjMLW8/dhaqLAvDdrQmXGIQ5ERETGwKgK3+xcuXIFkZGRSEtL02vv3LmzRImoJItNTMVnmy8BAIa0KIsaXvbSBiIiIqJCY7SF7z///IOuXbvi4sWLemN9s04zzDG+lJ3JWy4jNikNlVxtMLwNhzgQEREZE6M9c9tHH30Ef39/PHjwAJaWlrh8+TIOHjyIunXrYv/+/VLHoxLo1K3H2HYhikMciIiIjJTR9vgeO3YMe/fuhbOzM0xMTGBiYoKmTZti1qxZGD58OM6ePSt1RCpBhBCYs+MqAKB7XS9U97KTOBEREREVNqPt8c3IyIC1tTUAwMnJCffv3weQedBbRESElNGoBNof8RAnbz2BysyEQxyIiIiMlNH2+FarVg0XLlxA2bJl0aBBA8ydOxfm5uZYunQpypYtK3U8KkG0WoG5OzO/DPVt7Ad3OwuJExEREVFRMNrC97PPPkNSUhIAYPr06XjttdfQrFkzODo6Yv369RKno5Jk64X7CI+Kh43KDO+3KCd1HCIiIioiRlv4hoSE6P5ftmxZXLlyBY8fP4aDg4NuZgciTYYW88OuAQDea14WDlbmEiciIiKiomK0hW92ypQpI3UEKmHWn7yD27HJcLI2x4Cm/lLHISIioiJkVIXv66+/nu9lN27cWIRJSA6epWXg6z1/AwCGtSoPK5VRvRyIiIjoBUb1SW9nxymoKP9WHr2FmIRUeNpboGcDH6njEBERUREzqsJ3xYoVUkcgmYhL1mDx/usAgFFBFXmyCiIiolLAqArf7MTExCAiIgIKhQIVK1aEi4uL1JGoBPj+4A3Ep6Sjoqs1utT2lDoOERERFQOjPYFFfHw8evfuDU9PT7Ro0QLNmzeHp6cn3nnnHcTFxUkdjyQUk5CCFUduAQA+Dq4EUxPO8kFERFQaGG3hO2jQIBw/fhzbtm3D06dPERcXh23btuHUqVN49913pY5HEvp273U802Sgto89gqq4Sh2HiIiIionRDnX4888/sXPnTjRt2lTXFhISgh9++AHt2rWTMBlJKTI2GeuORwIAxoZU5pzOREREpYjR9vg6OjpmO8uDnZ0dHBwcJEhEJcFXu68hXSvQrIITGpVzlDoOERERFSOjLXw/++wzjBo1ClFRUbq26OhojBkzBhMnTpQwGUnlanQ8Np+7ByCzt5eIiIhKF6Md6rB48WJcv34dvr6+8PHJnKM1MjISKpUKDx8+xPfff69b9syZM1LFpGI0b2cEhAA6VndHdS/O+UxERFTaGG3h26VLF6kjUAly6tZj7A6PgamJAqOCK0odh4iIiCRgtIXv5MmTpY5AJYQQAnN3RAAA3gz0Qjlna4kTERERkRSMdozv7t27c7zu+WEOZPz2X3uIE7cew9zMBB+1rSB1HCIiIpKI0Ra+HTt2xOjRo5GWlqZre/jwITp16oTx48dLmIyKk1Yr8MW/vb19G/nC3c5C4kREREQkFaMtfA8ePIitW7eiXr16uHz5Mv78809Uq1YNiYmJOH/+vNTxqJhsuxiFK1HxsFGZYWjL8lLHISIiIgkZbeHboEEDnD17FjVq1EBgYCC6du2K0aNHY+/evfD29pY6HhUDTYYW83dl9va+27wsHKzMJU5EREREUjLawhcAIiIicPLkSXh5ecHMzAxXr15FcnKy1LGomPx66g5uxSbD0cocA5v6Sx2HiIiIJGa0he/s2bPRqFEjBAUF4dKlSzh58qSuB/jYsWNSx6Mi9iwtA1/v+RsAMKx1eVipjHYCEyIiIsonoy18Fy5ciM2bN+Obb76BWq1G1apVceLECbz++uto2bKl1PGoiK06dgsP4lPhaW+BXg18pI5DREREJYDRdoNdvHgRTk5Oem1KpRJffPEFXnvtNYlSUXGIe6bB4v03AAAjgypCZWYqcSIiIiIqCYy2x9fJyQlPnz7Fjz/+iPHjx+Px48cAMk9PXL48j+43ZksP3kDcMw0quFija21PqeMQERFRCWG0Pb4XLlxA27ZtYWdnh1u3buHdd99FmTJlsGnTJty+fRurV6+WOiIVgZiEFCw/fAsA8HFIJZiaKKQNRERERCWG0fb4jho1Cv369cPff/8NtVqta2/fvj0OHjwoYTIqSt/tvY5nmgzU8rZHcBVXqeMQERFRCWK0he/JkycxePBgg3ZPT09ER0dLkIiK2p3HyVh3IhIAMLZdJSgU7O0lIiKi/xht4atWqxEfH2/QHhERAWdnZwkSUVH7KuwaNBkCzSo4oXE5p7xXICIiolLFaAvf//3vf5g2bRo0Gg0AQKFQIDIyEuPGjcMbb7xR4O0tWrQI/v7+UKvVCAwMxKFDh3JdPjU1FRMmTICvry9UKhXKlSuH5cuXv9R9obxdjY7HpnP3AABjQipJnIaIiIhKIqMtfOfNm4eHDx/CxcUFz549Q4sWLVC+fHnY2NhgxowZBdrW+vXrMWLECEyYMAFnz55Fs2bN0L59e0RGRua4Tvfu3bFnzx4sW7YMERER+Pnnn1G5cuVXvVuUg3k7r0EIoEN1N9Twspc6DhEREZVARjurg62tLQ4fPoy9e/fizJkz0Gq1qFOnDtq2bVvgbc2fPx8DBw7EoEGDAAALFizAzp07sXjxYsyaNctg+R07duDAgQP4559/UKZMGQCAn5/fK90fytnp24+xO/wBTE0UGB3M3l4iIiLKntEWvllat26N1q1bv/T6aWlpOH36NMaNG6fXHhwcjKNHj2a7zpYtW1C3bl3MnTsXa9asgZWVFTp37ozPP/8cFhYW2a6TmpqK1NRU3eWs8ckajUY3XKOwZG2vsLdbHF7MLoTA7O1XAQCv1/aAj72qRN8vY9r3ciPn/HLODsg7v5yzA/LOL9fscstb2iiEEELqECXZ/fv34enpiSNHjqBx48a69pkzZ2LVqlWIiIgwWKddu3bYv38/2rZti0mTJuHRo0cYOnQoWrduneM43ylTpmDq1KkG7evWrYOlpWXh3SEjE/5EgSVXTWGmEPisdgYcVFInIiKi0iw5ORm9evVCXFwcbG1tpY5DLzD6Ht/C8uLUWEKIHKfL0mq1UCgU+Omnn2BnZwcgc7hEt27d8N1332Xb6zt+/HiMGjVKdzk+Ph7e3t4IDg4u9BeORqNBWFgYgoKCoFQqC3XbRe357KamZvh+yV8AEtCnkR/ebl/yhzkYy76XW3ZA3vnlnB2Qd345ZwfknV+u2bObUYpKDha+eXBycoKpqanB3L8xMTFwdc3+BAnu7u7w9PTUFb0AEBAQACEE7t69iwoVKhiso1KpoFIZdlcqlcoie8EX5baLmlKpxI4rD3ElKgHWKjMMa1NRVvdF7vtertkBeeeXc3ZA3vnlnB2Qd365ZZdT1tLIaGd1KCzm5uYIDAxEWFiYXntYWJje0IfnNWnSBPfv30diYqKu7dq1azAxMYGXl1eR5i0tNBlazA+7BgB4t1lZlLEylzgRERERlXRGXfjeuHEDn332GXr27ImYmBgAmTMuXL58uUDbGTVqFH788UcsX74c4eHhGDlyJCIjIzFkyBAAmcMU+vTpo1u+V69ecHR0RP/+/XHlyhUcPHgQY8aMwYABA3I8uI0KZsOZ+7j5KAmOVuYY2Mxf6jhEREQkA0Zb+B44cADVq1fH8ePHsXHjRl3v64ULFzB58uQCbatHjx5YsGABpk2bhlq1auHgwYMIDQ2Fr68vACAqKkpvTl9ra2uEhYXh6dOnqFu3Lt5++2106tQJX3/9deHdwVIsLQP4dt8NAMAHrcrDWsURO0RERJQ3o60Yxo0bh+nTp2PUqFGwsbHRtbdq1QoLFy4s8PaGDh2KoUOHZnvdypUrDdoqV65sMDyCCsehaAUeJKTC094Cbzf0kToOERERyYTR9vhevHgRXbt2NWh3dnZGbGysBImoMMQ/02D3vcyn7Yi2FaAyM5U4EREREcmF0Ra+9vb2iIqKMmg/e/YsPD09JUhEhWH50dtIzlCgvLMVXq/DAwWJiIgo/4y28O3Vqxc++eQTREdHQ6FQQKvV4siRI/j444/1DkQj+UhNz8C6E3cAAMNbl4OpSfbzKBMRERFlx2gL3xkzZsDHxweenp5ITExElSpV0Lx5czRu3BifffaZ1PHoJey6/ABPkjWwMxcICnCROg4RERHJjNEe3KZUKvHTTz9h2rRpOHv2LLRaLWrXrp3tySNIHn4+kTlzRkMXATNTo/3ORkREREXEaAvfAwcOoEWLFihXrhzKlSsndRx6RTcfJeHojVgoFEBDF63UcYiIiEiGjLbbLCgoCD4+Phg3bhwuXbokdRx6Rb/829vbvIITyhie2ZmIiIgoT0Zb+N6/fx9jx47FoUOHUKNGDdSoUQNz587F3bt3pY5GBZSanoHfTmc+bm/V5UwORERE9HKMtvB1cnLCsGHDcOTIEdy4cQM9evTA6tWr4efnh9atW0sdjwog7MoDPE5Kg6utCi0rOkkdh4iIiGTKaAvf5/n7+2PcuHGYPXs2qlevjgMHDkgdiQpg3fHMYQ496nrzoDYiIiJ6aUZfRRw5cgRDhw6Fu7s7evXqhapVq2Lbtm1Sx6J8ev6gtu71vKWOQ0RERDJmtLM6fPrpp/j5559x//59tG3bFgsWLECXLl1gaWkpdTQqgF9OZvb2tqzoDC8HS2g0GokTERERkVwZbeG7f/9+fPzxx+jRowecnDguVI7S0rX4/VTmQW096/tInIaIiIjkzmgL36NHj0odgV7RrivRiE1Kg4uNCq0r80xtRERE9GqMqvDdsmUL2rdvD6VSiS1btuS6bOfOnYspFb2srDO19ajHg9qIiIjo1RlV4dulSxdER0fDxcUFXbp0yXE5hUKBjIyM4gtGBXbrURKOXM88qK0HD2ojIiKiQmBUha9Wq832/yQ/P/97UFuLfw9qIyIiInpVRvv78erVq5GammrQnpaWhtWrV0uQiPKLB7URERFRUTDawrd///6Ii4szaE9ISED//v0lSET5FXblAQ9qIyIiokJntIWvEAIKhcKg/e7du7Czs5MgEeXX8we1KXlQGxERERUSoxrjCwC1a9eGQqGAQqFAmzZtYGb2313MyMjAzZs30a5dOwkTUm5uPUrC4euPMs/UVpcHtREREVHhMbrCN2s2h3PnziEkJATW1ta668zNzeHn54c33nhDonSUl19O3gEANK/gDO8yPKiNiIiICo/RFb6TJ08GAPj5+aFHjx5Qq9USJ6L8SkvX4vfTmYUvD2ojIiKiwmZ0hW+Wvn37Sh2BCmh3+AM8Ssw8qK1NAA9qIyIiosJltIVvRkYGvvrqK/z666+IjIxEWlqa3vWPHz+WKBnlZN3xzIPautflQW1ERERU+Iy2upg6dSrmz5+P7t27Iy4uDqNGjcLrr78OExMTTJkyRep49ILbsf8d1MYztREREVFRMNrC96effsIPP/yAjz/+GGZmZujZsyd+/PFHTJo0CX/99ZfU8egFWQe1NeNBbURERFREjLbwjY6ORvXq1QEA1tbWupNZvPbaa/jzzz+ljEYvSEvX4rdTmYVvLx7URkREREXEaAtfLy8vREVFAQDKly+PXbt2AQBOnjwJlUolZTR6QdZBbc48qI2IiIiKkNEWvl27dsWePXsAAB999BEmTpyIChUqoE+fPhgwYIDE6eh5WWdq617Xiwe1ERERUZEx2lkdZs+erft/t27d4OXlhaNHj6J8+fLo3LmzhMnoeZGxyTj0d+ZBbW/V4zAHIiIiKjpGW/i+qGHDhmjYsKHUMegFP5/M7O3lQW1ERERU1Iyq8N2yZUu+l2Wvr/T0D2rjFGZERERUtIyq8O3SpUu+llMoFMjIyCjaMJSnPXoHtblKHYeIiIiMnFEVvlqtVuoIVADreFAbERERFSNWGySJrIPaAB7URkRERMXDqHp8nzdt2rRcr580aVIxJaHs/KI7qM2JB7URERFRsTDawnfTpk16lzUaDW7evAkzMzOUK1euwIXvokWL8MUXXyAqKgpVq1bFggUL0KxZs2yX3b9/P1q1amXQHh4ejsqVKxfodo2RJkOLX0/dBcAztREREVHxMdrC9+zZswZt8fHx6NevH7p27Vqgba1fvx4jRozAokWL0KRJE3z//fdo3749rly5Ah+fnAu3iIgI2Nra6i47OzsX6HaNVeZBbalwslahbRUe1EZERETFo1SN8bW1tcW0adMwceLEAq03f/58DBw4EIMGDUJAQAAWLFgAb29vLF68ONf1XFxc4ObmpvszNTV9lfhG46fjPKiNiIiIip/R9vjm5OnTp4iLi8v38mlpaTh9+jTGjRun1x4cHIyjR4/mum7t2rWRkpKCKlWq4LPPPst2+EOW1NRUpKam6i7Hx8cDyByiodFo8p03P7K2V9jbzY87T/47qO2N2u4FziBl9sIg5/xyzg7IO7+cswPyzi/n7IC888s1u9zyljYKIYSQOkRR+Prrr/UuCyEQFRWFNWvWoHnz5vj555/ztZ379+/D09MTR44cQePGjXXtM2fOxKpVqxAREWGwTkREBA4ePIjAwECkpqZizZo1WLJkCfbv34/mzZtneztTpkzB1KlTDdrXrVsHS0vjOfhrW6QJwu6ZoJKdFkOrcPo5IiIyLsnJyejVqxfi4uL0hjtSyWC0ha+/v7/eZRMTEzg7O6N169YYP348bGxs8rWdrML36NGjaNSoka59xowZWLNmDa5evZqv7XTq1AkKhSLHs8tl1+Pr7e2NR48eFfoLR6PRICwsDEFBQVAqlYW67VxvN0OLFvMO4mFiGr55qybaVS34+F6pshcWOeeXc3ZA3vnlnB2Qd345ZwfknV+u2ePj4+Hk5MTCt4Qy2qEON2/eLJTtODk5wdTUFNHR0XrtMTExcHXNf+HWsGFDrF27NsfrVSoVVCqVQbtSqSyyF3xRbjs7eyKi8DAxDU7WKrSr7vFK43uLO3thk3N+OWcH5J1fztkBeeeXc3ZA3vnlll1OWUsjHlmUB3NzcwQGBiIsLEyvPSwsTG/oQ17Onj0Ld3f3wo4nK+tO3AEAvMmD2oiIiEgCRtvjm5KSgm+++Qb79u1DTEyMwemMz5w5k+9tjRo1Cr1790bdunXRqFEjLF26FJGRkRgyZAgAYPz48bh37x5Wr14NAFiwYAH8/PxQtWpVpKWlYe3atdiwYQM2bNhQeHdQZu48Tsahvx8CAN6q5y1xGiIiIiqNjLbwHTBgAMLCwtCtWzfUr18fCoXipbfVo0cPxMbGYtq0aYiKikK1atUQGhoKX19fAEBUVBQiIyN1y6elpeHjjz/GvXv3YGFhgapVq+LPP/9Ehw4dXvl+ydUvJyMhROaZ2nwdraSOQ0RERKWQ0Ra+f/75J0JDQ9GkSZNC2d7QoUMxdOjQbK9buXKl3uWxY8di7NixhXK7xuD5M7X15JnaiIiISCJGO9DS09Mz3zM3UNHaEx6DhwmpcLI2R9sAnqmNiIiIpGG0he+XX36JTz75BLdv35Y6Sqn384nMYSDdAr1hbma0TzkiIiIq4Yx2qEPdunWRkpKCsmXLwtLS0mB6kcePH0uUrHS58zgZB/89qK1nfR7URkRERNIx2sK3Z8+euHfvHmbOnAlXV9dXOriNXt76k3cgBNC0PA9qIyIiImkZbeF79OhRHDt2DDVr1pQ6SqmVeVBb5ty9PKiNiIiIpGa0Ay4rV66MZ8+eSR2jVNt7NQYx/x7UFlSFB7URERGRtIy28J09ezZGjx6N/fv3IzY2FvHx8Xp/VPTWHedBbURERFRyGO1Qh3bt2gEA2rRpo9cuhIBCoUBGRoYUsUqN5w9q45naiIiIqCQw2sJ33759Ukco1X49lXlQW5PyjvBz4kFtREREJD2jLXxbtGghdYRSS5OhxfqTmQe19arvK3EaIiIiokxGW/gePHgw1+ubN29eTElKn6yD2hyteFAbERERlRxGW/i2bNnSoO35uXw5xrfo6M7UVteLB7URERFRiWG0VcmTJ0/0/mJiYrBjxw7Uq1cPu3btkjqe0br7JBkHrv17prZ6nLuXiIiISg6j7fG1s7MzaAsKCoJKpcLIkSNx+vRpCVIZv41n7kEIoHE5HtRGREREJYvR9vjmxNnZGREREVLHMFqhF6MAAF1qe0qchIiIiEif0fb4XrhwQe+yEAJRUVGYPXs2T2NcRG49SsLV6ASYmigQFMCD2oiIiKhkMdrCt1atWlAoFBBC6LU3bNgQy5cvlyiVcdt+KRoA0KisIxyszCVOQ0RERKTPaAvfmzdv6l02MTGBs7Mz1Gq1RImM3/ZLmcMc2ld3kzgJERERkSGjLXx9fXnihOJ090kyLtyNg0IBBFdh4UtEREQlj9Ed3LZ3715UqVIF8fHxBtfFxcWhatWqOHTokATJjNuOf4c51PcrA2cblcRpiIiIiAwZXeG7YMECvPvuu7C1tTW4zs7ODoMHD8b8+fMlSGbcssb3tq/G3l4iIiIqmYyu8D1//jzatWuX4/XBwcGcw7eQRcel4PTtJwCAdtXcJU5DRERElD2jK3wfPHgApVKZ4/VmZmZ4+PBhMSYyfjsvZ/b21vGxh5sdDx4kIiKiksnoCl9PT09cvHgxx+svXLgAd3f2ShYm3WwO7O0lIiKiEszoCt8OHTpg0qRJSElJMbju2bNnmDx5Ml577TUJkhmnR4mpOHHzMQCgHcf3EhERUQlmdNOZffbZZ9i4cSMqVqyIYcOGoVKlSlAoFAgPD8d3332HjIwMTJgwQeqYRmPX5QfQCqC6px28y1hKHYeIiIgoR0ZX+Lq6uuLo0aN4//33MX78eN2Z2xQKBUJCQrBo0SK4uvJ0uoUla5gDe3uJiIiopDO6whfIPHlFaGgonjx5guvXr0MIgQoVKsDBwUHqaEblaXIajt2IBcBpzIiIiKjkM8rCN4uDgwPq1asndQyjFXblAdK1ApXdbFDW2VrqOERERES5MrqD26j4ZJ2tjcMciIiISA5Y+NJLSUjR4NDfjwAAHapzGjMiIiIq+Vj40kvZezUGaRlalHW2QgUXDnMgIiKiko+FL72U0IuZszl0qOYOhUIhcRoiIiKivLHwpQJLTkvHgWuZp33m+F4iIiKSCxa+VGD7Ix4iRaOFdxkLVPWwlToOERERUb6w8KUC4zAHIiIikiMWvlQgKZoM7LsaA4DDHIiIiEheWPhSgRy89hBJaRnwsFOjlre91HGIiIiI8o2Fbz4tWrQI/v7+UKvVCAwMxKFDh/K13pEjR2BmZoZatWoVbcBiknXSipBqbhzmQERERLLCwjcf1q9fjxEjRmDChAk4e/YsmjVrhvbt2yMyMjLX9eLi4tCnTx+0adOmmJIWrbR0LcLCHwAA2lfjSSuIiIhIXlj45sP8+fMxcOBADBo0CAEBAViwYAG8vb2xePHiXNcbPHgwevXqhUaNGhVT0qJ15MYjJKSkw9lGhUBfB6njEBERERWImdQBSrq0tDScPn0a48aN02sPDg7G0aNHc1xvxYoVuHHjBtauXYvp06fneTupqalITU3VXY6PjwcAaDQaaDSal0yfvaztFXS7oRfuAwCCApyhzUiHNqNQY+XLy2YvKeScX87ZAXnnl3N2QN755ZwdkHd+uWaXW97ShoVvHh49eoSMjAy4urrqtbu6uiI6Ojrbdf7++2+MGzcOhw4dgplZ/nbxrFmzMHXqVIP2Xbt2wdLSsuDB8yEsLCzfy2YIIPS8KQAF7BNvIzT0VpFkyq+CZC+J5JxfztkBeeeXc3ZA3vnlnB2Qd365ZU9OTpY6AuWChW8+vXgglxAi24O7MjIy0KtXL0ydOhUVK1bM9/bHjx+PUaNG6S7Hx8fD29sbwcHBsLUt3JNEaDQahIWFISgoCEqlMl/rHL0Ri6S/TsPBUokPu7eFmak0o2ReJntJIuf8cs4OyDu/nLMD8s4v5+yAvPPLNXvWL7ZUMrHwzYOTkxNMTU0NendjYmIMeoEBICEhAadOncLZs2cxbNgwAIBWq4UQAmZmZti1axdat25tsJ5KpYJKpTJoVyqVRfaCL8i2w65mnqI4uIobLNSGOYtbUe6X4iDn/HLODsg7v5yzA/LOL+fsgLzzyy27nLKWRjy4LQ/m5uYIDAw0+KklLCwMjRs3Nlje1tYWFy9exLlz53R/Q4YMQaVKlXDu3Dk0aNCguKIXmgytwI5L/87mUJ0nrSAiIiJ5Yo9vPowaNQq9e/dG3bp10ahRIyxduhSRkZEYMmQIgMxhCvfu3cPq1athYmKCatWq6a3v4uICtVpt0C4Xp28/waPEVNiozdC4nJPUcYiIiIheCgvffOjRowdiY2Mxbdo0REVFoVq1aggNDYWvry8AICoqKs85feVs+6UoAEBQgCvMzfgjAREREckTC998Gjp0KIYOHZrtdStXrsx13SlTpmDKlCmFH6oYaLVCd7a29tV50goiIiKSL3bfUa7O332KqLgUWJmbolkFDnMgIiIi+WLhS7na/m9vb6vKLlArTSVOQ0RERPTyWPhSjoQQuvG9HTjMgYiIiGSOhS/l6PL9eNx5/AxqpQlaVnKWOg4RERHRK2HhSznK6u1tWdEFluY8DpKIiIjkjYUvZUsIge0Xs2Zz4EkriIiISP5Y+FK2rj1IxD+PkmBuaoLWlV2kjkNERET0ylj4Urayhjk0q+AEGzXPO05ERETyx8KXspV10op21TjMgYiIiIwDC18y8M/DRFyNToCZiQJBVVyljkNERERUKFj4koGsk1Y0KucIe0tzidMQERERFQ4WvmQga3xv+2o8aQUREREZDxa+pOfO42RcuhcPEwUQXJXDHIiIiMh4sPAlPVkHtdX3LwMna5XEaYiIiIgKDwtf0hPKYQ5ERERkpFj4kk5U3DOcjXwKgNOYERERkfFh4Us6O/8d5hDo6wBXW7XEaYiIiIgKFwtf0gn9t/Btz95eIiIiMkIsfAkA8DAhFSdvPQbAYQ5ERERknFj4EgBg5+VoCAHU8LKDl4Ol1HGIiIiICh0LXwLw3zRmnM2BiIiIjBULX8KTpDQc+ycWAMf3EhERkfFi4UsIu/IAGVqBAHdb+DlZSR2HiIiIqEiw8CVs1520gr29REREZLxY+JZycc80OHz9EQAWvkRERGTcWPiWcnuvPoAmQ6C8izUquNpIHYeIiIioyLDwLeW2X+RJK4iIiKh0YOFbiiWlpuPAtYcAeNIKIiIiMn4sfEuxA9ceITVdC19HS1Rxt5U6DhEREVGRYuFbiu24/ABAZm+vQqGQOA0RERFR0WLhW0qlZQAH/s6czaEDz9ZGREREpQAL31LqapwCyWkZ8LS3QA0vO6njEBERERU5Fr6l1LnYzKENIVU5zIGIiIhKBxa+pVBquhaXn2QWux2qczYHIiIiKh1Y+JZCx/6JRUqGAi42KtTxcZA6DhEREVGxYOFbCmXN5hBcxQUmJhzmQERERKUDC99SRpOhxZ7wzJNWhFRxlTgNERERUfFh4ZtPixYtgr+/P9RqNQIDA3Ho0KEclz18+DCaNGkCR0dHWFhYoHLlyvjqq6+KMW3O/vonFk+faWBlJlDX117qOERERETFxkzqAHKwfv16jBgxAosWLUKTJk3w/fffo3379rhy5Qp8fHwMlreyssKwYcNQo0YNWFlZ4fDhwxg8eDCsrKzw3nvvSXAP/lPNww7TOgfg3IVLMDPl9x4iIiIqPVj55MP8+fMxcOBADBo0CAEBAViwYAG8vb2xePHibJevXbs2evbsiapVq8LPzw/vvPMOQkJCcu0lLi4OVuboWc8bLdyF1FGIiIiIihV7fPOQlpaG06dPY9y4cXrtwcHBOHr0aL62cfbsWRw9ehTTp0/PcZnU1FSkpqbqLsfHxwMANBoNNBrNSyTPWdb2Cnu7xUHO2QF555dzdkDe+eWcHZB3fjlnB+SdX67Z5Za3tFEIIdj1l4v79+/D09MTR44cQePGjXXtM2fOxKpVqxAREZHjul5eXnj48CHS09MxZcoUTJw4Mcdlp0yZgqlTpxq0r1u3DpaWlq92J4iIiKhYJCcno1evXoiLi4Otra3UcegF7PHNpxfPbiaEyPOMZ4cOHUJiYiL++usvjBs3DuXLl0fPnj2zXXb8+PEYNWqU7nJ8fDy8vb0RHBxc6C8cjUaDsLAwBAUFQalUFuq2i5qcswPyzi/n7IC888s5OyDv/HLODsg7v1yzZ/1iSyUTC988ODk5wdTUFNHR0XrtMTExcHXNfTowf39/AED16tXx4MEDTJkyJcfCV6VSQaVSGbQrlcoie8EX5baLmpyzA/LOL+fsgLzzyzk7IO/8cs4OyDu/3LLLKWtpxIPb8mBubo7AwECEhYXptYeFhekNfciLEEJvDC8RERERFS/2+ObDqFGj0Lt3b9StWxeNGjXC0qVLERkZiSFDhgDIHKZw7949rF69GgDw3XffwcfHB5UrVwaQOa/vvHnz8OGHH0p2H4iIiIhKOxa++dCjRw/ExsZi2rRpiIqKQrVq1RAaGgpfX18AQFRUFCIjI3XLa7VajB8/Hjdv3oSZmRnKlSuH2bNnY/DgwVLdBSIiIqJSj4VvPg0dOhRDhw7N9rqVK1fqXf7www/Zu0tERERUwnCMLxERERGVCix8iYiIiKhUYOFLRERERKUCC18iIiIiKhVY+BIRERFRqcBZHUooIQSAojn1oUajQXJyMuLj42V3hhk5ZwfknV/O2QF555dzdkDe+eWcHZB3frlmz/rczvocp5KFhW8JlZCQAADw9vaWOAkREREVVEJCAuzs7KSOQS9QCH4lKZG0Wi3u378PGxsbKBSKQt12fHw8vL29cefOHdja2hbqtouanLMD8s4v5+yAvPPLOTsg7/xyzg7IO79cswshkJCQAA8PD5iYcERpScMe3xLKxMQEXl5eRXobtra2snozeZ6cswPyzi/n7IC888s5OyDv/HLODsg7vxyzs6e35OJXESIiIiIqFVj4EhEREVGpwMK3FFKpVJg8eTJUKpXUUQpMztkBeeeXc3ZA3vnlnB2Qd345ZwfknV/O2ank4sFtRERERFQqsMeXiIiIiEoFFr5EREREVCqw8CUiIiKiUoGFLxERERGVCix8iYiIiKhUYOFbyixatAj+/v5Qq9UIDAzEoUOHpI6UL7NmzUK9evVgY2MDFxcXdOnSBREREVLHeimzZs2CQqHAiBEjpI6Sb/fu3cM777wDR0dHWFpaolatWjh9+rTUsfKUnp6Ozz77DP7+/rCwsEDZsmUxbdo0aLVaqaNl6+DBg+jUqRM8PDygUCiwefNmveuFEJgyZQo8PDxgYWGBli1b4vLly9KEfUFu2TUaDT755BNUr14dVlZW8PDwQJ8+fXD//n3pAr8gr33/vMGDB0OhUGDBggXFli83+ckeHh6Ozp07w87ODjY2NmjYsCEiIyOLP2w28sqfmJiIYcOGwcvLCxYWFggICMDixYulCUuyx8K3FFm/fj1GjBiBCRMm4OzZs2jWrBnat29fYt78cnPgwAF88MEH+OuvvxAWFob09HQEBwcjKSlJ6mgFcvLkSSxduhQ1atSQOkq+PXnyBE2aNIFSqcT27dtx5coVfPnll7C3t5c6Wp7mzJmDJUuW4Ntvv0V4eDjmzp2LL774At98843U0bKVlJSEmjVr4ttvv832+rlz52L+/Pn49ttvcfLkSbi5uSEoKAgJCQnFnNRQbtmTk5Nx5swZTJw4EWfOnMHGjRtx7do1dO7cWYKk2ctr32fZvHkzjh8/Dg8Pj2JKlre8st+4cQNNmzZF5cqVsX//fpw/fx4TJ06EWq0u5qTZyyv/yJEjsWPHDqxduxbh4eEYOXIkPvzwQ/zxxx/FnJSMgqBSo379+mLIkCF6bZUrVxbjxo2TKNHLi4mJEQDEgQMHpI6SbwkJCaJChQoiLCxMtGjRQnz00UdSR8qXTz75RDRt2lTqGC+lY8eOYsCAAXptr7/+unjnnXckSpR/AMSmTZt0l7VarXBzcxOzZ8/WtaWkpAg7OzuxZMkSCRLm7MXs2Tlx4oQAIG7fvl08oQogp/x3794Vnp6e4tKlS8LX11d89dVXxZ4tL9ll79Gjhyye80Jkn79q1api2rRpem116tQRn332WTEmI2PBHt9SIi0tDadPn0ZwcLBee3BwMI4ePSpRqpcXFxcHAChTpozESfLvgw8+QMeOHdG2bVupoxTIli1bULduXbz55ptwcXFB7dq18cMPP0gdK1+aNm2KPXv24Nq1awCA8+fP4/Dhw+jQoYPEyQru5s2biI6O1nsNq1QqtGjRQravYYVCIYtfDgBAq9Wid+/eGDNmDKpWrSp1nHzTarX4888/UbFiRYSEhMDFxQUNGjTIdShHSdO0aVNs2bIF9+7dgxAC+/btw7Vr1xASEiJ1NJIhFr6lxKNHj5CRkQFXV1e9dldXV0RHR0uU6uUIITBq1Cg0bdoU1apVkzpOvvzyyy84c+YMZs2aJXWUAvvnn3+wePFiVKhQATt37sSQIUMwfPhwrF69Wupoefrkk0/Qs2dPVK5cGUqlErVr18aIESPQs2dPqaMVWNbr1BhewykpKRg3bhx69eoFW1tbqePky5w5c2BmZobhw4dLHaVAYmJikJiYiNmzZ6Ndu3bYtWsXunbtitdffx0HDhyQOl6+fP3116hSpQq8vLxgbm6Odu3aYdGiRWjatKnU0UiGzKQOQMVLoVDoXRZCGLSVdMOGDcOFCxdw+PBhqaPky507d/DRRx9h165dJWZMXUFotVrUrVsXM2fOBADUrl0bly9fxuLFi9GnTx+J0+Vu/fr1WLt2LdatW4eqVavi3LlzGDFiBDw8PNC3b1+p470Uub+GNRoN3nrrLWi1WixatEjqOPly+vRpLFy4EGfOnJHVvgagO5Dzf//7H0aOHAkAqFWrFo4ePYolS5agRYsWUsbLl6+//hp//fUXtmzZAl9fXxw8eBBDhw6Fu7u77H5BI+mx8C0lnJycYGpqatAzFBMTY9CDVJJ9+OGH2LJlCw4ePAgvLy+p4+TL6dOnERMTg8DAQF1bRkYGDh48iG+//RapqakwNTWVMGHu3N3dUaVKFb22gIAAbNiwQaJE+TdmzBiMGzcOb731FgCgevXquH37NmbNmiW7wtfNzQ1AZs+vu7u7rl1Or2GNRoPu3bvj5s2b2Lt3r2x6ew8dOoSYmBj4+Pjo2jIyMjB69GgsWLAAt27dki5cHpycnGBmZpbta1gOnQfPnj3Dp59+ik2bNqFjx44AgBo1auDcuXOYN28eC18qMA51KCXMzc0RGBiIsLAwvfawsDA0btxYolT5J4TAsGHDsHHjRuzduxf+/v5SR8q3Nm3a4OLFizh37pzur27dunj77bdx7ty5El30AkCTJk0Mpo67du0afH19JUqUf8nJyTAx0X+bMzU1LbHTmeXG398fbm5ueq/htLQ0HDhwQBav4ayi9++//8bu3bvh6OgodaR86927Ny5cuKD3Gvbw8MCYMWOwc+dOqePlytzcHPXq1ZPta1ij0UCj0RjN65ikxx7fUmTUqFHo3bs36tati0aNGmHp0qWIjIzEkCFDpI6Wpw8++ADr1q3DH3/8ARsbG13PtZ2dHSwsLCROlzsbGxuDschWVlZwdHSUxRjlkSNHonHjxpg5cya6d++OEydOYOnSpVi6dKnU0fLUqVMnzJgxAz4+PqhatSrOnj2L+fPnY8CAAVJHy1ZiYiKuX7+uu3zz5k2cO3cOZcqUgY+PD0aMGIGZM2eiQoUKqFChAmbOnAlLS0v06tVLwtSZcsvu4eGBbt264cyZM9i2bRsyMjJ0r+EyZcrA3Nxcqtg6ee37Fwt1pVIJNzc3VKpUqbijGsgr+5gxY9CjRw80b94crVq1wo4dO7B161bs379futDPySt/ixYtMGbMGFhYWMDX1xcHDhzA6tWrMX/+fAlTk2xJOqcEFbvvvvtO+Pr6CnNzc1GnTh3ZTAcGINu/FStWSB3tpchpOjMhhNi6dauoVq2aUKlUonLlymLp0qVSR8qX+Ph48dFHHwkfHx+hVqtF2bJlxYQJE0RqaqrU0bK1b9++bJ/nffv2FUJkTmk2efJk4ebmJlQqlWjevLm4ePGitKH/lVv2mzdv5vga3rdvn9TRhRB57/sXlaTpzPKTfdmyZaJ8+fJCrVaLmjVris2bN0sX+AV55Y+KihL9+vUTHh4eQq1Wi0qVKokvv/xSaLVaaYOTLCmEEKJIK2siIiIiohKAY3yJiIiIqFRg4UtEREREpQILXyIiIiIqFVj4EhEREVGpwMKXiIiIiEoFFr5EREREVCqw8CUiIiKiUoGFLxERERGVCix8iYrRrVu3oFAocO7cOamj6Fy9ehUNGzaEWq1GrVq1pI5D+bRy5UrY29vnuZxCocDmzZsLvO2WLVu+VK7i0K9fP3Tp0qXEbOdFCoUCt27dKvTtEtGrY+FLpUq/fv2gUCgwe/ZsvfbNmzdDoVBIlEpakydPhpWVFSIiIrBnzx6p48hWy5YtMWLEiGK7vR49euDatWu6y1OmTOEXlxzk9IVz4cKFWLlypSSZXtWBAwcQGBgItVqNsmXLYsmSJXmu89FHHyEwMBAqlYrPFSq1WPhSqaNWqzFnzhw8efJE6iiFJi0t7aXXvXHjBpo2bQpfX184OjoWYioqShYWFnBxcZE6xkvTaDQGba/yPH4ZdnZ2+eo1L2xPnz5FfHz8S69/8+ZNdOjQAc2aNcPZs2fx6aefYvjw4diwYUOu6wkhMGDAAPTo0eOlb5tI7lj4UqnTtm1buLm5YdasWTkuk13v2YIFC+Dn56e7nPUz6cyZM+Hq6gp7e3tMnToV6enpGDNmDMqUKQMvLy8sX77cYPtXr15F48aNoVarUbVqVezfv1/v+itXrqBDhw6wtraGq6srevfujUePHumub9myJYYNG4ZRo0bByckJQUFB2d4PrVaLadOmwcvLS9fLs2PHDt31CoUCp0+fxrRp06BQKDBlypQctzNnzhyUL18eKpUKPj4+mDFjhu76ixcvonXr1rCwsICjoyPee+89JCYmvtK+yuql++WXX3LdVwcOHED9+vWhUqng7u6OcePGIT09XW9fDR8+HGPHjkWZMmXg5uZmcD/j4uLw3nvvwcXFBba2tmjdujXOnz+vuz7r+bBmzRr4+fnBzs4Ob731FhISEnT378CBA1i4cCEUCoXup+4nT57g7bffhrOzMywsLFChQgWsWLEi2328detW2NvbQ6vVAgDOnTsHhUKBMWPG6JYZPHgwevbsCUB/qMPKlSsxdepUnD9/Xnf7z/dkPnr0CF27doWlpSUqVKiALVu2ZJshN5cvX0bHjh1ha2sLGxsbNGvWDDdu3ACQ9/Ms67H89ddf0bJlS6jVaqxdu1b3vJg1axY8PDxQsWJFAMC9e/fQo0cPODg4wNHREf/73/9yHTqwY8cONG3aFPb29nB0dMRrr72mywYA/v7+AIDatWtDoVDohnG8ONQhNTUVw4cPh4uLC9RqNZo2bYqTJ0/qrt+/fz8UCgX27NmDunXrwtLSEo0bN0ZERESB9uX58+fh5uaGd955B2FhYbrHPL+WLFkCHx8fLFiwAAEBARg0aBAGDBiAefPm5bre119/jQ8++ABly5Yt0O0RGRMWvlTqmJqaYubMmfjmm29w9+7dV9rW3r17cf/+fRw8eBDz58/HlClT8Nprr8HBwQHHjx/HkCFDMGTIENy5c0dvvTFjxmD06NE4e/YsGjdujM6dOyM2NhYAEBUVhRYtWqBWrVo4deoUduzYgQcPHqB79+5621i1ahXMzMxw5MgRfP/999nmW7hwIb788kvMmzcPFy5cQEhICDp37oy///5bd1tVq1bF6NGjERUVhY8//jjb7YwfPx5z5szBxIkTceXKFaxbtw6urq4AgOTkZLRr1w4ODg44efIkfvvtN+zevRvDhg0r8n117949dOjQAfXq1cP58+exePFiLFu2DNOnTzfYV1ZWVjh+/Djmzp2LadOmISwsDEBmL1jHjh0RHR2N0NBQnD59GnXq1EGbNm3w+PFj3TZu3LiBzZs3Y9u2bdi2bRsOHDigGzKzcOFCNGrUCO+++y6ioqIQFRUFb29v3f7avn07wsPDsXjxYjg5OWW7j5s3b46EhAScPXsWQGZB7+TkhAMHDuiW2b9/P1q0aGGwbo8ePTB69GhUrVpVd/vP9+pNnToV3bt3x4ULF9ChQwe8/fbbevctL/fu3UPz5s2hVquxd+9enD59GgMGDNB9wcjreZblk08+wfDhwxEeHo6QkBAAwJ49exAeHo6wsDBs27YNycnJaNWqFaytrXHw4EEcPnwY1tbWaNeuXY49wklJSRg1ahROnjyJPXv2wMTEBF27dtUVlCdOnAAA7N69G1FRUdi4cWO22xk7diw2bNiAVatW4cyZMyhfvjxCQkIM9tWECRPw5Zdf4tSpUzAzM8OAAQPyvS+BzMd6+/btUKlU6NatG3x9ffHpp5/mu4A+duwYgoOD9dpCQkJw6tSpbHvSieg5gqgU6du3r/jf//4nhBCiYcOGYsCAAUIIITZt2iSefzlMnjxZ1KxZU2/dr776Svj6+upty9fXV2RkZOjaKlWqJJo1a6a7nJ6eLqysrMTPP/8shBDi5s2bAoCYPXu2bhmNRiO8vLzEnDlzhBBCTJw4UQQHB+vd9p07dwQAERERIYQQokWLFqJWrVp53l8PDw8xY8YMvbZ69eqJoUOH6i7XrFlTTJ48OcdtxMfHC5VKJX744Ydsr1+6dKlwcHAQiYmJurY///xTmJiYiOjoaCFE0e2rTz/9VFSqVElotVrdMt99952wtrbW3VaLFi1E06ZNDfbBJ598IoQQYs+ePcLW1lakpKToLVOuXDnx/fffCyEynw+WlpYiPj5ed/2YMWNEgwYNdJdbtGghPvroI71tdOrUSfTv3z/b/ZadOnXqiHnz5gkhhOjSpYuYMWOGMDc3F/Hx8SIqKkoAEOHh4UIIIVasWCHs7Ox062b3nBVCCADis88+011OTEwUCoVCbN++PcccK1asEC1atNBdHj9+vPD39xdpaWnZLp/X8yzrsVywYIHeMn379hWurq4iNTVV17Zs2TKDxzQ1NVVYWFiInTt36tbLeh1nJyYmRgAQFy9e1Lv9s2fPGtx+1nYSExOFUqkUP/30k+76tLQ04eHhIebOnSuEEGLfvn0CgNi9e7dumT///FMAEM+ePdO1ARA3b97MMd/zkpOTxbp160S7du2EmZmZaNCggVi0aJF4+vRpjutUqFDBYH8fOXJEABD379/P8zZzeq4QlQbs8aVSa86cOVi1ahWuXLny0tuoWrUqTEz+exm5urqievXqusumpqZwdHRETEyM3nqNGjXS/d/MzAx169ZFeHg4AOD06dPYt28frK2tdX+VK1cGAL2fb+vWrZtrtvj4eNy/fx9NmjTRa2/SpInutvIjPDwcqampaNOmTY7X16xZE1ZWVnq3odVq9XqwimJfhYeHo1GjRnoHJjZp0gSJif9v725Dmvz6OIB/N3W4ZIrpLGfFFA02pk7tgV40FQPrhRgapA1JtMCHTNS0B0xf+MbVG9EUVAwxI3sl68GnwqfpMHG5QNN08ykSKVMMy0Kd94s/2+3anLO/d3Wz3wcEPbs813XOdeT6efY7Z8tGs/kBAQFGdXp6ehrOo1KpsLy8DDc3N6M+n5ycNOpvPp8PDodjto6tpKamoqGhAWKxGHl5eVAqlRaPDwsLQ2dnJzY2NqBQKBAdHQ2RSISenh50dHRg3759hrGwE5vb7+TkBA6Hs+21b6ZWq3Hy5Ek4ODiYvLaTcWZuzPr7+4PFYhl+VqlU0Gg04HA4hnuxd+9efP/+3eh+bKbVanHhwgX4+PjA2dnZkNowMzNjdRu1Wi1WV1eN2uHg4IBjx46ZtGNzf3p6egLAjvpzMzabjfj4eDQ3N2N4eBirq6tIS0vbMiVG7+fFuBsbG2bLCSHG7P/0BRDyp0gkEkRGRuLWrVtITEw0eo3JZBoeJHrm3kL8ORBgMBhmy6zJ4dM/sHQ6HaKioiCTyUyO0T9kARgFmtbUq7exsbGjhyObzbb4uqX6Npf/L/rK3LnNBQCWzqPT6eDp6WmSOwzAaOHTr1zrmTNnMD09jefPn+Ply5eIiIhAenr6lrmYYWFhqKmpwZs3b8BkMiEUChEaGoquri4sLi6aTXOwxq/2s952Y0Bf52bm7o25MftzmU6nQ0hICB4+fGhyLJfLNXvuqKgoHDx4ENXV1eDxeNDpdBCJRDtaLLdV4GiuHZv7c/Pf7a9YW1vDixcvUFdXB7lcDh8fH8hkMkil0i1/Z//+/ZibmzMq+/jxI+zt7WmBKiHboBlfYtOKi4vx9OlTk5k4LpeLubk5o+B3N/fe7evrM3y/trYGlUplmMkLDg7G8PAw+Hw+fH19jb6sDXYBwNnZGTweDz09PUblSqUSAoHA6nr8/PzAZrO33OpMKBRCrVbj69evhrLe3l4wmUzDYqV/w1JfCYVCKJVKo/ukVCrB4XDg5eVlVf3BwcGYm5uDvb29SX9vlY9rDovFwvr6ukk5l8tFYmIi6uvrUVJSgqqqqi3r0Of5lpSUIDQ0FAwGA6Ghoejs7Nwyv3e78++GgIAAKBQKs//87dY40wsODsb4+Dg8PDxM7oeLi4vJ8Z8/f8bIyAjy8/MREREBgUBgsmOLfkbZUv/4+vqCxWIZtWN1dRUDAwO/1I7tDA4OIisrCwcOHEBCQgLc3d3R3d2NoaEh5OXlbRnkA/+8C6LPUddra2vDkSNHzM7KE0L+iwJfYtP8/f0hlUpRVlZmVB4WFoZPnz7hzp070Gq1KC8vR3Nz866dt7y8HI2NjRgdHUV6ejoWFxcNC2TS09OxsLCA+Ph49Pf3Y2JiAm1tbUhKStpxYJObmwuZTIbHjx/j3bt3uHHjBtRqNTIzM62uw9HREdevX0deXh7q6uqg1WrR19eHmpoaAIBUKoWjoyMuXryIoaEhdHR0ICMjAwkJCYYFcP+Gpb5KS0vD+/fvkZGRgdHRUcjlchQWFiI7O9sorcKSU6dO4cSJEzh79ixaW1sxNTUFpVKJ/Px8DAwMWH2dfD4fr169wtTUFObn56HT6VBQUAC5XA6NRoPh4WE8e/bMYhDl4uICsViM+vp6w84DEokEr1+/xtjYmMUPleDz+ZicnIRarcb8/Dx+/Phh9bVv58qVK/jy5Qvi4uIwMDCA8fFxPHjwwJDKshvjTE8qlcLd3R3R0dFQKBSYnJxEV1cXMjMzzS5G1e/8UFVVBY1Gg/b2dmRnZxsd4+HhATabbVgourS0ZFKPk5MTUlNTkZubi5aWFrx9+xaXL1/Gt2/fkJycvON2WKJQKHD8+HFMTEygoqICs7OzKCsr2zZ9SS8lJQXT09PIzs7GyMgI7t+/j5qaGqPFqY2NjSZpMRqNBmq1GnNzc1hZWYFarYZarf7t28gR8idR4EtsXlFRkUlag0AgQEVFBcrLyxEYGIj+/v4tdzz4FcXFxZDJZAgMDIRCoYBcLjfMLvJ4PPT29mJ9fR2RkZEQiUTIzMyEi4uL1cGc3tWrV5GTk4OcnBz4+/ujpaUFT548gZ+f347quX37NnJyclBQUACBQIDz588bchr37NmD1tZWLCws4OjRozh37hwiIiJw7969HZ1jK5b6ysvLC01NTejv70dgYCBSUlKQnJyM/Px8q+tnMBhoamqCRCJBUlISDh8+jLi4OExNTe0ocL927Rrs7OwgFArB5XIxMzMDFouFmzdvIiAgABKJBHZ2dmhoaLBYT3h4ONbX1w1Brqurq6FOS0FzbGwsTp8+jfDwcHC5XDx69Mjqa9+Om5sb2tvbsby8jNDQUISEhKC6utowu7hb4wz4Zzx1d3fj0KFDiImJgUAgQFJSElZWVuDs7GxyPJPJRENDA1QqFUQiEbKysnD37l2jY+zt7VFaWorKykrweDxER0ebPXdxcTFiY2ORkJCA4OBgaDQatLa2wtXVdcftsEQoFOLDhw+Qy+WIiYkxynG2hre3N5qamtDZ2QmxWIyioiKUlpYiNjbWcMzS0pLJLhGXLl1CUFAQKisrMTY2hqCgIAQFBWF2dnZX2kXI/wPGxs9PfEII+QtMTU3B29sbg4OD9ClTv1ltbS1qa2vN5j2T7TEYDExOThrt+00I+TvQjC8hhBBCCLEJFPgSQgghhBCbQNuZEUL+Snw+3yT3mvweYrHYZIs/Yr3CwkKjrfAIIX8PyvElhBBCCCE2gVIdCCGEEEKITaDAlxBCCCGE2AQKfAkhhBBCiE2gwJcQQgghhNgECnwJIYQQQohNoMCXEEIIIYTYBAp8CSGEEEKITfgPFxZp1E1m/QMAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_gt1 = df[cols_corr_gt1]\n",
    "X_gt1 = X_gt1.drop(columns=[\"class\"])\n",
    "\n",
    "scaler_gt1 = StandardScaler()\n",
    "X_gt1_scaled = scaler_gt1.fit_transform(X_gt1)\n",
    "\n",
    "pca_corr_gt1 = PCA(n_components=len(cols_corr_gt1) - 1)\n",
    "X_gt1_pca = pca_corr_gt1.fit_transform(X_gt1_scaled)\n",
    "\n",
    "pca_cumsum = pca_corr_gt1.explained_variance_ratio_.cumsum()\n",
    "plt.plot(pca_cumsum)\n",
    "plt.xlabel(\"Number of components with |correlation| > 0.1\")\n",
    "plt.ylabel(\"Cumulative explained variance\")\n",
    "plt.title(\n",
    "    \"Cumulative explained variance vs Number of components with |correlation| > 0.1\"\n",
    ")\n",
    "plt.grid()\n",
    "plt.xticks(range(0, len(cols_corr_gt1) - 1, 2))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64added9",
   "metadata": {},
   "source": [
    "- at n=10 of the selected features, we have 95% of the variance explained"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704963c5",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ffbe16f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "_, _, __X__, _, _, __y__ = test_train_val_split(df)\n",
    "df_known_attacks = pd.DataFrame(__X__)\n",
    "df_known_attacks[\"class\"] = __y__\n",
    "df_known_attacks.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a7dcb8a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_similar_attacks = pd.read_csv(similar_attacks_path, low_memory=False)\n",
    "df_similar_attacks = df_similar_attacks.drop(columns=[\"ip_RF\", \"ip_MF\", \"ip_offset\"])\n",
    "df_similar_attacks[\"class\"] = df_similar_attacks[\"class\"].replace({\"normal\": 0, \"attack\": 1})\n",
    "\n",
    "df_new_attacks = pd.read_csv(new_attacks_path, low_memory=False)\n",
    "df_new_attacks = df_new_attacks.drop(columns=[\"ip_RF\", \"ip_MF\", \"ip_offset\"])\n",
    "df_new_attacks[\"class\"] = df_new_attacks[\"class\"].replace({\"normal\": 0, \"attack\": 1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "25d947ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "if TESTING:\n",
    "    df_similar_attacks = df_similar_attacks.sample(frac=TESTING_SIZE, random_state=random_state)\n",
    "    df_similar_attacks.reset_index(drop=True, inplace=True)\n",
    "    df_new_attacks = df_new_attacks.sample(frac=TESTING_SIZE, random_state=random_state)\n",
    "    df_new_attacks.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "5de59b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_scaled(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs:\n",
    "        raise ValueError(\"df and scaler must be passed as keyword arguments for pipeline_scaled\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "\n",
    "    df_ = df.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pd.DataFrame(df_, columns=df.columns[:-1])\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "fb0a3017",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_corr_gt1_scaled(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs or \"cols\" not in kwargs:\n",
    "        raise ValueError(\"df, scaler, and cols must be passed as keyword arguments for pipeline_corr_gt1_scaled\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "    cols = kwargs[\"cols\"]\n",
    "\n",
    "    df_ = df[cols]\n",
    "    df_ = df_.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pd.DataFrame(df_, columns=cols[:-1])\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "85aa6215",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_pca(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs or \"pca\" not in kwargs:\n",
    "        raise ValueError(\"df, scaler, and pca must be passed as keyword arguments for pipeline_pca\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "    pca = kwargs[\"pca\"]\n",
    "\n",
    "    df_ = df.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pca.transform(df_)\n",
    "    df_ = df_[:, :27]\n",
    "    df_ = pd.DataFrame(df_)\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "3779cf45",
   "metadata": {},
   "outputs": [],
   "source": [
    "def pipeline_corr_gt1_pca(**kwargs):\n",
    "    if \"df\" not in kwargs or \"scaler\" not in kwargs or \"cols\" not in kwargs or \"pca\" not in kwargs:\n",
    "        raise ValueError(\"df, scaler, cols, and pca must be passed as keyword arguments for pipeline_corr_gt1_pca\")\n",
    "    df = kwargs[\"df\"]\n",
    "    scaler = kwargs[\"scaler\"]\n",
    "    cols = kwargs[\"cols\"]\n",
    "    pca = kwargs[\"pca\"]\n",
    "\n",
    "    df_ = df[cols]\n",
    "    df_ = df_.drop(columns=[\"class\"])\n",
    "    df_ = scaler.transform(df_)\n",
    "    df_ = pca.transform(df_)\n",
    "    df_ = df_[:, :10]\n",
    "    df_ = pd.DataFrame(df_)\n",
    "    df_[\"class\"] = df[\"class\"]\n",
    "    return df_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7e5bf51",
   "metadata": {},
   "source": [
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "260914d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_param_grid = {\n",
    "    'C': [0.01, 0.1, 1, 10, 100],  # Regularization strength\n",
    "    'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],  # Algorithm to use in the optimization problem\n",
    "    'penalty': ['l1', 'l2', 'elasticnet', 'none']  # Norm used in the penalization\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "fe9a3d3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "verbose = 3\n",
    "cv = 3\n",
    "n_jobs = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e68b75aa",
   "metadata": {},
   "source": [
    "### All features scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2055b375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_type</th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_id</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>ip_proto</th>\n",
       "      <th>ip_checksum</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_dport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>udp_chk</th>\n",
       "      <th>icmp_type</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_seq</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_frst</th>\n",
       "      <th>tcp_fpush</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>tcp_furg</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>count_fr_src_dst</th>\n",
       "      <th>count_fr_dst_src</th>\n",
       "      <th>count_serv_src_dst</th>\n",
       "      <th>count_serv_dst_src</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_pushed_src_dst</th>\n",
       "      <th>num_pushed_dst_src</th>\n",
       "      <th>num_syn_fin_src_dst</th>\n",
       "      <th>num_syn_fin_dst_src</th>\n",
       "      <th>num_fin_src_dst</th>\n",
       "      <th>num_fin_dst_src</th>\n",
       "      <th>num_ack_src_dst</th>\n",
       "      <th>num_ack_dst_src</th>\n",
       "      <th>num_syn_src_dst</th>\n",
       "      <th>num_syn_dst_src</th>\n",
       "      <th>num_rst_src_dst</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_packet</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.863934</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>0.859266</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.023986</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.042562</td>\n",
       "      <td>0.044490</td>\n",
       "      <td>0.203746</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.154188</td>\n",
       "      <td>0.267020</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.863884</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>0.859213</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.023987</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.008185</td>\n",
       "      <td>0.043293</td>\n",
       "      <td>0.044490</td>\n",
       "      <td>0.204454</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.154188</td>\n",
       "      <td>0.267872</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>-0.315216</td>\n",
       "      <td>-0.262465</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>0.597862</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.258300</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>-1.036906</td>\n",
       "      <td>-0.445392</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>-0.315189</td>\n",
       "      <td>-1.146024</td>\n",
       "      <td>-0.327640</td>\n",
       "      <td>-0.380841</td>\n",
       "      <td>-0.167630</td>\n",
       "      <td>-0.205911</td>\n",
       "      <td>-0.582023</td>\n",
       "      <td>-0.680948</td>\n",
       "      <td>-0.468717</td>\n",
       "      <td>-0.600078</td>\n",
       "      <td>-0.036490</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>-0.098600</td>\n",
       "      <td>-0.226426</td>\n",
       "      <td>-0.073183</td>\n",
       "      <td>-0.022541</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>16.893706</td>\n",
       "      <td>3.188363</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>-0.252576</td>\n",
       "      <td>1.273936</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>1.234992</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.158517</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>-1.031884</td>\n",
       "      <td>1.391738</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.303363</td>\n",
       "      <td>-0.353784</td>\n",
       "      <td>-0.152296</td>\n",
       "      <td>-0.179733</td>\n",
       "      <td>-0.553556</td>\n",
       "      <td>-0.271239</td>\n",
       "      <td>-0.440730</td>\n",
       "      <td>-0.025361</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>-0.080893</td>\n",
       "      <td>-0.194893</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.127368</td>\n",
       "      <td>-0.252576</td>\n",
       "      <td>-0.188418</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.458411</td>\n",
       "      <td>-0.708360</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.336106</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.419224</td>\n",
       "      <td>-0.12636</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.099910</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>0.924837</td>\n",
       "      <td>1.391442</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>-0.642375</td>\n",
       "      <td>-0.591224</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.575889</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>0.008994</td>\n",
       "      <td>0.043293</td>\n",
       "      <td>0.045001</td>\n",
       "      <td>0.204454</td>\n",
       "      <td>-0.286574</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178253</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.035595</td>\n",
       "      <td>-0.030035</td>\n",
       "      <td>-0.046082</td>\n",
       "      <td>-0.066375</td>\n",
       "      <td>-0.064148</td>\n",
       "      <td>-0.020566</td>\n",
       "      <td>0.154799</td>\n",
       "      <td>0.267872</td>\n",
       "      <td>-0.072540</td>\n",
       "      <td>-0.021807</td>\n",
       "      <td>-0.02882</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.059194</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    ip_type    ip_len     ip_id     ip_DF  ip_proto  ip_checksum  udp_sport  udp_dport  udp_len   udp_chk  icmp_type  icmp_code  icmp_chk  tcp_sport  tcp_dport   tcp_seq   tcp_ack  tcp_ffyn  tcp_fsyn  tcp_frst  tcp_fpush  tcp_fack  tcp_furg  fr_length  conn_status  count_fr_src_dst  count_fr_dst_src  count_serv_src_dst  count_serv_dst_src  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_pushed_src_dst  num_pushed_dst_src  num_syn_fin_src_dst  num_syn_fin_dst_src  num_fin_src_dst  num_fin_dst_src  num_ack_src_dst  num_ack_dst_src  num_syn_src_dst  num_syn_dst_src  num_rst_src_dst  num_rst_dst_src  first_packet  first_serv_packet  class\n",
       "0 -0.127368  2.357424 -0.863934 -0.756411 -0.458411     0.859266  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014  -1.137734   1.949417  1.023986  1.289289 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889   2.345335     0.030635          0.008185          0.042562            0.044490            0.203746          -0.287266           0.906322               -0.178933                1.626457           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566         0.154188         0.267020        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0\n",
       "1 -0.127368  2.357424 -0.863884 -0.756411 -0.458411     0.859213  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014  -1.137734   1.949417  1.023987  1.289289 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889   2.345335     0.030635          0.008185          0.043293            0.044490            0.204454          -0.287266           0.906322               -0.178933                1.626457           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566         0.154188         0.267872        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0\n",
       "2 -0.127368 -0.315216 -0.262465 -0.756411 -0.458411     0.597862  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014   1.258300  -0.663754 -1.036906 -0.445392 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889  -0.315189    -1.146024         -0.327640         -0.380841           -0.167630           -0.205911          -0.582023          -0.680948               -0.468717               -0.600078           -0.036490           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566        -0.098600        -0.226426        -0.073183        -0.022541         -0.02882        -0.210164     16.893706           3.188363    1.0\n",
       "3 -0.127368 -0.252576  1.273936  1.322033 -0.458411     1.234992  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014   1.158517  -0.663754 -1.031884  1.391738 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889  -0.283641     0.030635         -0.303363         -0.353784           -0.152296           -0.179733          -0.553556          -0.271239               -0.440730               -0.025361           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566        -0.080893        -0.194893        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0\n",
       "4 -0.127368 -0.252576 -0.188418  1.322033 -0.458411    -0.708360  -0.411019  -0.336106 -0.37061 -0.419224   -0.12636  -0.135969 -0.138014   1.099910  -0.663754  0.924837  1.391442 -0.674975 -0.693234 -0.642375  -0.591224  0.121177 -0.575889  -0.283641     0.030635          0.008994          0.043293            0.045001            0.204454          -0.286574           0.906322               -0.178253                1.626457           -0.035595           -0.030035            -0.046082            -0.066375        -0.064148        -0.020566         0.154799         0.267872        -0.072540        -0.021807         -0.02882        -0.210164     -0.059194          -0.313641    0.0"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_scaled = pipeline_scaled(df=df, scaler=scaler)\n",
    "df_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "69d5240a",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_scaled_train,\n",
    "    X_scaled_val,\n",
    "    X_scaled_test,\n",
    "    y_scaled_train,\n",
    "    y_scaled_val,\n",
    "    y_scaled_test,\n",
    ") = test_train_val_split(df_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b310aa0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=245)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scaled_baseline = LogisticRegression(random_state=random_state)\n",
    "log_scaled_baseline.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "795d3a3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      7154\n",
      "         1.0       0.99      1.00      0.99      5605\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_val, log_scaled_baseline.predict(X_scaled_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "38d535c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.980 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.983 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.978 total time=   0.0s\n",
      "[CV 1/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.981 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.983 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.978 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.985 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.986 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.984 total time=   0.0s\n",
      "[CV 1/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.985 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.986 total time=   0.0s\n",
      "[CV 3/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.984 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.985 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.985 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.984 total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.985 total time=   0.1s\n",
      "[CV 2/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.986 total time=   0.1s\n",
      "[CV 3/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.984 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.985 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.986 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.984 total time=   0.2s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.561 total time=   4.1s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.561 total time=   3.3s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ..C=0.01, penalty=none, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=0.01, penalty=none, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=0.01, penalty=none, solver=sag;, score=0.991 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .C=0.01, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=0.01, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .C=0.01, penalty=none, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.990 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.991 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.991 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.990 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.991 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.991 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.990 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.990 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.990 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.989 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.987 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.987 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.561 total time=   4.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.561 total time=   3.3s\n",
      "[CV 1/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.1, penalty=none, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=0.1, penalty=none, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.1, penalty=none, solver=sag;, score=0.991 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ..C=0.1, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=0.1, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=0.1, penalty=none, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l1, solver=liblinear;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l1, solver=liblinear;, score=0.995 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l1, solver=liblinear;, score=0.993 total time=   0.0s\n",
      "[CV 1/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ......C=1, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ......C=1, penalty=l1, solver=saga;, score=0.989 total time=   0.3s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.992 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .C=1, penalty=l2, solver=liblinear;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=liblinear;, score=0.992 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .......C=1, penalty=l2, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .......C=1, penalty=l2, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .......C=1, penalty=l2, solver=sag;, score=0.991 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ......C=1, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ......C=1, penalty=l2, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, penalty=none, solver=newton-cg;, score=0.561 total time=   4.0s\n",
      "[CV 2/3] END C=1, penalty=none, solver=newton-cg;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, penalty=none, solver=newton-cg;, score=0.561 total time=   3.2s\n",
      "[CV 1/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=1, penalty=none, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=1, penalty=none, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=1, penalty=none, solver=sag;, score=0.991 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=1, penalty=none, solver=saga;, score=0.988 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=1, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=1, penalty=none, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l1, solver=liblinear;, score=0.992 total time=   0.5s\n",
      "[CV 2/3] END C=10, penalty=l1, solver=liblinear;, score=0.995 total time=   2.1s\n",
      "[CV 3/3] END C=10, penalty=l1, solver=liblinear;, score=0.992 total time=   0.4s\n",
      "[CV 1/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=10, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=10, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=10, penalty=l1, solver=saga;, score=0.989 total time=   0.3s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=newton-cg;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=newton-cg;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=newton-cg;, score=0.991 total time=   0.0s\n",
      "[CV 1/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.992 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.991 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=liblinear;, score=0.992 total time=   0.1s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=liblinear;, score=0.994 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=liblinear;, score=0.992 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ......C=10, penalty=l2, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=10, penalty=l2, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ......C=10, penalty=l2, solver=sag;, score=0.991 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=10, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=10, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=10, penalty=l2, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, penalty=none, solver=newton-cg;, score=0.561 total time=   4.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=newton-cg;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, penalty=none, solver=newton-cg;, score=0.561 total time=   3.3s\n",
      "[CV 1/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=none, solver=sag;, score=0.990 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=10, penalty=none, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=10, penalty=none, solver=sag;, score=0.991 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=10, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=10, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=10, penalty=none, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l1, solver=liblinear;, score=0.992 total time=   0.8s\n",
      "[CV 2/3] END C=100, penalty=l1, solver=liblinear;, score=0.995 total time=   1.0s\n",
      "[CV 3/3] END C=100, penalty=l1, solver=liblinear;, score=0.990 total time=   2.9s\n",
      "[CV 1/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=100, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=100, penalty=l1, solver=saga;, score=0.988 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=100, penalty=l1, solver=saga;, score=0.989 total time=   0.3s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=newton-cg;, score=0.991 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, penalty=l2, solver=newton-cg;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=newton-cg;, score=0.991 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=liblinear;, score=0.991 total time=   0.7s\n",
      "[CV 2/3] END C=100, penalty=l2, solver=liblinear;, score=0.993 total time=   0.4s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=liblinear;, score=0.991 total time=   0.5s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=100, penalty=l2, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=100, penalty=l2, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=100, penalty=l2, solver=sag;, score=0.991 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=100, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=100, penalty=l2, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=100, penalty=l2, solver=saga;, score=0.989 total time=   0.2s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, penalty=none, solver=newton-cg;, score=0.561 total time=   4.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=newton-cg;, score=0.994 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:457: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, penalty=none, solver=newton-cg;, score=0.561 total time=   3.2s\n",
      "[CV 1/3] END .C=100, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=none, solver=lbfgs;, score=0.993 total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=none, solver=lbfgs;, score=0.992 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=100, penalty=none, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=100, penalty=none, solver=sag;, score=0.990 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=100, penalty=none, solver=sag;, score=0.991 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ..C=100, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=100, penalty=none, solver=saga;, score=0.988 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 73, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.98064112        nan 0.98064112 0.98518693\n",
      " 0.98518693 0.98510855 0.98518693 0.98503017        nan        nan\n",
      "        nan        nan        nan 0.70499255 0.9921624         nan\n",
      " 0.99012462 0.98800846        nan        nan 0.99239752        nan\n",
      " 0.98793009 0.99067325 0.99067325 0.98996787 0.98949761 0.98745983\n",
      "        nan        nan        nan        nan        nan 0.70499255\n",
      " 0.9921624         nan 0.99012462 0.98800846        nan        nan\n",
      " 0.99325966        nan 0.98824359 0.9924759  0.9924759  0.99255428\n",
      " 0.99012462 0.98808684        nan        nan        nan        nan\n",
      "        nan 0.70499255 0.9921624         nan 0.99012462 0.98800846\n",
      "        nan        nan 0.99271103        nan 0.98800846 0.9921624\n",
      " 0.9921624  0.99231915 0.99012462 0.98800846        nan        nan\n",
      "        nan        nan        nan 0.70499255 0.9921624         nan\n",
      " 0.99012462 0.98800846        nan        nan 0.99200564        nan\n",
      " 0.98800846 0.99192727 0.9921624  0.99192727 0.99012462 0.98800846\n",
      "        nan        nan        nan        nan        nan 0.70499255\n",
      " 0.9921624         nan 0.99012462 0.98800846]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=100, penalty=none, solver=saga;, score=0.989 total time=   0.2s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scaled_grid = GridSearchCV(LogisticRegression(random_state=245), log_param_grid, cv=cv, n_jobs=n_jobs, verbose=verbose)\n",
    "log_scaled_grid.fit(X_scaled_val, y_scaled_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6bba940c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(log_scaled_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "b06b35cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-3 {color: black;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', random_state=245, solver='liblinear')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_scaled = LogisticRegression(**log_scaled_grid.best_params_, random_state=random_state)\n",
    "log_scaled.fit(X_scaled_train, y_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "fffd27fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      7209\n",
      "         1.0       0.99      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_scaled_test, log_scaled.predict(X_scaled_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "71f320fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.99      0.99      7209\n",
      "         1.0       0.99      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9933380358962302\n",
      "Precision: 0.9899587591895285\n",
      "Recall: 0.9947747747747748\n",
      "F1: 0.9923609238788532\n",
      "Time per data per iter: 593.9305588212243\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_scaled,\n",
    "        f\"Logistic Regression {log_scaled_grid.best_params_}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ac9d1e3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.97      1.00      0.98     15969\n",
      "           1       1.00      0.95      0.97     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9800446817372865\n",
      "Precision: 0.9951053840775147\n",
      "Recall: 0.9542145593869732\n",
      "F1: 0.9742310889443059\n",
      "Time per data per iter: 496.5754098981408\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_scaled,\n",
    "        f\"Logistic Regression {log_scaled_grid.best_params_}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c8324fa8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      1.00      0.87     58138\n",
      "           1       0.85      0.04      0.08     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.81      0.52      0.48     75890\n",
      "weighted avg       0.79      0.77      0.69     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7744762155751745\n",
      "Precision: 0.8450704225352113\n",
      "Recall: 0.04393871113114015\n",
      "F1: 0.08353413654618473\n",
      "Time per data per iter: 420.4474897878508\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_scaled,\n",
    "        f\"Logistic Regression {log_scaled_grid.best_params_}\",\n",
    "        \"New attacks\",\n",
    "        \"All features scaled\",\n",
    "        pipeline_scaled,\n",
    "        scaler=scaler\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5410da89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>593.930559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>496.575410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>420.447490</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                  Model          Dataset                 Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0  Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  All features scaled      12759  0.993338   0.989959  0.994775  0.992361              593.930559\n",
       "1  Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  All features scaled      26409  0.980045   0.995105  0.954215  0.974231              496.575410\n",
       "2  Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  All features scaled      75890  0.774476   0.845070  0.043939  0.083534              420.447490"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80532aeb",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "6960555a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_len</th>\n",
       "      <th>ip_DF</th>\n",
       "      <th>udp_sport</th>\n",
       "      <th>udp_len</th>\n",
       "      <th>icmp_code</th>\n",
       "      <th>icmp_chk</th>\n",
       "      <th>tcp_sport</th>\n",
       "      <th>tcp_dport</th>\n",
       "      <th>tcp_ack</th>\n",
       "      <th>tcp_ffyn</th>\n",
       "      <th>tcp_fsyn</th>\n",
       "      <th>tcp_fack</th>\n",
       "      <th>fr_length</th>\n",
       "      <th>conn_status</th>\n",
       "      <th>num_bytes_src_dst</th>\n",
       "      <th>num_bytes_dst_src</th>\n",
       "      <th>num_bytes_serv_src_dst</th>\n",
       "      <th>num_bytes_serv_dst_src</th>\n",
       "      <th>num_rst_dst_src</th>\n",
       "      <th>first_serv_packet</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.357424</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>-1.137734</td>\n",
       "      <td>1.949417</td>\n",
       "      <td>1.289289</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>2.345335</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.287266</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178933</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.315216</td>\n",
       "      <td>-0.756411</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.258300</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>-0.445392</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.315189</td>\n",
       "      <td>-1.146024</td>\n",
       "      <td>-0.582023</td>\n",
       "      <td>-0.680948</td>\n",
       "      <td>-0.468717</td>\n",
       "      <td>-0.600078</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>3.188363</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.252576</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.158517</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>1.391738</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.553556</td>\n",
       "      <td>-0.271239</td>\n",
       "      <td>-0.440730</td>\n",
       "      <td>-0.025361</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.252576</td>\n",
       "      <td>1.322033</td>\n",
       "      <td>-0.411019</td>\n",
       "      <td>-0.37061</td>\n",
       "      <td>-0.135969</td>\n",
       "      <td>-0.138014</td>\n",
       "      <td>1.099910</td>\n",
       "      <td>-0.663754</td>\n",
       "      <td>1.391442</td>\n",
       "      <td>-0.674975</td>\n",
       "      <td>-0.693234</td>\n",
       "      <td>0.121177</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>0.030635</td>\n",
       "      <td>-0.286574</td>\n",
       "      <td>0.906322</td>\n",
       "      <td>-0.178253</td>\n",
       "      <td>1.626457</td>\n",
       "      <td>-0.210164</td>\n",
       "      <td>-0.313641</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     ip_len     ip_DF  udp_sport  udp_len  icmp_code  icmp_chk  tcp_sport  tcp_dport   tcp_ack  tcp_ffyn  tcp_fsyn  tcp_fack  fr_length  conn_status  num_bytes_src_dst  num_bytes_dst_src  num_bytes_serv_src_dst  num_bytes_serv_dst_src  num_rst_dst_src  first_serv_packet  class\n",
       "0  2.357424 -0.756411  -0.411019 -0.37061  -0.135969 -0.138014  -1.137734   1.949417  1.289289 -0.674975 -0.693234  0.121177   2.345335     0.030635          -0.287266           0.906322               -0.178933                1.626457        -0.210164          -0.313641    0.0\n",
       "1  2.357424 -0.756411  -0.411019 -0.37061  -0.135969 -0.138014  -1.137734   1.949417  1.289289 -0.674975 -0.693234  0.121177   2.345335     0.030635          -0.287266           0.906322               -0.178933                1.626457        -0.210164          -0.313641    0.0\n",
       "2 -0.315216 -0.756411  -0.411019 -0.37061  -0.135969 -0.138014   1.258300  -0.663754 -0.445392 -0.674975 -0.693234  0.121177  -0.315189    -1.146024          -0.582023          -0.680948               -0.468717               -0.600078        -0.210164           3.188363    1.0\n",
       "3 -0.252576  1.322033  -0.411019 -0.37061  -0.135969 -0.138014   1.158517  -0.663754  1.391738 -0.674975 -0.693234  0.121177  -0.283641     0.030635          -0.553556          -0.271239               -0.440730               -0.025361        -0.210164          -0.313641    0.0\n",
       "4 -0.252576  1.322033  -0.411019 -0.37061  -0.135969 -0.138014   1.099910  -0.663754  1.391442 -0.674975 -0.693234  0.121177  -0.283641     0.030635          -0.286574           0.906322               -0.178253                1.626457        -0.210164          -0.313641    0.0"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_gt1_scaled = pipeline_corr_gt1_scaled(df=df, scaler=scaler_gt1, cols=cols_corr_gt1)\n",
    "df_corr_gt1_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bcad4811",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_corr_gt1_scaled_train,\n",
    "    X_corr_gt1_scaled_val,\n",
    "    X_corr_gt1_scaled_test,\n",
    "    y_corr_gt1_scaled_train,\n",
    "    y_corr_gt1_scaled_val,\n",
    "    y_corr_gt1_scaled_test,\n",
    ") = test_train_val_split(df_corr_gt1_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "492507d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-4 {color: black;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" checked><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=245)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_scaled_baseline = LogisticRegression(random_state=random_state)\n",
    "log_corr_gt1_scaled_baseline.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "682b08e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.98      0.98      7154\n",
      "         1.0       0.97      0.99      0.98      5605\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_corr_gt1_scaled_val, log_corr_gt1_scaled_baseline.predict(X_corr_gt1_scaled_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "b9abc488",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.978 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.980 total time=   0.1s\n",
      "[CV 3/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.978 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.979 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.978 total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.978 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.989 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.988 total time=   0.3s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.989 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.990 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ..C=0.01, penalty=none, solver=sag;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.01, penalty=none, solver=sag;, score=0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=0.01, penalty=none, solver=sag;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .C=0.01, penalty=none, solver=saga;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=0.01, penalty=none, solver=saga;, score=0.981 total time=   0.1s\n",
      "[CV 3/3] END .C=0.01, penalty=none, solver=saga;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.981 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.982 total time=   0.1s\n",
      "[CV 3/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.980 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.980 total time=   0.0s\n",
      "[CV 3/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.989 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.988 total time=   0.3s\n",
      "[CV 1/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.989 total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.990 total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.1, penalty=none, solver=sag;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.1, penalty=none, solver=sag;, score=0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.1, penalty=none, solver=sag;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END ..C=0.1, penalty=none, solver=saga;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=0.1, penalty=none, solver=saga;, score=0.981 total time=   0.1s\n",
      "[CV 3/3] END ..C=0.1, penalty=none, solver=saga;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l1, solver=liblinear;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l1, solver=liblinear;, score=0.983 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l1, solver=liblinear;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ......C=1, penalty=l1, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l1, solver=saga;, score=0.982 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ......C=1, penalty=l1, solver=saga;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.982 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.982 total time=   0.0s\n",
      "[CV 3/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=liblinear;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=liblinear;, score=0.982 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=liblinear;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .......C=1, penalty=l2, solver=sag;, score=0.981 total time=   0.1s\n",
      "[CV 2/3] END .......C=1, penalty=l2, solver=sag;, score=0.982 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .......C=1, penalty=l2, solver=sag;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END ......C=1, penalty=l2, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l2, solver=saga;, score=0.981 total time=   0.1s\n",
      "[CV 3/3] END ......C=1, penalty=l2, solver=saga;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=none, solver=newton-cg;, score=0.989 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=1, penalty=none, solver=newton-cg;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=1, penalty=none, solver=newton-cg;, score=0.988 total time=   0.3s\n",
      "[CV 1/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.989 total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.990 total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=1, penalty=none, solver=sag;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .....C=1, penalty=none, solver=sag;, score=0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=1, penalty=none, solver=sag;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END ....C=1, penalty=none, solver=saga;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=1, penalty=none, solver=saga;, score=0.981 total time=   0.0s\n",
      "[CV 3/3] END ....C=1, penalty=none, solver=saga;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l1, solver=liblinear;, score=0.989 total time=   0.7s\n",
      "[CV 2/3] END C=10, penalty=l1, solver=liblinear;, score=0.991 total time=   0.8s\n",
      "[CV 3/3] END C=10, penalty=l1, solver=liblinear;, score=0.988 total time=   0.8s\n",
      "[CV 1/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=10, penalty=l1, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=10, penalty=l1, solver=saga;, score=0.981 total time=   0.1s\n",
      "[CV 3/3] END .....C=10, penalty=l1, solver=saga;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=newton-cg;, score=0.982 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=newton-cg;, score=0.984 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=newton-cg;, score=0.978 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.982 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.984 total time=   0.0s\n",
      "[CV 3/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=liblinear;, score=0.982 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=liblinear;, score=0.983 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=liblinear;, score=0.978 total time=   0.0s\n",
      "[CV 1/3] END ......C=10, penalty=l2, solver=sag;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=10, penalty=l2, solver=sag;, score=0.982 total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l2, solver=sag;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=10, penalty=l2, solver=saga;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END .....C=10, penalty=l2, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=10, penalty=l2, solver=saga;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=newton-cg;, score=0.989 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=10, penalty=none, solver=newton-cg;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, penalty=none, solver=newton-cg;, score=0.988 total time=   0.3s\n",
      "[CV 1/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.989 total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.990 total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=none, solver=sag;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=none, solver=sag;, score=0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=10, penalty=none, solver=sag;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END ...C=10, penalty=none, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=10, penalty=none, solver=saga;, score=0.981 total time=   0.1s\n",
      "[CV 3/3] END ...C=10, penalty=none, solver=saga;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l1, solver=liblinear;, score=0.989 total time=   0.9s\n",
      "[CV 2/3] END C=100, penalty=l1, solver=liblinear;, score=0.992 total time=   0.8s\n",
      "[CV 3/3] END C=100, penalty=l1, solver=liblinear;, score=0.988 total time=   0.9s\n",
      "[CV 1/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=100, penalty=l1, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=100, penalty=l1, solver=saga;, score=0.981 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=100, penalty=l1, solver=saga;, score=0.977 total time=   0.1s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=newton-cg;, score=0.987 total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=l2, solver=newton-cg;, score=0.987 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=newton-cg;, score=0.982 total time=   0.0s\n",
      "[CV 1/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.985 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.986 total time=   0.0s\n",
      "[CV 3/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, penalty=l2, solver=liblinear;, score=0.987 total time=   0.1s\n",
      "[CV 2/3] END C=100, penalty=l2, solver=liblinear;, score=0.987 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=liblinear;, score=0.982 total time=   0.1s\n",
      "[CV 1/3] END .....C=100, penalty=l2, solver=sag;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=100, penalty=l2, solver=sag;, score=0.982 total time=   0.0s\n",
      "[CV 3/3] END .....C=100, penalty=l2, solver=sag;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=100, penalty=l2, solver=saga;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END ....C=100, penalty=l2, solver=saga;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=100, penalty=l2, solver=saga;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=none, solver=newton-cg;, score=0.989 total time=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, penalty=none, solver=newton-cg;, score=0.994 total time=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=100, penalty=none, solver=newton-cg;, score=0.988 total time=   0.3s\n",
      "[CV 1/3] END .C=100, penalty=none, solver=lbfgs;, score=0.989 total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=none, solver=lbfgs;, score=0.990 total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=none, solver=lbfgs;, score=0.988 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=100, penalty=none, solver=sag;, score=0.981 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=none, solver=sag;, score=0.982 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=100, penalty=none, solver=sag;, score=0.977 total time=   0.0s\n",
      "[CV 1/3] END ..C=100, penalty=none, solver=saga;, score=0.981 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 73, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.97797633        nan 0.97813308 0.97805471\n",
      " 0.97805471 0.97805471 0.97805471 0.97805471        nan        nan\n",
      "        nan        nan        nan 0.99059487 0.98902735        nan\n",
      " 0.98024924 0.97985736        nan        nan 0.97977898        nan\n",
      " 0.97977898 0.97891684 0.97891684 0.97868171 0.97891684 0.97891684\n",
      "        nan        nan        nan        nan        nan 0.99059487\n",
      " 0.98902735        nan 0.98024924 0.97985736        nan        nan\n",
      " 0.98040599        nan 0.98009248 0.98017086 0.98017086 0.98017086\n",
      " 0.98009248 0.97985736        nan        nan        nan        nan\n",
      "        nan 0.99059487 0.98902735        nan 0.98024924 0.97985736\n",
      "        nan        nan 0.98957599        nan 0.97985736 0.98111137\n",
      " 0.98111137 0.98087624 0.98024924 0.97985736        nan        nan\n",
      "        nan        nan        nan 0.99059487 0.98902735        nan\n",
      " 0.98024924 0.97985736        nan        nan 0.98949761        nan\n",
      " 0.97985736 0.98550043 0.98408966 0.98550043 0.98024924 0.97985736\n",
      "        nan        nan        nan        nan        nan 0.99059487\n",
      " 0.98902735        nan 0.98024924 0.97985736]\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=100, penalty=none, solver=saga;, score=0.981 total time=   0.0s\n",
      "[CV 3/3] END ..C=100, penalty=none, solver=saga;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" ><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-8\" type=\"checkbox\" ><label for=\"sk-estimator-id-8\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-9\" type=\"checkbox\" ><label for=\"sk-estimator-id-9\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_scaled_grid = GridSearchCV(LogisticRegression(random_state=random_state), log_param_grid, cv=cv, n_jobs=n_jobs, verbose=verbose)\n",
    "log_corr_gt1_scaled_grid.fit(X_corr_gt1_scaled_val, y_corr_gt1_scaled_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "b739cf66",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n"
     ]
    }
   ],
   "source": [
    "print(log_corr_gt1_scaled_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "448cb20f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:211: ConvergenceWarning: newton-cg failed to converge. Increase the number of iterations.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-6 {color: black;}#sk-container-id-6 pre{padding: 0;}#sk-container-id-6 div.sk-toggleable {background-color: white;}#sk-container-id-6 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-6 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-6 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-6 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-6 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-6 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-6 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-6 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-6 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-6 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-6 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-6 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-6 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-6 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-6 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-6 div.sk-item {position: relative;z-index: 1;}#sk-container-id-6 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-6 div.sk-item::before, #sk-container-id-6 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-6 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-6 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-6 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-6 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-6 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-6 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-6 div.sk-label-container {text-align: center;}#sk-container-id-6 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-6 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-6\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=245, solver=&#x27;newton-cg&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-10\" type=\"checkbox\" checked><label for=\"sk-estimator-id-10\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=245, solver=&#x27;newton-cg&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='none', random_state=245, solver='newton-cg')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_scaled = LogisticRegression(**log_corr_gt1_scaled_grid.best_params_, random_state=random_state)\n",
    "log_corr_gt1_scaled.fit(X_corr_gt1_scaled_train, y_corr_gt1_scaled_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a49230c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      7209\n",
      "         1.0       0.98      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_corr_gt1_scaled_test, log_corr_gt1_scaled.predict(X_corr_gt1_scaled_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "cfe60707",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.99      0.99      0.99      7209\n",
      "         1.0       0.98      0.99      0.99      5550\n",
      "\n",
      "    accuracy                           0.99     12759\n",
      "   macro avg       0.99      0.99      0.99     12759\n",
      "weighted avg       0.99      0.99      0.99     12759\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9896543616270868\n",
      "Precision: 0.983232251159472\n",
      "Recall: 0.9931531531531531\n",
      "F1: 0.9881678020795984\n",
      "Time per data per iter: 439.86362567599343\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_corr_gt1_scaled,\n",
    "        f\"Logistic Regression {log_corr_gt1_scaled_grid.best_params_}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "22192867",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15969\n",
      "           1       0.99      0.97      0.98     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9841341966753758\n",
      "Precision: 0.987639902676399\n",
      "Recall: 0.9720306513409962\n",
      "F1: 0.9797731112720252\n",
      "Time per data per iter: 338.08777310765265\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_corr_gt1_scaled,\n",
    "        f\"Logistic Regression {log_corr_gt1_scaled_grid.best_params_}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d422ce47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.99      0.88     58138\n",
      "           1       0.82      0.10      0.18     17752\n",
      "\n",
      "    accuracy                           0.78     75890\n",
      "   macro avg       0.80      0.55      0.53     75890\n",
      "weighted avg       0.79      0.78      0.71     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7846751877717749\n",
      "Precision: 0.8219990871748061\n",
      "Recall: 0.10145335736818387\n",
      "F1: 0.18061475204332347\n",
      "Time per data per iter: 286.5265515878245\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_corr_gt1_scaled,\n",
    "        f\"Logistic Regression{log_corr_gt1_scaled_grid.best_params_}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features scaled\",\n",
    "        pipeline_corr_gt1_scaled,\n",
    "        scaler=scaler_gt1,\n",
    "        cols=cols_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "6167a868",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>593.930559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>496.575410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>420.447490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>439.863626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>338.087773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>286.526552</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Model          Dataset                                 Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                  All features scaled      12759  0.993338   0.989959  0.994775  0.992361              593.930559\n",
       "1       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                  All features scaled      26409  0.980045   0.995105  0.954215  0.974231              496.575410\n",
       "2       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                  All features scaled      75890  0.774476   0.845070  0.043939  0.083534              420.447490\n",
       "3  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks  |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168              439.863626\n",
       "4  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks  |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773              338.087773\n",
       "5   Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks  |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615              286.526552"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17974b68",
   "metadata": {},
   "source": [
    "### All features with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "065da356",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>17</th>\n",
       "      <th>18</th>\n",
       "      <th>19</th>\n",
       "      <th>20</th>\n",
       "      <th>21</th>\n",
       "      <th>22</th>\n",
       "      <th>23</th>\n",
       "      <th>24</th>\n",
       "      <th>25</th>\n",
       "      <th>26</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1.516735</td>\n",
       "      <td>-1.070537</td>\n",
       "      <td>4.199741</td>\n",
       "      <td>-1.394049</td>\n",
       "      <td>0.957756</td>\n",
       "      <td>0.583451</td>\n",
       "      <td>1.314415</td>\n",
       "      <td>0.300038</td>\n",
       "      <td>-0.100427</td>\n",
       "      <td>-0.074686</td>\n",
       "      <td>0.018951</td>\n",
       "      <td>-0.068260</td>\n",
       "      <td>-0.085588</td>\n",
       "      <td>-0.029476</td>\n",
       "      <td>-0.045298</td>\n",
       "      <td>0.029734</td>\n",
       "      <td>0.115908</td>\n",
       "      <td>0.130896</td>\n",
       "      <td>-0.111055</td>\n",
       "      <td>-0.021935</td>\n",
       "      <td>-0.102228</td>\n",
       "      <td>0.114430</td>\n",
       "      <td>0.068183</td>\n",
       "      <td>-0.159354</td>\n",
       "      <td>0.227031</td>\n",
       "      <td>-0.697531</td>\n",
       "      <td>0.338713</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.516680</td>\n",
       "      <td>-1.070594</td>\n",
       "      <td>4.199846</td>\n",
       "      <td>-1.393880</td>\n",
       "      <td>0.957351</td>\n",
       "      <td>0.583922</td>\n",
       "      <td>1.314396</td>\n",
       "      <td>0.300622</td>\n",
       "      <td>-0.100220</td>\n",
       "      <td>-0.074792</td>\n",
       "      <td>0.018950</td>\n",
       "      <td>-0.068254</td>\n",
       "      <td>-0.085581</td>\n",
       "      <td>-0.029455</td>\n",
       "      <td>-0.045232</td>\n",
       "      <td>0.029740</td>\n",
       "      <td>0.115972</td>\n",
       "      <td>0.130898</td>\n",
       "      <td>-0.111276</td>\n",
       "      <td>-0.022129</td>\n",
       "      <td>-0.102981</td>\n",
       "      <td>0.114281</td>\n",
       "      <td>0.068581</td>\n",
       "      <td>-0.159547</td>\n",
       "      <td>0.227155</td>\n",
       "      <td>-0.697391</td>\n",
       "      <td>0.338751</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-2.194275</td>\n",
       "      <td>0.599526</td>\n",
       "      <td>-2.547375</td>\n",
       "      <td>1.784875</td>\n",
       "      <td>4.735872</td>\n",
       "      <td>2.335350</td>\n",
       "      <td>-1.259882</td>\n",
       "      <td>0.229815</td>\n",
       "      <td>-6.911835</td>\n",
       "      <td>-8.327002</td>\n",
       "      <td>-2.483018</td>\n",
       "      <td>0.013701</td>\n",
       "      <td>-2.341332</td>\n",
       "      <td>-1.531040</td>\n",
       "      <td>-0.593786</td>\n",
       "      <td>1.307459</td>\n",
       "      <td>5.735253</td>\n",
       "      <td>2.203422</td>\n",
       "      <td>1.863483</td>\n",
       "      <td>0.821762</td>\n",
       "      <td>-1.594002</td>\n",
       "      <td>-2.386889</td>\n",
       "      <td>2.089085</td>\n",
       "      <td>8.092894</td>\n",
       "      <td>1.559132</td>\n",
       "      <td>0.200839</td>\n",
       "      <td>-1.005800</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.795953</td>\n",
       "      <td>-0.176684</td>\n",
       "      <td>-0.057415</td>\n",
       "      <td>0.785596</td>\n",
       "      <td>-0.009620</td>\n",
       "      <td>-1.722739</td>\n",
       "      <td>-0.344424</td>\n",
       "      <td>0.030185</td>\n",
       "      <td>0.169341</td>\n",
       "      <td>0.000372</td>\n",
       "      <td>-0.112997</td>\n",
       "      <td>-0.017776</td>\n",
       "      <td>-0.066358</td>\n",
       "      <td>0.030031</td>\n",
       "      <td>-0.103921</td>\n",
       "      <td>-0.081910</td>\n",
       "      <td>-0.207825</td>\n",
       "      <td>-0.091106</td>\n",
       "      <td>0.108699</td>\n",
       "      <td>0.166714</td>\n",
       "      <td>-0.022175</td>\n",
       "      <td>-0.519474</td>\n",
       "      <td>0.144395</td>\n",
       "      <td>0.563761</td>\n",
       "      <td>-0.508144</td>\n",
       "      <td>1.405539</td>\n",
       "      <td>0.976435</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-1.698577</td>\n",
       "      <td>-0.885367</td>\n",
       "      <td>1.251274</td>\n",
       "      <td>1.889236</td>\n",
       "      <td>-0.672711</td>\n",
       "      <td>-1.345817</td>\n",
       "      <td>-0.983839</td>\n",
       "      <td>0.260147</td>\n",
       "      <td>0.271514</td>\n",
       "      <td>0.089606</td>\n",
       "      <td>-0.036208</td>\n",
       "      <td>-0.054843</td>\n",
       "      <td>0.004780</td>\n",
       "      <td>-0.013959</td>\n",
       "      <td>-0.135784</td>\n",
       "      <td>-0.008889</td>\n",
       "      <td>-0.014911</td>\n",
       "      <td>0.071884</td>\n",
       "      <td>-0.026465</td>\n",
       "      <td>0.074480</td>\n",
       "      <td>-0.111767</td>\n",
       "      <td>-0.359301</td>\n",
       "      <td>0.286965</td>\n",
       "      <td>0.171620</td>\n",
       "      <td>-0.189821</td>\n",
       "      <td>-0.418918</td>\n",
       "      <td>-0.024381</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6         7         8         9        10        11        12        13        14        15        16        17        18        19        20        21        22        23        24        25        26  class\n",
       "0 -1.516735 -1.070537  4.199741 -1.394049  0.957756  0.583451  1.314415  0.300038 -0.100427 -0.074686  0.018951 -0.068260 -0.085588 -0.029476 -0.045298  0.029734  0.115908  0.130896 -0.111055 -0.021935 -0.102228  0.114430  0.068183 -0.159354  0.227031 -0.697531  0.338713    0.0\n",
       "1 -1.516680 -1.070594  4.199846 -1.393880  0.957351  0.583922  1.314396  0.300622 -0.100220 -0.074792  0.018950 -0.068254 -0.085581 -0.029455 -0.045232  0.029740  0.115972  0.130898 -0.111276 -0.022129 -0.102981  0.114281  0.068581 -0.159547  0.227155 -0.697391  0.338751    0.0\n",
       "2 -2.194275  0.599526 -2.547375  1.784875  4.735872  2.335350 -1.259882  0.229815 -6.911835 -8.327002 -2.483018  0.013701 -2.341332 -1.531040 -0.593786  1.307459  5.735253  2.203422  1.863483  0.821762 -1.594002 -2.386889  2.089085  8.092894  1.559132  0.200839 -1.005800    1.0\n",
       "3 -1.795953 -0.176684 -0.057415  0.785596 -0.009620 -1.722739 -0.344424  0.030185  0.169341  0.000372 -0.112997 -0.017776 -0.066358  0.030031 -0.103921 -0.081910 -0.207825 -0.091106  0.108699  0.166714 -0.022175 -0.519474  0.144395  0.563761 -0.508144  1.405539  0.976435    0.0\n",
       "4 -1.698577 -0.885367  1.251274  1.889236 -0.672711 -1.345817 -0.983839  0.260147  0.271514  0.089606 -0.036208 -0.054843  0.004780 -0.013959 -0.135784 -0.008889 -0.014911  0.071884 -0.026465  0.074480 -0.111767 -0.359301  0.286965  0.171620 -0.189821 -0.418918 -0.024381    0.0"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pca = pipeline_pca(df=df, scaler=scaler, pca=pca)\n",
    "df_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "3ab7927b",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_pca_train,\n",
    "    X_pca_val,\n",
    "    X_pca_test,\n",
    "    y_pca_train,\n",
    "    y_pca_val,\n",
    "    y_pca_test,\n",
    ") = test_train_val_split(df_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f072be7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-11\" type=\"checkbox\" checked><label for=\"sk-estimator-id-11\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=245)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pca_baseline = LogisticRegression(random_state=random_state)\n",
    "log_pca_baseline.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "7b710668",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.97      0.97      7154\n",
      "         1.0       0.96      0.97      0.97      5605\n",
      "\n",
      "    accuracy                           0.97     12759\n",
      "   macro avg       0.97      0.97      0.97     12759\n",
      "weighted avg       0.97      0.97      0.97     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pca_val, log_pca_baseline.predict(X_pca_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "7dd9156f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.949 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.948 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.955 total time=   0.0s\n",
      "[CV 1/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.954 total time=   0.1s\n",
      "[CV 2/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.956 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.957 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.963 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.960 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.967 total time=   0.0s\n",
      "[CV 1/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.963 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.960 total time=   0.0s\n",
      "[CV 3/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.967 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.960 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.955 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.964 total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.963 total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.960 total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.967 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.962 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.960 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.967 total time=   0.1s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.977 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ..C=0.01, penalty=none, solver=sag;, score=0.972 total time=   0.1s\n",
      "[CV 2/3] END ..C=0.01, penalty=none, solver=sag;, score=0.968 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=0.01, penalty=none, solver=sag;, score=0.970 total time=   0.1s\n",
      "[CV 1/3] END .C=0.01, penalty=none, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=0.01, penalty=none, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END .C=0.01, penalty=none, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.971 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.966 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.968 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.963 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.969 total time=   0.2s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.968 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.968 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.971 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.967 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.970 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.971 total time=   0.1s\n",
      "[CV 2/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.967 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.971 total time=   0.1s\n",
      "[CV 1/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.967 total time=   0.1s\n",
      "[CV 3/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.970 total time=   0.1s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=0.1, penalty=none, solver=sag;, score=0.972 total time=   0.1s\n",
      "[CV 2/3] END ...C=0.1, penalty=none, solver=sag;, score=0.968 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.1, penalty=none, solver=sag;, score=0.970 total time=   0.1s\n",
      "[CV 1/3] END ..C=0.1, penalty=none, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=0.1, penalty=none, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END ..C=0.1, penalty=none, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l1, solver=liblinear;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l1, solver=liblinear;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l1, solver=liblinear;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ......C=1, penalty=l1, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l1, solver=saga;, score=0.966 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ......C=1, penalty=l1, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .C=1, penalty=l2, solver=liblinear;, score=0.973 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=liblinear;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=liblinear;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .......C=1, penalty=l2, solver=sag;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l2, solver=sag;, score=0.968 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .......C=1, penalty=l2, solver=sag;, score=0.970 total time=   0.1s\n",
      "[CV 1/3] END ......C=1, penalty=l2, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l2, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END ......C=1, penalty=l2, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=1, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=none, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=none, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=1, penalty=none, solver=sag;, score=0.972 total time=   0.1s\n",
      "[CV 2/3] END .....C=1, penalty=none, solver=sag;, score=0.968 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=1, penalty=none, solver=sag;, score=0.970 total time=   0.1s\n",
      "[CV 1/3] END ....C=1, penalty=none, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=1, penalty=none, solver=saga;, score=0.966 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=1, penalty=none, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l1, solver=liblinear;, score=0.977 total time=   0.6s\n",
      "[CV 2/3] END C=10, penalty=l1, solver=liblinear;, score=0.978 total time=   0.5s\n",
      "[CV 3/3] END C=10, penalty=l1, solver=liblinear;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=10, penalty=l1, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=10, penalty=l1, solver=saga;, score=0.966 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=10, penalty=l1, solver=saga;, score=0.969 total time=   0.2s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=newton-cg;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=liblinear;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=liblinear;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ......C=10, penalty=l2, solver=sag;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END ......C=10, penalty=l2, solver=sag;, score=0.968 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ......C=10, penalty=l2, solver=sag;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END .....C=10, penalty=l2, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=10, penalty=l2, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END .....C=10, penalty=l2, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=10, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=none, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=none, solver=sag;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=none, solver=sag;, score=0.968 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=10, penalty=none, solver=sag;, score=0.970 total time=   0.1s\n",
      "[CV 1/3] END ...C=10, penalty=none, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ...C=10, penalty=none, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END ...C=10, penalty=none, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l1, solver=liblinear;, score=0.977 total time=   0.5s\n",
      "[CV 2/3] END C=100, penalty=l1, solver=liblinear;, score=0.978 total time=   0.5s\n",
      "[CV 3/3] END C=100, penalty=l1, solver=liblinear;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=100, penalty=l1, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=100, penalty=l1, solver=saga;, score=0.966 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=100, penalty=l1, solver=saga;, score=0.969 total time=   0.2s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=l2, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=newton-cg;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.977 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=liblinear;, score=0.976 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\svm\\_base.py:1250: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END C=100, penalty=l2, solver=liblinear;, score=0.976 total time=   0.3s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=liblinear;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .....C=100, penalty=l2, solver=sag;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END .....C=100, penalty=l2, solver=sag;, score=0.968 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=100, penalty=l2, solver=sag;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END ....C=100, penalty=l2, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ....C=100, penalty=l2, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END ....C=100, penalty=l2, solver=saga;, score=0.969 total time=   0.1s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\scipy\\optimize\\_linesearch.py:306: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\optimize.py:204: UserWarning: Line Search failed\n",
      "  warnings.warn(\"Line Search failed\")\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END C=100, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=newton-cg;, score=0.973 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=none, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .C=100, penalty=none, solver=lbfgs;, score=0.977 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .C=100, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=none, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=100, penalty=none, solver=sag;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=none, solver=sag;, score=0.968 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=100, penalty=none, solver=sag;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END ..C=100, penalty=none, solver=saga;, score=0.970 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 73, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.95062309        nan 0.95563916 0.96308488\n",
      " 0.96308488 0.95979309 0.96308488 0.96292813        nan        nan\n",
      "        nan        nan        nan 0.97335214 0.97562505        nan\n",
      " 0.97006035 0.96833608        nan        nan 0.96927659        nan\n",
      " 0.9666118  0.9702171  0.9702171  0.96919821 0.96966847 0.96864958\n",
      "        nan        nan        nan        nan        nan 0.97335214\n",
      " 0.97562505        nan 0.97006035 0.96833608        nan        nan\n",
      " 0.97358727        nan 0.96810095 0.97319539 0.97319539 0.97264676\n",
      " 0.97013873 0.96841445        nan        nan        nan        nan\n",
      "        nan 0.97335214 0.97562505        nan 0.97006035 0.96833608\n",
      "        nan        nan 0.9754683         nan 0.96833608 0.9735089\n",
      " 0.97366565 0.97366565 0.97006035 0.96833608        nan        nan\n",
      "        nan        nan        nan 0.97335214 0.97562505        nan\n",
      " 0.97006035 0.96833608        nan        nan 0.97562505        nan\n",
      " 0.96833608 0.97335214 0.97476291 0.97468454 0.97006035 0.96833608\n",
      "        nan        nan        nan        nan        nan 0.97335214\n",
      " 0.97562505        nan 0.97006035 0.96833608]\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ..C=100, penalty=none, solver=saga;, score=0.966 total time=   0.1s\n",
      "[CV 3/3] END ..C=100, penalty=none, solver=saga;, score=0.969 total time=   0.1s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-8 {color: black;}#sk-container-id-8 pre{padding: 0;}#sk-container-id-8 div.sk-toggleable {background-color: white;}#sk-container-id-8 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-8 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-8 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-8 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-8 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-8 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-8 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-8 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-8 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-8 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-8 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-8 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-8 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-8 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-8 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-8 div.sk-item {position: relative;z-index: 1;}#sk-container-id-8 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-8 div.sk-item::before, #sk-container-id-8 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-8 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-8 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-8 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-8 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-8 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-8 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-8 div.sk-label-container {text-align: center;}#sk-container-id-8 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-8 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-8\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-12\" type=\"checkbox\" ><label for=\"sk-estimator-id-12\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-13\" type=\"checkbox\" ><label for=\"sk-estimator-id-13\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-14\" type=\"checkbox\" ><label for=\"sk-estimator-id-14\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pca_grid = GridSearchCV(LogisticRegression(random_state=random_state), log_param_grid, cv=cv, n_jobs=n_jobs, verbose=verbose)\n",
    "log_pca_grid.fit(X_pca_val, y_pca_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "751b3e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n"
     ]
    }
   ],
   "source": [
    "print(log_pca_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "b3440983",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-9 {color: black;}#sk-container-id-9 pre{padding: 0;}#sk-container-id-9 div.sk-toggleable {background-color: white;}#sk-container-id-9 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-9 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-9 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-9 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-9 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-9 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-9 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-9 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-9 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-9 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-9 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-9 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-9 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-9 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-9 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-9 div.sk-item {position: relative;z-index: 1;}#sk-container-id-9 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-9 div.sk-item::before, #sk-container-id-9 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-9 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-9 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-9 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-9 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-9 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-9 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-9 div.sk-label-container {text-align: center;}#sk-container-id-9 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-9 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-9\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-15\" type=\"checkbox\" checked><label for=\"sk-estimator-id-15\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=0.01, penalty=&#x27;none&#x27;, random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=0.01, penalty='none', random_state=245)"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_pca = LogisticRegression(**log_pca_grid.best_params_, random_state=random_state)\n",
    "log_pca.fit(X_pca_train, y_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6211c133",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7209\n",
      "         1.0       0.97      0.98      0.97      5550\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_pca_test, log_pca.predict(X_pca_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "841a8087",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7209\n",
      "         1.0       0.97      0.98      0.97      5550\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9770358178540638\n",
      "Precision: 0.9709729439168607\n",
      "Recall: 0.9763963963963964\n",
      "F1: 0.9736771179588536\n",
      "Time per data per iter: 927.9120620738302\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_pca,\n",
    "        f\"Logistic Regression {log_pca_grid.best_params_}\",\n",
    "        \"Known attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler,\n",
    "        pca=pca\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "8f69f22e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.99     15969\n",
      "           1       0.98      0.98      0.98     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regressiion {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9828467567874588\n",
      "Precision: 0.9808377467501204\n",
      "Recall: 0.9756704980842912\n",
      "F1: 0.9782472989195679\n",
      "Time per data per iter: 894.3954712408649\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_pca,\n",
    "        f\"Logistic Regressiion {log_pca_grid.best_params_}\",\n",
    "        \"Similar attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler,\n",
    "        pca=pca\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "84f80179",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87     58138\n",
      "           1       0.51      0.04      0.07     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.64      0.51      0.47     75890\n",
      "weighted avg       0.71      0.77      0.68     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7664909737778364\n",
      "Precision: 0.5117157974300831\n",
      "Recall: 0.03813654799459216\n",
      "F1: 0.07098296199213629\n",
      "Time per data per iter: 909.4849123731717\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_pca,\n",
    "        f\"Logistic Regression {log_pca_grid.best_params_}\",\n",
    "        \"New attacks\",\n",
    "        \"All features with 95% PCA\",\n",
    "        pipeline_pca,\n",
    "        scaler=scaler,\n",
    "        pca=pca\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "9f34af51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>593.930559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>496.575410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>420.447490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>439.863626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>338.087773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>286.526552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.970973</td>\n",
       "      <td>0.976396</td>\n",
       "      <td>0.973677</td>\n",
       "      <td>927.912062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regressiion {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.980838</td>\n",
       "      <td>0.975670</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>894.395471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766491</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.070983</td>\n",
       "      <td>909.484912</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                       Model          Dataset                                 Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                  All features scaled      12759  0.993338   0.989959  0.994775  0.992361              593.930559\n",
       "1       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                  All features scaled      26409  0.980045   0.995105  0.954215  0.974231              496.575410\n",
       "2       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                  All features scaled      75890  0.774476   0.845070  0.043939  0.083534              420.447490\n",
       "3  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks  |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168              439.863626\n",
       "4  Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks  |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773              338.087773\n",
       "5   Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks  |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615              286.526552\n",
       "6      Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}    Known attacks            All features with 95% PCA      12759  0.977036   0.970973  0.976396  0.973677              927.912062\n",
       "7     Logistic Regressiion {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}  Similar attacks            All features with 95% PCA      26409  0.982847   0.980838  0.975670  0.978247              894.395471\n",
       "8      Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}      New attacks            All features with 95% PCA      75890  0.766491   0.511716  0.038137  0.070983              909.484912"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76925a3e",
   "metadata": {},
   "source": [
    "### Features with |correlation| > 0.1 with 95% PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "024ad27d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.543609</td>\n",
       "      <td>4.230357</td>\n",
       "      <td>1.869249</td>\n",
       "      <td>-0.251843</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.190714</td>\n",
       "      <td>0.364347</td>\n",
       "      <td>-0.114097</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>-0.081331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.543609</td>\n",
       "      <td>4.230357</td>\n",
       "      <td>1.869249</td>\n",
       "      <td>-0.251843</td>\n",
       "      <td>0.788871</td>\n",
       "      <td>0.190714</td>\n",
       "      <td>0.364347</td>\n",
       "      <td>-0.114097</td>\n",
       "      <td>0.499856</td>\n",
       "      <td>-0.081331</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-1.994167</td>\n",
       "      <td>-1.461920</td>\n",
       "      <td>-0.938954</td>\n",
       "      <td>0.293926</td>\n",
       "      <td>1.364275</td>\n",
       "      <td>-0.010223</td>\n",
       "      <td>0.649041</td>\n",
       "      <td>-0.738695</td>\n",
       "      <td>-0.118310</td>\n",
       "      <td>0.030188</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.350594</td>\n",
       "      <td>0.261992</td>\n",
       "      <td>-0.964845</td>\n",
       "      <td>1.102809</td>\n",
       "      <td>-0.889646</td>\n",
       "      <td>-1.028780</td>\n",
       "      <td>-0.107525</td>\n",
       "      <td>0.580810</td>\n",
       "      <td>-1.068071</td>\n",
       "      <td>0.201405</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.704318</td>\n",
       "      <td>1.340008</td>\n",
       "      <td>-1.522401</td>\n",
       "      <td>1.729258</td>\n",
       "      <td>-1.340019</td>\n",
       "      <td>-0.612810</td>\n",
       "      <td>-0.126361</td>\n",
       "      <td>0.481897</td>\n",
       "      <td>0.016040</td>\n",
       "      <td>-0.037508</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6         7         8         9  class\n",
       "0 -0.543609  4.230357  1.869249 -0.251843  0.788871  0.190714  0.364347 -0.114097  0.499856 -0.081331    0.0\n",
       "1 -0.543609  4.230357  1.869249 -0.251843  0.788871  0.190714  0.364347 -0.114097  0.499856 -0.081331    0.0\n",
       "2 -1.994167 -1.461920 -0.938954  0.293926  1.364275 -0.010223  0.649041 -0.738695 -0.118310  0.030188    1.0\n",
       "3 -1.350594  0.261992 -0.964845  1.102809 -0.889646 -1.028780 -0.107525  0.580810 -1.068071  0.201405    0.0\n",
       "4 -0.704318  1.340008 -1.522401  1.729258 -1.340019 -0.612810 -0.126361  0.481897  0.016040 -0.037508    0.0"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_corr_gt1_pca = pipeline_corr_gt1_pca(df=df, scaler=scaler_gt1, cols=cols_corr_gt1, pca=pca_corr_gt1)\n",
    "df_corr_gt1_pca.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9006bc85",
   "metadata": {},
   "outputs": [],
   "source": [
    "(\n",
    "    X_corr_gt1_pca_train,\n",
    "    X_corr_gt1_pca_val,\n",
    "    X_corr_gt1_pca_test,\n",
    "    y_corr_gt1_pca_train,\n",
    "    y_corr_gt1_pca_val,\n",
    "    y_corr_gt1_pca_test,\n",
    ") = test_train_val_split(df_corr_gt1_pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "6111b00a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-10 {color: black;}#sk-container-id-10 pre{padding: 0;}#sk-container-id-10 div.sk-toggleable {background-color: white;}#sk-container-id-10 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-10 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-10 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-10 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-10 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-10 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-10 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-10 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-10 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-10 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-10 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-10 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-10 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-10 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-10 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-10 div.sk-item {position: relative;z-index: 1;}#sk-container-id-10 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-10 div.sk-item::before, #sk-container-id-10 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-10 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-10 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-10 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-10 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-10 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-10 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-10 div.sk-label-container {text-align: center;}#sk-container-id-10 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-10 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-10\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(random_state=245)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-16\" type=\"checkbox\" checked><label for=\"sk-estimator-id-16\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(random_state=245)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_pca_baseline = LogisticRegression(random_state=random_state)\n",
    "log_corr_gt1_pca_baseline.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "24f7b183",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7154\n",
      "         1.0       0.97      0.97      0.97      5605\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_corr_gt1_pca_val, log_corr_gt1_pca_baseline.predict(X_corr_gt1_pca_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "1c249af2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.948 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.941 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l1, solver=liblinear;, score=0.949 total time=   0.0s\n",
      "[CV 1/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=0.01, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.957 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.952 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.01, penalty=l1, solver=saga;, score=0.958 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.954 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.954 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=newton-cg;, score=0.956 total time=   0.0s\n",
      "[CV 1/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.954 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.954 total time=   0.0s\n",
      "[CV 3/3] END ..C=0.01, penalty=l2, solver=lbfgs;, score=0.956 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.949 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.940 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=l2, solver=liblinear;, score=0.950 total time=   0.0s\n",
      "[CV 1/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.954 total time=   0.0s\n",
      "[CV 2/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.954 total time=   0.0s\n",
      "[CV 3/3] END ....C=0.01, penalty=l2, solver=sag;, score=0.956 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.954 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.954 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.01, penalty=l2, solver=saga;, score=0.956 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=0.01, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.01, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ..C=0.01, penalty=none, solver=sag;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.01, penalty=none, solver=sag;, score=0.976 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=0.01, penalty=none, solver=sag;, score=0.974 total time=   0.0s\n",
      "[CV 1/3] END .C=0.01, penalty=none, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .C=0.01, penalty=none, solver=saga;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .C=0.01, penalty=none, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=0.1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=0.1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l1, solver=liblinear;, score=0.974 total time=   0.0s\n",
      "[CV 1/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=0.1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.971 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=0.1, penalty=l1, solver=saga;, score=0.971 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.970 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=newton-cg;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.970 total time=   0.0s\n",
      "[CV 3/3] END ...C=0.1, penalty=l2, solver=lbfgs;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.967 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.966 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=l2, solver=liblinear;, score=0.967 total time=   0.0s\n",
      "[CV 1/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.970 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=0.1, penalty=l2, solver=sag;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 2/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.969 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=0.1, penalty=l2, solver=saga;, score=0.970 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .C=0.1, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=0.1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ...C=0.1, penalty=none, solver=sag;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END ...C=0.1, penalty=none, solver=sag;, score=0.976 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ...C=0.1, penalty=none, solver=sag;, score=0.974 total time=   0.0s\n",
      "[CV 1/3] END ..C=0.1, penalty=none, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ..C=0.1, penalty=none, solver=saga;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ..C=0.1, penalty=none, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=1, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l1, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l1, solver=liblinear;, score=0.979 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l1, solver=liblinear;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .........C=1, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ......C=1, penalty=l1, solver=saga;, score=0.976 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=1, penalty=l1, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END ......C=1, penalty=l1, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.978 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .C=1, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END .....C=1, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=l2, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=l2, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=l2, solver=liblinear;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .......C=1, penalty=l2, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .......C=1, penalty=l2, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END .......C=1, penalty=l2, solver=sag;, score=0.973 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ......C=1, penalty=l2, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ......C=1, penalty=l2, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END ......C=1, penalty=l2, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=1, penalty=none, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=1, penalty=none, solver=newton-cg;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=1, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END ...C=1, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=1, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=1, penalty=none, solver=sag;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END .....C=1, penalty=none, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END .....C=1, penalty=none, solver=sag;, score=0.974 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=1, penalty=none, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ....C=1, penalty=none, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END ....C=1, penalty=none, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l1, solver=liblinear;, score=0.975 total time=   0.1s\n",
      "[CV 2/3] END C=10, penalty=l1, solver=liblinear;, score=0.978 total time=   0.1s\n",
      "[CV 3/3] END C=10, penalty=l1, solver=liblinear;, score=0.975 total time=   0.1s\n",
      "[CV 1/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END ........C=10, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END .....C=10, penalty=l1, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .....C=10, penalty=l1, solver=saga;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END .....C=10, penalty=l1, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=newton-cg;, score=0.979 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.979 total time=   0.0s\n",
      "[CV 3/3] END ....C=10, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=l2, solver=liblinear;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=l2, solver=liblinear;, score=0.979 total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=l2, solver=liblinear;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END ......C=10, penalty=l2, solver=sag;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END ......C=10, penalty=l2, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END ......C=10, penalty=l2, solver=sag;, score=0.974 total time=   0.0s\n",
      "[CV 1/3] END .....C=10, penalty=l2, solver=saga;, score=0.976 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=10, penalty=l2, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END .....C=10, penalty=l2, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=newton-cg;, score=0.978 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END C=10, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END ..C=10, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=10, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=10, penalty=none, solver=sag;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END ....C=10, penalty=none, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END ....C=10, penalty=none, solver=sag;, score=0.974 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=10, penalty=none, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ...C=10, penalty=none, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END ...C=10, penalty=none, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=l1, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .....C=100, penalty=l1, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l1, solver=liblinear;, score=0.976 total time=   0.1s\n",
      "[CV 2/3] END C=100, penalty=l1, solver=liblinear;, score=0.978 total time=   0.1s\n",
      "[CV 3/3] END C=100, penalty=l1, solver=liblinear;, score=0.975 total time=   0.1s\n",
      "[CV 1/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END .......C=100, penalty=l1, solver=sag;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=100, penalty=l1, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ....C=100, penalty=l1, solver=saga;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 3/3] END ....C=100, penalty=l1, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=l2, solver=newton-cg;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END ...C=100, penalty=l2, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=l2, solver=liblinear;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=l2, solver=liblinear;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=l2, solver=liblinear;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .....C=100, penalty=l2, solver=sag;, score=0.975 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 2/3] END .....C=100, penalty=l2, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END .....C=100, penalty=l2, solver=sag;, score=0.974 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ....C=100, penalty=l2, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ....C=100, penalty=l2, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END ....C=100, penalty=l2, solver=saga;, score=0.972 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=newton-cg;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=lbfgs;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=sag;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=elasticnet, solver=saga;, score=nan total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=none, solver=newton-cg;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=newton-cg;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=none, solver=newton-cg;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END .C=100, penalty=none, solver=lbfgs;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END .C=100, penalty=none, solver=lbfgs;, score=0.978 total time=   0.0s\n",
      "[CV 3/3] END .C=100, penalty=none, solver=lbfgs;, score=0.975 total time=   0.0s\n",
      "[CV 1/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 2/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n",
      "[CV 3/3] END C=100, penalty=none, solver=liblinear;, score=nan total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ...C=100, penalty=none, solver=sag;, score=0.975 total time=   0.0s\n",
      "[CV 2/3] END ...C=100, penalty=none, solver=sag;, score=0.976 total time=   0.0s\n",
      "[CV 3/3] END ...C=100, penalty=none, solver=sag;, score=0.974 total time=   0.0s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1183: FutureWarning: `penalty='none'`has been deprecated in 1.2 and will be removed in 1.4. To keep the past behaviour, set `penalty=None`.\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:1193: UserWarning: Setting penalty=None will ignore the C and l1_ratio parameters\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_sag.py:350: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:425: FitFailedWarning: \n",
      "135 fits failed out of a total of 300.\n",
      "The score on these train-test partitions for these parameters will be set to nan.\n",
      "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
      "\n",
      "Below are more details about the failures:\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got l1 penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver newton-cg supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 66, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 56, in _check_solver\n",
      "    raise ValueError(\n",
      "ValueError: Solver sag supports only 'l2' or 'none' penalties, got elasticnet penalty.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1179, in fit\n",
      "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
      "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "15 fits failed with the following error:\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py\", line 729, in _fit_and_score\n",
      "    estimator.fit(X_train, y_train, **fit_params)\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\base.py\", line 1152, in wrapper\n",
      "    return fit_method(estimator, *args, **kwargs)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 1169, in fit\n",
      "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py\", line 73, in _check_solver\n",
      "    raise ValueError(\"penalty='none' is not supported for the liblinear solver\")\n",
      "ValueError: penalty='none' is not supported for the liblinear solver\n",
      "\n",
      "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
      "c:\\Users\\harsh\\anaconda3\\Lib\\site-packages\\sklearn\\model_selection\\_search.py:979: UserWarning: One or more of the test scores are non-finite: [       nan        nan 0.94576377        nan 0.95571753 0.95477702\n",
      " 0.95477702 0.94639078 0.95477702 0.95477702        nan        nan\n",
      "        nan        nan        nan 0.97625206 0.97625206        nan\n",
      " 0.97523317 0.97429266        nan        nan 0.97484129        nan\n",
      " 0.97225488 0.97092249 0.97092249 0.96700368 0.97084411 0.97037385\n",
      "        nan        nan        nan        nan        nan 0.97625206\n",
      " 0.97625206        nan 0.97523317 0.97429266        nan        nan\n",
      " 0.97664394        nan 0.97429266 0.97625206 0.97625206 0.97562505\n",
      " 0.97507642 0.97437103        nan        nan        nan        nan\n",
      "        nan 0.97625206 0.97625206        nan 0.97523317 0.97429266\n",
      "        nan        nan 0.97617368        nan 0.97421428 0.97633043\n",
      " 0.97633043 0.97648719 0.97515479 0.97421428        nan        nan\n",
      "        nan        nan        nan 0.97625206 0.97625206        nan\n",
      " 0.97523317 0.97429266        nan        nan 0.97625206        nan\n",
      " 0.97421428 0.97625206 0.97625206 0.97617368 0.97523317 0.97421428\n",
      "        nan        nan        nan        nan        nan 0.97625206\n",
      " 0.97625206        nan 0.97523317 0.97429266]\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV 1/3] END ..C=100, penalty=none, solver=saga;, score=0.976 total time=   0.0s\n",
      "[CV 2/3] END ..C=100, penalty=none, solver=saga;, score=0.975 total time=   0.0s\n",
      "[CV 3/3] END ..C=100, penalty=none, solver=saga;, score=0.972 total time=   0.0s\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-11 {color: black;}#sk-container-id-11 pre{padding: 0;}#sk-container-id-11 div.sk-toggleable {background-color: white;}#sk-container-id-11 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-11 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-11 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-11 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-11 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-11 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-11 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-11 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-11 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-11 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-11 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-11 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-11 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-11 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-11 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-11 div.sk-item {position: relative;z-index: 1;}#sk-container-id-11 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-11 div.sk-item::before, #sk-container-id-11 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-11 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-11 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-11 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-11 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-11 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-11 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-11 div.sk-label-container {text-align: center;}#sk-container-id-11 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-11 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-11\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-17\" type=\"checkbox\" ><label for=\"sk-estimator-id-17\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">GridSearchCV</label><div class=\"sk-toggleable__content\"><pre>GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={&#x27;C&#x27;: [0.01, 0.1, 1, 10, 100],\n",
       "                         &#x27;penalty&#x27;: [&#x27;l1&#x27;, &#x27;l2&#x27;, &#x27;elasticnet&#x27;, &#x27;none&#x27;],\n",
       "                         &#x27;solver&#x27;: [&#x27;newton-cg&#x27;, &#x27;lbfgs&#x27;, &#x27;liblinear&#x27;, &#x27;sag&#x27;,\n",
       "                                    &#x27;saga&#x27;]},\n",
       "             verbose=3)</pre></div></div></div><div class=\"sk-parallel\"><div class=\"sk-parallel-item\"><div class=\"sk-item\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-18\" type=\"checkbox\" ><label for=\"sk-estimator-id-18\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">estimator: LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-19\" type=\"checkbox\" ><label for=\"sk-estimator-id-19\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(random_state=245)</pre></div></div></div></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "GridSearchCV(cv=3, estimator=LogisticRegression(random_state=245),\n",
       "             param_grid={'C': [0.01, 0.1, 1, 10, 100],\n",
       "                         'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
       "                         'solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag',\n",
       "                                    'saga']},\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_pca_grid = GridSearchCV(LogisticRegression(random_state=random_state), log_param_grid, cv=cv, n_jobs=n_jobs, verbose=verbose)\n",
    "log_corr_gt1_pca_grid.fit(X_corr_gt1_pca_val, y_corr_gt1_pca_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "21ef3bad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n"
     ]
    }
   ],
   "source": [
    "print(log_corr_gt1_pca_grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "396870a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-12 {color: black;}#sk-container-id-12 pre{padding: 0;}#sk-container-id-12 div.sk-toggleable {background-color: white;}#sk-container-id-12 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-12 label.sk-toggleable__label-arrow:before {content: \"\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-12 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-12 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-12 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-12 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-12 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-12 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"\";}#sk-container-id-12 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-12 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-12 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-12 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-12 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-12 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-12 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-12 div.sk-item {position: relative;z-index: 1;}#sk-container-id-12 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-12 div.sk-item::before, #sk-container-id-12 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-12 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-12 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-12 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-12 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-12 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-12 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-12 div.sk-label-container {text-align: center;}#sk-container-id-12 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-12 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-12\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-20\" type=\"checkbox\" checked><label for=\"sk-estimator-id-20\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(C=1, penalty=&#x27;l1&#x27;, random_state=245, solver=&#x27;liblinear&#x27;)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression(C=1, penalty='l1', random_state=245, solver='liblinear')"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_corr_gt1_pca = LogisticRegression(**log_corr_gt1_pca_grid.best_params_, random_state=random_state)\n",
    "log_corr_gt1_pca.fit(X_corr_gt1_pca_train, y_corr_gt1_pca_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "80a49c32",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7209\n",
      "         1.0       0.97      0.98      0.98      5550\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_corr_gt1_pca_test, log_corr_gt1_pca.predict(X_corr_gt1_pca_test)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "5ba8a401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.98      0.98      0.98      7209\n",
      "         1.0       0.97      0.98      0.98      5550\n",
      "\n",
      "    accuracy                           0.98     12759\n",
      "   macro avg       0.98      0.98      0.98     12759\n",
      "weighted avg       0.98      0.98      0.98     12759\n",
      "\n",
      "\n",
      "Model: Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 12759\n",
      "Accuracy: 0.9784465867230974\n",
      "Precision: 0.9737740255074546\n",
      "Recall: 0.9767567567567568\n",
      "F1: 0.9752631105514078\n",
      "Time per data per iter: 565.6266165059958\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_known_attacks,\n",
    "        log_corr_gt1_pca,\n",
    "        f\"Logisitc Regression {log_corr_gt1_pca_grid.best_params_}\",\n",
    "        \"Known attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "aec96012",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.99      0.98     15969\n",
      "           1       0.98      0.97      0.98     10440\n",
      "\n",
      "    accuracy                           0.98     26409\n",
      "   macro avg       0.98      0.98      0.98     26409\n",
      "weighted avg       0.98      0.98      0.98     26409\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 26409\n",
      "Accuracy: 0.9817486462948237\n",
      "Precision: 0.9805056938814901\n",
      "Recall: 0.9731800766283525\n",
      "F1: 0.9768291510431689\n",
      "Time per data per iter: 415.227005944943\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_similar_attacks,\n",
    "        log_corr_gt1_pca,\n",
    "        f\"Logistic Regression {log_corr_gt1_pca_grid.best_params_}\",\n",
    "        \"Similar attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "8728980e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.99      0.87     58138\n",
      "           1       0.55      0.03      0.06     17752\n",
      "\n",
      "    accuracy                           0.77     75890\n",
      "   macro avg       0.66      0.51      0.46     75890\n",
      "weighted avg       0.72      0.77      0.68     75890\n",
      "\n",
      "\n",
      "Model: Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}\n",
      "Data size: 75890\n",
      "Accuracy: 0.7673606535775465\n",
      "Precision: 0.5457979225684608\n",
      "Recall: 0.0325597115817936\n",
      "F1: 0.06145340492265163\n",
      "Time per data per iter: 420.4991434971669\n"
     ]
    }
   ],
   "source": [
    "benchmarkAndUpdateResult(\n",
    "        df_new_attacks,\n",
    "        log_corr_gt1_pca,\n",
    "        f\"Logistic Regression {log_corr_gt1_pca_grid.best_params_}\",\n",
    "        \"New attacks\",\n",
    "        \"|correlation| > 0.1 features with 95% PCA\",\n",
    "        pipeline_corr_gt1_pca,\n",
    "        scaler=scaler_gt1,\n",
    "        cols=cols_corr_gt1,\n",
    "        pca=pca_corr_gt1\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "5bdfc189",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Dataset</th>\n",
       "      <th>Info</th>\n",
       "      <th>Data size</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "      <th>Time per data per iter</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.993338</td>\n",
       "      <td>0.989959</td>\n",
       "      <td>0.994775</td>\n",
       "      <td>0.992361</td>\n",
       "      <td>593.930559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.980045</td>\n",
       "      <td>0.995105</td>\n",
       "      <td>0.954215</td>\n",
       "      <td>0.974231</td>\n",
       "      <td>496.575410</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.774476</td>\n",
       "      <td>0.845070</td>\n",
       "      <td>0.043939</td>\n",
       "      <td>0.083534</td>\n",
       "      <td>420.447490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.989654</td>\n",
       "      <td>0.983232</td>\n",
       "      <td>0.993153</td>\n",
       "      <td>0.988168</td>\n",
       "      <td>439.863626</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.984134</td>\n",
       "      <td>0.987640</td>\n",
       "      <td>0.972031</td>\n",
       "      <td>0.979773</td>\n",
       "      <td>338.087773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features scaled</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.784675</td>\n",
       "      <td>0.821999</td>\n",
       "      <td>0.101453</td>\n",
       "      <td>0.180615</td>\n",
       "      <td>286.526552</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.977036</td>\n",
       "      <td>0.970973</td>\n",
       "      <td>0.976396</td>\n",
       "      <td>0.973677</td>\n",
       "      <td>927.912062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Logistic Regressiion {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.982847</td>\n",
       "      <td>0.980838</td>\n",
       "      <td>0.975670</td>\n",
       "      <td>0.978247</td>\n",
       "      <td>894.395471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>All features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.766491</td>\n",
       "      <td>0.511716</td>\n",
       "      <td>0.038137</td>\n",
       "      <td>0.070983</td>\n",
       "      <td>909.484912</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Known attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>12759</td>\n",
       "      <td>0.978447</td>\n",
       "      <td>0.973774</td>\n",
       "      <td>0.976757</td>\n",
       "      <td>0.975263</td>\n",
       "      <td>565.626617</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>Similar attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>26409</td>\n",
       "      <td>0.981749</td>\n",
       "      <td>0.980506</td>\n",
       "      <td>0.973180</td>\n",
       "      <td>0.976829</td>\n",
       "      <td>415.227006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}</td>\n",
       "      <td>New attacks</td>\n",
       "      <td>|correlation| &gt; 0.1 features with 95% PCA</td>\n",
       "      <td>75890</td>\n",
       "      <td>0.767361</td>\n",
       "      <td>0.545798</td>\n",
       "      <td>0.032560</td>\n",
       "      <td>0.061453</td>\n",
       "      <td>420.499143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                                        Model          Dataset                                       Info  Data size  Accuracy  Precision    Recall        F1  Time per data per iter\n",
       "0        Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks                        All features scaled      12759  0.993338   0.989959  0.994775  0.992361              593.930559\n",
       "1        Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks                        All features scaled      26409  0.980045   0.995105  0.954215  0.974231              496.575410\n",
       "2        Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks                        All features scaled      75890  0.774476   0.845070  0.043939  0.083534              420.447490\n",
       "3   Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}    Known attacks        |correlation| > 0.1 features scaled      12759  0.989654   0.983232  0.993153  0.988168              439.863626\n",
       "4   Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}  Similar attacks        |correlation| > 0.1 features scaled      26409  0.984134   0.987640  0.972031  0.979773              338.087773\n",
       "5    Logistic Regression{'C': 0.01, 'penalty': 'none', 'solver': 'newton-cg'}      New attacks        |correlation| > 0.1 features scaled      75890  0.784675   0.821999  0.101453  0.180615              286.526552\n",
       "6       Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}    Known attacks                  All features with 95% PCA      12759  0.977036   0.970973  0.976396  0.973677              927.912062\n",
       "7      Logistic Regressiion {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}  Similar attacks                  All features with 95% PCA      26409  0.982847   0.980838  0.975670  0.978247              894.395471\n",
       "8       Logistic Regression {'C': 0.01, 'penalty': 'none', 'solver': 'lbfgs'}      New attacks                  All features with 95% PCA      75890  0.766491   0.511716  0.038137  0.070983              909.484912\n",
       "9        Logisitc Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}    Known attacks  |correlation| > 0.1 features with 95% PCA      12759  0.978447   0.973774  0.976757  0.975263              565.626617\n",
       "10       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}  Similar attacks  |correlation| > 0.1 features with 95% PCA      26409  0.981749   0.980506  0.973180  0.976829              415.227006\n",
       "11       Logistic Regression {'C': 1, 'penalty': 'l1', 'solver': 'liblinear'}      New attacks  |correlation| > 0.1 features with 95% PCA      75890  0.767361   0.545798  0.032560  0.061453              420.499143"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "benchmark_results"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
